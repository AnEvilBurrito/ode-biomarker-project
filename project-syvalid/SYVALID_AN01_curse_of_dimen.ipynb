{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sungyoung Internal Validation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "from DataLink import DataLink\n",
    "data_link = DataLink(path_loader, 'data_codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SY's Valiadtion Method for Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CCLE Palbociclib..\n",
      "Data loaded for code ccle-gdsc-2-Palbociclib-LN_IC50\n"
     ]
    }
   ],
   "source": [
    "## Loading Data \n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_informative=50, n_features=1000, noise=0.1)\n",
    "# make X,y into dataframes\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "print('Loading CCLE Palbociclib..')\n",
    "\n",
    "loading_code = 'ccle-gdsc-2-Palbociclib-LN_IC50'\n",
    "feature_data, label_data = data_link.get_data_using_code(loading_code)\n",
    "print(f'Data loaded for code {loading_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions \n",
    "\n",
    "def log_distributed_feature_size_list(min_size,max_size):\n",
    "    # log distributed feature size list\n",
    "    feature_size_list = []\n",
    "    # first, find the which tenth power the min_size and max_size are\n",
    "    min_power = int(np.log10(min_size))\n",
    "    max_power = int(np.log10(max_size))\n",
    "    # print(f'min_power: {min_power}, max_power: {max_power}')\n",
    "    for power in range(min_power,max_power+1):\n",
    "        for i in range(1,10):\n",
    "            feature_size = i*10**power\n",
    "            if feature_size <= max_size:\n",
    "                feature_size_list.append(feature_size)\n",
    "    return feature_size_list\n",
    "\n",
    "def generate_feature_list(feature_data, feature_size):\n",
    "    feature_list = list(feature_data.columns)\n",
    "    shuffled_feature_list = np.random.permutation(feature_list)\n",
    "    shuffled_feature_list = shuffled_feature_list[:feature_size]\n",
    "    return shuffled_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global Parameters \n",
    "\n",
    "no_random_partitions = 100 \n",
    "partitition_seed = 42\n",
    "# set the random seed for the partitions\n",
    "np.random.seed(partitition_seed)\n",
    "partition_random_seed_list = list(np.random.randint(0,1000000,no_random_partitions))\n",
    "features_random_seed = 50\n",
    "np.random.seed(features_random_seed)\n",
    "feature_sizes = log_distributed_feature_size_list(1,feature_data.shape[1])\n",
    "feature_list = generate_feature_list(feature_data, feature_data.shape[1])\n",
    "\n",
    "## File Parameters \n",
    "run_id = 'ccle_pal_1'\n",
    "project_folder_name = 'SYVALID'\n",
    "folder_name = \"AN01_curse_of_dimensionality\"\n",
    "if not os.path.exists(f'{path_loader.get_data_path()}data/results/{project_folder_name}'):\n",
    "    os.makedirs(f'{path_loader.get_data_path()}data/results/{project_folder_name}')\n",
    "    \n",
    "if not os.path.exists(f'{path_loader.get_data_path()}data/results/{project_folder_name}/{folder_name}'):\n",
    "    os.makedirs(f'{path_loader.get_data_path()}data/results/{project_folder_name}/{folder_name}')\n",
    "\n",
    "file_save_path = f'{path_loader.get_data_path()}data/results/{project_folder_name}/{folder_name}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from toolkit import *\n",
    "\n",
    "def pipeline_func(X_train, y_train, rng, feature_data, label_data, pre_selected_features, feature_size, max_iter, **kwargs):\n",
    "    # NOTE: X_train, y_train are not used in this function\n",
    "\n",
    "    model = LinearSVR(max_iter=max_iter, random_state=rng)\n",
    "    # print(f'Feature size: {feature_size}')\n",
    "    if feature_size == feature_data.shape[1]:\n",
    "        selected_features = feature_data.columns\n",
    "        X_selected = feature_data\n",
    "    else:\n",
    "        selected_features = pre_selected_features[:feature_size]\n",
    "        X_selected = feature_data[selected_features]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, label_data, test_size=0.2, random_state=rng)\n",
    "    # print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')\n",
    "    model.fit(X_train, y_train)\n",
    "    # print('Model fitted')\n",
    "    return {'model': model,\n",
    "            'selected_features': selected_features,\n",
    "            'feature_size': feature_size,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test\n",
    "            }\n",
    "    \n",
    "def eval_func(X_test, y_test, pipeline_components=None, save_model=False, **kwargs):\n",
    "    \n",
    "    # NOTE: override the X_test, y_test with the ones from pipeline_components\n",
    "    X_test = pipeline_components['X_test']\n",
    "    y_test = pipeline_components['y_test']\n",
    "    # print(f'X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n",
    "    selected_features, X_selected = select_preset_features(X_test, y_test, pipeline_components['selected_features'])\n",
    "    y_pred = pipeline_components['model'].predict(X_selected)\n",
    "    # print(f'y_pred shape: {y_pred.shape}')\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test, y_pred)\n",
    "\n",
    "    # print(f'Correlation: {corr}')\n",
    "    returned_data = {'model_performance': corr, \n",
    "                     'feature_importance': None, ### DO NOT GET RID \n",
    "                     'p_vals': p_vals,\n",
    "                     'selected_features': selected_features,\n",
    "                     'feature_size' : pipeline_components['feature_size']\n",
    "    }\n",
    "    if save_model:\n",
    "        returned_data['model'] = pipeline_components['model']\n",
    "    return returned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Debugging revealed the LinearSVR is substantially faster than SVR with the linear kernal (both implemented by sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVR(max_iter=10000)\n",
    "feature_size = X.shape[1]\n",
    "feature_data = X\n",
    "label_data = y\n",
    "print(f'Feature size: {feature_size}')\n",
    "if feature_size == feature_data.shape[1]:\n",
    "    selected_features = feature_data.columns\n",
    "    X_selected = feature_data\n",
    "    print(f'All features selected')\n",
    "else:\n",
    "    selected_features = feature_list[:feature_size]\n",
    "    X_selected = feature_data[selected_features]\n",
    "    print(f'Randomly selected features')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, label_data, test_size=0.2, random_state=1)\n",
    "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')\n",
    "model.fit(X_train, y_train)\n",
    "print('Model fitted')\n",
    "\n",
    "selected_features, X_selected = select_preset_features(X_test, y_test, selected_features)\n",
    "y_pred = model.predict(X_selected)\n",
    "print(f'y_pred shape: {y_pred.shape}')\n",
    "# assess performance by pearson correlation\n",
    "corr, p_vals = pearsonr(y_test, y_pred)\n",
    "\n",
    "print(f'Correlation: {corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on Mock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerkit = Powerkit(X,y)\n",
    "\n",
    "# add conditions based on feature size \n",
    "\n",
    "for feature_size in feature_sizes:\n",
    "    powerkit.add_condition(str(feature_size), False, \n",
    "                           pipeline_func, \n",
    "                           {\n",
    "                            \"feature_data\": X,\n",
    "                            \"label_data\": y,\n",
    "                            \"pre_selected_features\": feature_list, \n",
    "                            \"feature_size\": feature_size,\n",
    "                            \"max_iter\": 10000\n",
    "                           },\n",
    "                           eval_func, \n",
    "                           {}\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_dfs = []\n",
    "for feature_size in tqdm(feature_sizes):\n",
    "    df = powerkit.run_selected_condition(str(feature_size), partition_random_seed_list, 16, False)\n",
    "    all_dfs.append(df)\n",
    "    \n",
    "final_df = pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# change plot size \n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(data=final_df, x='condition', y='model_performance')\n",
    "plt.title(f'{run_id} Curse of Dimensionality and Optimal Feature Size', fontsize=18)\n",
    "# xlabel and ylabel, increase font size1\n",
    "plt.xlabel('Feature Size', fontsize=16)\n",
    "plt.ylabel('Model Performance', fontsize=16)\n",
    "# rotate x-axis labels\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock Data Save Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f'{file_save_path}{run_id}_curse_of_dimensionality.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on CCLE Palbociclib Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerkit = Powerkit(feature_data, label_data)\n",
    "\n",
    "# add conditions based on feature size \n",
    "\n",
    "for feature_size in feature_sizes:\n",
    "    powerkit.add_condition(str(feature_size), False, \n",
    "                           pipeline_func, \n",
    "                           {\n",
    "                            \"feature_data\": feature_data,\n",
    "                            \"label_data\": label_data,\n",
    "                            \"pre_selected_features\": feature_list, \n",
    "                            \"feature_size\": feature_size,\n",
    "                            \"max_iter\": 10000\n",
    "                           },\n",
    "                           eval_func, \n",
    "                           {}\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_dfs = []\n",
    "for feature_size in tqdm(feature_sizes):\n",
    "    df = powerkit.run_selected_condition(str(feature_size), partition_random_seed_list, 16, False)\n",
    "    all_dfs.append(df)\n",
    "    \n",
    "final_df = pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# change plot size \n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(data=final_df, x='condition', y='model_performance')\n",
    "plt.title(f'{run_id} Curse of Dimensionality and Optimal Feature Size', fontsize=18)\n",
    "# xlabel and ylabel, increase font size1\n",
    "plt.xlabel('Feature Size', fontsize=16)\n",
    "plt.ylabel('Model Performance', fontsize=16)\n",
    "# rotate x-axis labels\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Figure and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f'{file_save_path}{run_id}_curse_of_dimensionality.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_pickle(f'{file_save_path}{run_id}_curse_of_dimensionality.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SY's Rudimentary Pipeline Logic\n",
    "\n",
    "Whole data --> Preprocessing --> Feature Selection --> Splitting --> Fitting\n",
    "\n",
    "This is a fundamentally different process from the current Powerkit protocol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Selecting the top 100 features in the data')\n",
    "\n",
    "from toolkit import *\n",
    "\n",
    "selected_features, scores = f_regression_select(feature_data, label_data, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR(kernel='linear')\n",
    "selected_features, X_selected = select_preset_features(feature_data, label_data, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# pearson correlation from scipy \n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "pearson_corr, p_vals = pearsonr(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Pearson Correlation: {pearson_corr}, p-value: {p_vals}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Greedy Forward Select, but without resetting the model and report the internal validation scores \n",
    "\n",
    "print('Greedy Forward Selecting the top 20 features in the data')\n",
    "\n",
    "start_feature = selected_features[0]\n",
    "\n",
    "selected_features, scores, model = greedy_feedforward_select_sy(X_selected, label_data,\n",
    "                                                                k=20, \n",
    "                                                                model=model, \n",
    "                                                                start_feature=start_feature, \n",
    "                                                                cv=5,\n",
    "                                                                verbose=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

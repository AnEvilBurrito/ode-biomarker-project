{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sungyoung Internal Validation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data..\n",
      "Data loaded for code ccle-gdsc-2-Palbociclib-LN_IC50\n"
     ]
    }
   ],
   "source": [
    "from PathLoader import PathLoader\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "from DataLink import DataLink\n",
    "data_link = DataLink(path_loader, 'data_codes.csv')\n",
    "\n",
    "print('Loading data..')\n",
    "\n",
    "loading_code = 'ccle-gdsc-2-Palbociclib-LN_IC50'\n",
    "feature_data, label_data = data_link.get_data_using_code(loading_code)\n",
    "print(f'Data loaded for code {loading_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=500, noise=0.1)\n",
    "# make X,y into dataframes\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SY's Valiadtion Method for Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions \n",
    "\n",
    "def log_distributed_feature_size_list(min_size,max_size):\n",
    "    # log distributed feature size list\n",
    "    feature_size_list = []\n",
    "    # first, find the which tenth power the min_size and max_size are\n",
    "    min_power = int(np.log10(min_size))\n",
    "    max_power = int(np.log10(max_size))\n",
    "    # print(f'min_power: {min_power}, max_power: {max_power}')\n",
    "    for power in range(min_power,max_power+1):\n",
    "        for i in range(1,10):\n",
    "            feature_size = i*10**power\n",
    "            if feature_size <= max_size:\n",
    "                feature_size_list.append(feature_size)\n",
    "    return feature_size_list\n",
    "\n",
    "def generate_feature_list(feature_data, feature_size):\n",
    "    features = feature_data.columns\n",
    "    feature_list = []\n",
    "    # randomly select feature_size number of features\n",
    "    for i in range(feature_size):\n",
    "        while True:\n",
    "            # ensure that the same feature is not selected twice\n",
    "            feature = np.random.choice(features)\n",
    "            if feature not in feature_list:\n",
    "                feature_list.append(feature)\n",
    "                break\n",
    "            \n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global Parameters \n",
    "\n",
    "no_random_partitions = 100 \n",
    "partition_random_seed_list = [i for i in range(no_random_partitions)]\n",
    "features_random_seed = 42\n",
    "feature_sizes = log_distributed_feature_size_list(1,X.shape[1])\n",
    "feature_list = generate_feature_list(X, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from toolkit import *\n",
    "\n",
    "def pipeline_func(X_train, y_train, rng, feature_data, label_data, pre_selected_features, feature_size, **kwargs):\n",
    "    # NOTE: X_train, y_train are not used in this function\n",
    "\n",
    "    model = SVR(kernel='linear')\n",
    "    X_selected = feature_data[pre_selected_features[:feature_size]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, label_data, test_size=0.2, random_state=rng)\n",
    "    model.fit(X_train, y_train)\n",
    "    return {'model': model,\n",
    "            'selected_features': pre_selected_features[:feature_size],\n",
    "            'feature_size': feature_size,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test\n",
    "            }\n",
    "    \n",
    "def eval_func(X_test, y_test, pipeline_components=None, save_model=False, **kwargs):\n",
    "    \n",
    "    # NOTE: override the X_test, y_test with the ones from pipeline_components\n",
    "    X_test = pipeline_components['X_test']\n",
    "    y_test = pipeline_components['y_test']\n",
    "    \n",
    "    selected_features, X_selected = select_preset_features(X_test, y_test, pipeline_components['selected_features'])\n",
    "    y_pred = pipeline_components['model'].predict(X_selected)\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test, y_pred)\n",
    "\n",
    "    returned_data = {'model_performance': corr, \n",
    "                     'feature_importance': None, ### DO NOT GET RID \n",
    "                     'p_vals': p_vals,\n",
    "                     'selected_features': selected_features,\n",
    "                     'feature_size' : pipeline_components['feature_size']\n",
    "    }\n",
    "    if save_model:\n",
    "        returned_data['model'] = pipeline_components['model']\n",
    "    return returned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on Mock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerkit = Powerkit(X,y)\n",
    "\n",
    "# add conditions based on feature size \n",
    "\n",
    "for feature_size in feature_sizes:\n",
    "    powerkit.add_condition(str(feature_size), False, \n",
    "                           pipeline_func, \n",
    "                           {\n",
    "                            \"feature_data\": X,\n",
    "                            \"label_data\": y,\n",
    "                            \"pre_selected_features\": feature_list, \n",
    "                            \"feature_size\": feature_size\n",
    "                           },\n",
    "                           eval_func, \n",
    "                           {}\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [02:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpowerkit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_conditions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition_random_seed_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:309\u001b[0m, in \u001b[0;36mPowerkit.run_all_conditions\u001b[1;34m(self, rng_list, n_jobs, verbose)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_all_conditions\u001b[39m(\u001b[38;5;28mself\u001b[39m, rng_list: \u001b[38;5;28mlist\u001b[39m, n_jobs: \u001b[38;5;28mint\u001b[39m, verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 309\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_abstract_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:281\u001b[0m, in \u001b[0;36mPowerkit._abstract_run\u001b[1;34m(self, rng_list, n_jobs, verbose, conditions)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rng \u001b[38;5;129;01min\u001b[39;00m tqdm(rng_list):\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m condition \u001b[38;5;129;01min\u001b[39;00m conditions:\n\u001b[1;32m--> 281\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_abstract_run_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcondition_to_get_feature_importance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpipeline_function\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpipeline_args\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_function\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_args\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m             data_collector\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# use joblib to parallelize the process, disable verbose printing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:261\u001b[0m, in \u001b[0;36mPowerkit._abstract_run_single\u001b[1;34m(self, condition, condition_to_get_feature_importance, rng, pipeline_function, pipeline_args, eval_function, eval_args, verbose)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# split the data and go through the pipeline\u001b[39;00m\n\u001b[0;32m    260\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_split_size, random_state\u001b[38;5;241m=\u001b[39mrng)\n\u001b[1;32m--> 261\u001b[0m pipeline_comps \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpipeline_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m eval_returns \u001b[38;5;241m=\u001b[39m eval_function(X_test, y_test, pipeline_components\u001b[38;5;241m=\u001b[39mpipeline_comps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meval_args)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# update the final returns\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mpipeline_func\u001b[1;34m(X_train, y_train, rng, feature_data, label_data, pre_selected_features, feature_size, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m X_selected \u001b[38;5;241m=\u001b[39m feature_data[pre_selected_features[:feature_size]]\n\u001b[0;32m     11\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_selected, label_data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrng)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model,\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_features\u001b[39m\u001b[38;5;124m'\u001b[39m: pre_selected_features[:feature_size],\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_size\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_size,\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test\u001b[39m\u001b[38;5;124m'\u001b[39m: X_test,\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m: y_test\n\u001b[0;32m     18\u001b[0m         }\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 252\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    317\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    321\u001b[0m (\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 331\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "File \u001b[1;32msklearn\\svm\\_libsvm.pyx:236\u001b[0m, in \u001b[0;36msklearn.svm._libsvm.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "powerkit.run_all_conditions(partition_random_seed_list, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SY's Rudimentary Pipeline Logic\n",
    "\n",
    "Whole data --> Preprocessing --> Feature Selection --> Splitting --> Fitting\n",
    "\n",
    "This is a fundamentally different process from the current Powerkit protocol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting the top 100 features in the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "print('Selecting the top 100 features in the data')\n",
    "\n",
    "from toolkit import *\n",
    "\n",
    "selected_features, scores = f_regression_select(feature_data, label_data, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR(kernel='linear')\n",
    "selected_features, X_selected = select_preset_features(feature_data, label_data, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.3432940622273413\n",
      "Pearson Correlation: 0.4649029418773342, p-value: 1.2870656256712425e-07\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# pearson correlation from scipy \n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "pearson_corr, p_vals = pearsonr(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Pearson Correlation: {pearson_corr}, p-value: {p_vals}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Forward Selecting the top 20 features in the data\n",
      "Feature Selected: RPL3, Score: 0.552636050749855, Feature Size: 2\n",
      "Feature Selected: PPIC, Score: 0.5927602111000807, Feature Size: 3\n",
      "Feature Selected: SETDB2, Score: 0.6098624819706714, Feature Size: 4\n",
      "Feature Selected: BAIAP2, Score: 0.6223589576710935, Feature Size: 5\n",
      "Feature Selected: TUFT1, Score: 0.6289724594011268, Feature Size: 6\n",
      "Feature Selected: SNX21, Score: 0.6389793248636391, Feature Size: 7\n",
      "Feature Selected: GMFG, Score: 0.6397582885947983, Feature Size: 8\n",
      "Feature Selected: ITGAL, Score: 0.6400193045732537, Feature Size: 9\n",
      "Feature Selected: NCKAP1, Score: 0.642028397388853, Feature Size: 10\n",
      "Feature Selected: TESPA1, Score: 0.6439144344847202, Feature Size: 11\n",
      "Feature Selected: SLC49A4, Score: 0.6441354794630852, Feature Size: 12\n",
      "Feature Selected: ITGB5, Score: 0.6494810956678634, Feature Size: 13\n",
      "Feature Selected: SNX24, Score: 0.6512696720556639, Feature Size: 14\n",
      "Feature Selected: TNFRSF12A, Score: 0.6531007351758524, Feature Size: 15\n",
      "Feature Selected: SDC4, Score: 0.6571784005388024, Feature Size: 16\n",
      "Feature Selected: EGFR, Score: 0.657360934232831, Feature Size: 17\n",
      "Feature Selected: RASAL2, Score: 0.6577709910332427, Feature Size: 18\n",
      "Feature Selected: ARHGAP15, Score: 0.6573203738066695, Feature Size: 19\n",
      "Feature Selected: CTTN, Score: 0.6564965325818154, Feature Size: 20\n"
     ]
    }
   ],
   "source": [
    "### Greedy Forward Select, but without resetting the model and report the internal validation scores \n",
    "\n",
    "print('Greedy Forward Selecting the top 20 features in the data')\n",
    "\n",
    "start_feature = selected_features[0]\n",
    "\n",
    "selected_features, scores, model = greedy_feedforward_select_sy(X_selected, label_data,\n",
    "                                                                k=20, \n",
    "                                                                model=model, \n",
    "                                                                start_feature=start_feature, \n",
    "                                                                cv=5,\n",
    "                                                                verbose=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch # type: ignore\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(torch.__version__)\n",
    "    # Setup device agnostic code\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0708, -0.0851,  0.0290,  ...,  0.0032, -0.0527,  0.0193],\n",
      "        [ 0.0232, -0.0486,  0.0378,  ..., -0.0408,  0.0732, -0.0149],\n",
      "        [ 0.0373,  0.0352, -0.0231,  ...,  0.0403, -0.0399, -0.0527],\n",
      "        ...,\n",
      "        [ 0.0759,  0.0617, -0.0757,  ..., -0.0038,  0.0693, -0.0414],\n",
      "        [-0.0157,  0.0224,  0.0283,  ...,  0.0580, -0.0439,  0.0638],\n",
      "        [ 0.0731, -0.0434,  0.0294,  ...,  0.0854,  0.0757, -0.0095]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0284,  0.0284, -0.0258, -0.0305,  0.0641, -0.0005,  0.0453,  0.0070,\n",
      "         0.0833, -0.0531,  0.0888, -0.0586,  0.0956, -0.0037, -0.0676, -0.0806,\n",
      "        -0.0609,  0.0648,  0.0021,  0.0681,  0.0767, -0.0044, -0.0067,  0.0731,\n",
      "         0.0454,  0.0395, -0.0641, -0.0912,  0.0140, -0.0568, -0.0939, -0.0051,\n",
      "         0.0756,  0.0050, -0.0717,  0.0632,  0.0177,  0.0138, -0.0406,  0.0170,\n",
      "        -0.0959, -0.0203, -0.0078,  0.0365, -0.0981, -0.0395,  0.0467, -0.0873,\n",
      "        -0.0342, -0.0776, -0.0355, -0.0841,  0.0061, -0.0282,  0.0018, -0.0472,\n",
      "        -0.0763,  0.0441,  0.0852,  0.0774,  0.0094, -0.0123,  0.0631, -0.0658,\n",
      "        -0.0384,  0.0006, -0.0887,  0.0152,  0.0934,  0.0272,  0.0419,  0.0009,\n",
      "        -0.0907, -0.0319, -0.0144, -0.0005,  0.0460,  0.0455, -0.0112,  0.0319,\n",
      "        -0.0009,  0.0643, -0.0656, -0.0890, -0.0704, -0.0590, -0.0295, -0.0071,\n",
      "        -0.0105, -0.0552,  0.0350,  0.0106, -0.0320, -0.0064, -0.0524, -0.0217,\n",
      "        -0.0645, -0.0522,  0.0976, -0.0039, -0.0869, -0.0851, -0.0652, -0.0698,\n",
      "         0.0653,  0.0457,  0.0802, -0.0095,  0.0579, -0.0125,  0.0063,  0.0386,\n",
      "         0.0497, -0.0058,  0.0897,  0.0348, -0.0947, -0.0038,  0.0013,  0.0470,\n",
      "         0.0084, -0.0504, -0.0748,  0.0535,  0.0177, -0.0971,  0.0726, -0.0070,\n",
      "        -0.0394, -0.0832,  0.0039, -0.0690, -0.0998,  0.0650,  0.0278,  0.0267,\n",
      "         0.0512, -0.0406,  0.0506, -0.0710,  0.0896, -0.0404,  0.0069, -0.0571,\n",
      "        -0.0271, -0.0411, -0.0832, -0.0431,  0.0977, -0.0766,  0.0167, -0.0643,\n",
      "        -0.0868, -0.0759,  0.0104,  0.0252, -0.0801, -0.0982,  0.0414, -0.0051,\n",
      "         0.0555,  0.0296, -0.0245, -0.0316,  0.0045, -0.0518,  0.0463,  0.0751,\n",
      "         0.0282,  0.0047, -0.0828, -0.0366, -0.0879,  0.0096,  0.0378, -0.0365,\n",
      "        -0.0599,  0.0669,  0.0383,  0.0807,  0.0102,  0.0479,  0.0413, -0.0261,\n",
      "         0.0133,  0.0100,  0.0145,  0.0266,  0.0228,  0.0326, -0.0780,  0.0930,\n",
      "         0.0932,  0.0865,  0.0549,  0.0771,  0.0433,  0.0300, -0.0436,  0.0841],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0098,  0.0603,  0.0274,  ...,  0.0313, -0.0629,  0.0301],\n",
      "        [-0.0565, -0.0422, -0.0081,  ..., -0.0318, -0.0574,  0.0583],\n",
      "        [ 0.0701,  0.0536, -0.0513,  ..., -0.0036,  0.0112, -0.0681],\n",
      "        ...,\n",
      "        [ 0.0375,  0.0088, -0.0568,  ...,  0.0168,  0.0314,  0.0253],\n",
      "        [-0.0630,  0.0016, -0.0097,  ...,  0.0146,  0.0198,  0.0534],\n",
      "        [-0.0331, -0.0421,  0.0513,  ..., -0.0404, -0.0050,  0.0576]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0356,  0.0365,  0.0318, -0.0482,  0.0087,  0.0496, -0.0403,  0.0545,\n",
      "        -0.0642, -0.0372], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0098,  0.0603,  0.0274,  ...,  0.0313, -0.0629,  0.0301],\n",
      "        [-0.0565, -0.0422, -0.0081,  ..., -0.0318, -0.0574,  0.0583],\n",
      "        [ 0.0701,  0.0536, -0.0513,  ..., -0.0036,  0.0112, -0.0681],\n",
      "        ...,\n",
      "        [ 0.0375,  0.0088, -0.0568,  ...,  0.0168,  0.0314,  0.0253],\n",
      "        [-0.0630,  0.0016, -0.0097,  ...,  0.0146,  0.0198,  0.0534],\n",
      "        [-0.0331, -0.0421,  0.0513,  ..., -0.0404, -0.0050,  0.0576]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0356,  0.0365,  0.0318, -0.0482,  0.0087,  0.0496, -0.0403,  0.0545,\n",
      "        -0.0642, -0.0372], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn  # type: ignore\n",
    "import torch.nn.functional as F # type: ignore\n",
    "\n",
    "\n",
    "class MySmallModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MySmallModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.network1 = MySmallModel()\n",
    "        self.network2 = MySmallModel()\n",
    "        self.network3 = MySmallModel()\n",
    "\n",
    "        self.fc1 = nn.Linear(3, 2)\n",
    "        self.fc_out = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        x1 = F.relu(self.network1(x1))\n",
    "        x2 = F.relu(self.network2(x2))\n",
    "        x3 = F.relu(self.network3(x3))\n",
    "\n",
    "        x = torch.cat((x1, x2, x3), 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "N = 10\n",
    "x1, x2, x3 = torch.randn(N, 5), torch.randn(N, 5), torch.randn(N, 5)\n",
    "\n",
    "output = model(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Model Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterisation of Feature Size and Group Feature Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2135],\n",
      "        [-0.1285],\n",
      "        [-0.2141],\n",
      "        [-0.1349],\n",
      "        [-0.0851],\n",
      "        [-0.0523],\n",
      "        [-0.2534],\n",
      "        [-0.2638],\n",
      "        [-0.0889],\n",
      "        [-0.2055]], grad_fn=<AddmmBackward0>)\n",
      "TorchModel(\n",
      "  (group_layers): ModuleList(\n",
      "    (0-25): 26 x GroupLayer(\n",
      "      (fc1): Linear(in_features=10, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=26, out_features=13, bias=True)\n",
      "  (fc_out): Linear(in_features=13, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GroupLayer(nn.Module):\n",
    "    def __init__(self, group_feat_size: int):\n",
    "        super(GroupLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(group_feat_size, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x \n",
    "\n",
    "class TorchModel(nn.Module):\n",
    "    def __init__(self, group_feat_size: int, total_feat_size: int):\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.group_feat_size = group_feat_size\n",
    "        self.total_feat_size = total_feat_size\n",
    "        num_groups = self.total_feat_size // self.group_feat_size\n",
    "        # if num_groups not an integer, throw error\n",
    "        if num_groups != self.total_feat_size / self.group_feat_size:\n",
    "            raise ValueError(\"Total feature size must be divisible by group feature size\")\n",
    "        \n",
    "        self.num_groups = num_groups\n",
    "        self.group_layers = nn.ModuleList()\n",
    "        i = 0 \n",
    "        while i < num_groups:\n",
    "            self.group_layers.append(GroupLayer(group_feat_size))\n",
    "            i += 1\n",
    "            \n",
    "        self.layer_2_size = int(num_groups / 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_groups, self.layer_2_size)\n",
    "        self.fc_out = nn.Linear(self.layer_2_size, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # print(input_data.shape)\n",
    "        xs = []\n",
    "        i = 0\n",
    "        while i < self.total_feat_size:\n",
    "            xs.append(input_data[:, i:i+self.group_feat_size])\n",
    "            i += group_feat_size\n",
    "        \n",
    "        outs = []\n",
    "        for i,x in enumerate(xs):\n",
    "            # print(i+1, x.shape)\n",
    "            outs.append(self.group_layers[i](x))\n",
    "\n",
    "        x = torch.cat(outs, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "group_feat_size = 10\n",
    "total_feat_size = 260\n",
    "\n",
    "model = TorchModel(group_feat_size, total_feat_size)\n",
    "N = 10\n",
    "x = torch.randn(N, total_feat_size)\n",
    "output = model(x)\n",
    "print(output)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimisation Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn to generate some regression data\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=10000, n_features=260, noise=0.1)\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train_dl = DataLoader(list(zip(X_train, y_train)), batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(list(zip(X_test, y_test)), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "model = TorchModel(group_feat_size, total_feat_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "\n",
    "# def train(model, train_dl, optimizer, criterion, epochs=10):\n",
    "#     running_loss = 0.0\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f\"### Epoch {epoch}\")\n",
    "#         for i, (x, y) in enumerate(train_dl):\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(x)\n",
    "#             loss = criterion(output, y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item()\n",
    "#             print(f\"Batch {i} loss: {loss.item()}\")\n",
    "            \n",
    "#     return running_loss / len(train_dl)\n",
    "                            \n",
    "\n",
    "# train(model, train_dl, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the output against the target\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# plt.scatter(y_test, output.detach().numpy())\n",
    "# plt.xlabel('True Value')\n",
    "# plt.ylabel('Predicted Value')\n",
    "# plt.title('Predicted vs True Value')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "from torch import nn  # type: ignore\n",
    "import torch.nn.functional as F  # type: ignore\n",
    "\n",
    "class GroupLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, group_feat_size: int):\n",
    "        super(GroupLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(group_feat_size, 1).double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class TorchModel(nn.Module):\n",
    "\n",
    "    def __init__(self, group_feat_size: int, total_feat_size: int):\n",
    "\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.group_feat_size = group_feat_size\n",
    "        self.total_feat_size = total_feat_size\n",
    "\n",
    "        num_groups = self.total_feat_size // self.group_feat_size\n",
    "\n",
    "        # if num_groups not an integer, throw error\n",
    "        if num_groups != self.total_feat_size / self.group_feat_size:\n",
    "            raise ValueError(\"Total feature size must be divisible by group feature size\")\n",
    "\n",
    "        self.num_groups = num_groups\n",
    "        self.group_layers = nn.ModuleList()\n",
    "        i = 0\n",
    "        while i < num_groups:\n",
    "            self.group_layers.append(GroupLayer(group_feat_size))\n",
    "            i += 1\n",
    "        self.layer_2_size = int(num_groups / 2)\n",
    "        self.fc1 = nn.Linear(num_groups, self.layer_2_size).double()\n",
    "        self.fc_out = nn.Linear(self.layer_2_size, 1).double()\n",
    "\n",
    "\n",
    "    def forward(self, input_data):\n",
    "\n",
    "        # print(input_data.shape)\n",
    "\n",
    "        xs = []\n",
    "        i = 0\n",
    "        while i < self.total_feat_size:\n",
    "            xs.append(input_data[:, i:i+self.group_feat_size])\n",
    "            i += group_feat_size\n",
    "\n",
    "\n",
    "        outs = []\n",
    "        for i, x in enumerate(xs):\n",
    "            # print(i+1, x.shape)\n",
    "            outs.append(self.group_layers[i](x))\n",
    "\n",
    "\n",
    "        x = torch.cat(outs, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "group_feat_size = 10\n",
    "total_feat_size = 260\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    TorchModel,\n",
    "    module__group_feat_size=group_feat_size,\n",
    "    module__total_feat_size=total_feat_size,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=torch.nn.MSELoss,\n",
    "    max_epochs=20,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=2000, n_features=260, noise=0.01)\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m36538.5951\u001b[0m    \u001b[32m30354.4184\u001b[0m  0.2810\n",
      "      2    \u001b[36m36533.6516\u001b[0m    \u001b[32m30353.1917\u001b[0m  0.2420\n",
      "      3    \u001b[36m36528.3852\u001b[0m    \u001b[32m30350.3127\u001b[0m  0.2340\n",
      "      4    \u001b[36m36519.5394\u001b[0m    \u001b[32m30346.8352\u001b[0m  0.2270\n",
      "      5    \u001b[36m36506.7564\u001b[0m    \u001b[32m30339.8095\u001b[0m  0.2300\n",
      "      6    \u001b[36m36483.1964\u001b[0m    \u001b[32m30326.1093\u001b[0m  0.2260\n",
      "      7    \u001b[36m36442.3965\u001b[0m    \u001b[32m30300.9058\u001b[0m  0.2287\n",
      "      8    \u001b[36m36373.7734\u001b[0m    \u001b[32m30250.7520\u001b[0m  0.2210\n",
      "      9    \u001b[36m36253.8789\u001b[0m    \u001b[32m30159.9985\u001b[0m  0.2340\n",
      "     10    \u001b[36m36048.8307\u001b[0m    \u001b[32m30005.9318\u001b[0m  0.2310\n",
      "     11    \u001b[36m35733.6286\u001b[0m    \u001b[32m29758.5801\u001b[0m  0.2420\n",
      "     12    \u001b[36m35277.7611\u001b[0m    \u001b[32m29411.6200\u001b[0m  0.2330\n",
      "     13    \u001b[36m34664.7881\u001b[0m    \u001b[32m28955.0099\u001b[0m  0.2320\n",
      "     14    \u001b[36m33879.7537\u001b[0m    \u001b[32m28352.6917\u001b[0m  0.2270\n",
      "     15    \u001b[36m32897.6194\u001b[0m    \u001b[32m27620.7411\u001b[0m  0.2228\n",
      "     16    \u001b[36m31736.0332\u001b[0m    \u001b[32m26750.7767\u001b[0m  0.2350\n",
      "     17    \u001b[36m30372.7937\u001b[0m    \u001b[32m25785.9721\u001b[0m  0.2270\n",
      "     18    \u001b[36m28853.6752\u001b[0m    \u001b[32m24630.6073\u001b[0m  0.2240\n",
      "     19    \u001b[36m27153.0052\u001b[0m    \u001b[32m23415.5359\u001b[0m  0.2270\n",
      "     20    \u001b[36m25371.6254\u001b[0m    \u001b[32m22117.3457\u001b[0m  0.2370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=TorchModel(\n",
       "    (group_layers): ModuleList(\n",
       "      (0-25): 26 x GroupLayer(\n",
       "        (fc1): Linear(in_features=10, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (fc1): Linear(in_features=26, out_features=13, bias=True)\n",
       "    (fc_out): Linear(in_features=13, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make prediction \n",
    "\n",
    "y_pred = net.predict(X_test)\n",
    "\n",
    "# plot the output against the target\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.title('Predicted vs True Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.7669682676823475\n"
     ]
    }
   ],
   "source": [
    "# test pearson correlation \n",
    "\n",
    "# calculate pearson correlation\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr, _ = pearsonr(y_test.flatten(), y_pred.flatten())\n",
    "\n",
    "print(f'Pearsons correlation: {corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n",
    "# Bring in CCLE data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader\n",
    "from DataLink import DataLink\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "data_link = DataLink(path_loader, 'data_codes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in original ccle data\n",
    "loading_code = 'generic-gdsc-1-FGFR_0939-LN_IC50-fgfr4_ccle_dynamic_features_v2-true-Unnamed: 0'\n",
    "# generic-gdsc-{number}-{drug_name}-{target_label}-{dataset_name}-{replace_index}-{row_index}\n",
    "feature_data, label_data = data_link.get_data_using_code(loading_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pIGFR_auc</th>\n",
       "      <th>pIGFR_median</th>\n",
       "      <th>pIGFR_tfc</th>\n",
       "      <th>pIGFR_tmax</th>\n",
       "      <th>pIGFR_max</th>\n",
       "      <th>pIGFR_tmin</th>\n",
       "      <th>pIGFR_min</th>\n",
       "      <th>pIGFR_ttsv</th>\n",
       "      <th>pIGFR_tsv</th>\n",
       "      <th>pIGFR_init</th>\n",
       "      <th>...</th>\n",
       "      <th>amTORC2_auc</th>\n",
       "      <th>amTORC2_median</th>\n",
       "      <th>amTORC2_tfc</th>\n",
       "      <th>amTORC2_tmax</th>\n",
       "      <th>amTORC2_max</th>\n",
       "      <th>amTORC2_tmin</th>\n",
       "      <th>amTORC2_min</th>\n",
       "      <th>amTORC2_ttsv</th>\n",
       "      <th>amTORC2_tsv</th>\n",
       "      <th>amTORC2_init</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SIDM01085</th>\n",
       "      <td>0.019410</td>\n",
       "      <td>0.021032</td>\n",
       "      <td>4.682872</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.032885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>5.486629</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00949</th>\n",
       "      <td>0.077292</td>\n",
       "      <td>0.084704</td>\n",
       "      <td>9.089875</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.140803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218305</td>\n",
       "      <td>0.226915</td>\n",
       "      <td>0.364546</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.264206</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.193622</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.193622</td>\n",
       "      <td>0.193622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00494</th>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>3.560627</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.015136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>0.020458</td>\n",
       "      <td>0.403167</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.024825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>0.017692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00377</th>\n",
       "      <td>0.036978</td>\n",
       "      <td>0.039602</td>\n",
       "      <td>5.138051</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.065341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>1.189183</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00988</th>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.030932</td>\n",
       "      <td>8.449997</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.039991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.465354</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.008079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00697</th>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>9.576674</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.024837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.539425</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM01188</th>\n",
       "      <td>0.032034</td>\n",
       "      <td>0.036092</td>\n",
       "      <td>11.164995</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140425</td>\n",
       "      <td>0.146074</td>\n",
       "      <td>0.332654</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.167943</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.126022</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.126022</td>\n",
       "      <td>0.126022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00999</th>\n",
       "      <td>0.015288</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>5.579325</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>4.879114</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00149</th>\n",
       "      <td>0.078582</td>\n",
       "      <td>0.089001</td>\n",
       "      <td>14.430451</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.135102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142652</td>\n",
       "      <td>0.147998</td>\n",
       "      <td>0.297572</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.170342</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.131277</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.131277</td>\n",
       "      <td>0.131277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00848</th>\n",
       "      <td>0.031927</td>\n",
       "      <td>0.037403</td>\n",
       "      <td>11.575419</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.053087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463970</td>\n",
       "      <td>0.483035</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.544116</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.424736</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.424736</td>\n",
       "      <td>0.424736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pIGFR_auc  pIGFR_median  pIGFR_tfc  pIGFR_tmax  pIGFR_max  \\\n",
       "SIDM01085   0.019410      0.021032   4.682872        0.96   0.032885   \n",
       "SIDM00949   0.077292      0.084704   9.089875        0.96   0.140803   \n",
       "SIDM00494   0.010086      0.011210   3.560627        0.96   0.015136   \n",
       "SIDM00377   0.036978      0.039602   5.138051        0.96   0.065341   \n",
       "SIDM00988   0.027368      0.030932   8.449997        0.96   0.039991   \n",
       "...              ...           ...        ...         ...        ...   \n",
       "SIDM00697   0.013521      0.014763   9.576674        0.96   0.024837   \n",
       "SIDM01188   0.032034      0.036092  11.164995        0.96   0.056863   \n",
       "SIDM00999   0.015288      0.016662   5.579325        0.96   0.026040   \n",
       "SIDM00149   0.078582      0.089001  14.430451        0.96   0.135102   \n",
       "SIDM00848   0.031927      0.037403  11.575419        0.96   0.053087   \n",
       "\n",
       "           pIGFR_tmin  pIGFR_min  pIGFR_ttsv  pIGFR_tsv  pIGFR_init  ...  \\\n",
       "SIDM01085         0.0   0.005787        0.04   0.005787    0.005787  ...   \n",
       "SIDM00949         0.0   0.013955        0.04   0.013955    0.013955  ...   \n",
       "SIDM00494         0.0   0.003319        0.04   0.003319    0.003319  ...   \n",
       "SIDM00377         0.0   0.010645        0.04   0.010645    0.010645  ...   \n",
       "SIDM00988         0.0   0.004232        0.04   0.004232    0.004232  ...   \n",
       "...               ...        ...         ...        ...         ...  ...   \n",
       "SIDM00697         0.0   0.002348        0.04   0.002348    0.002348  ...   \n",
       "SIDM01188         0.0   0.004674        0.04   0.004674    0.004674  ...   \n",
       "SIDM00999         0.0   0.003958        0.04   0.003958    0.003958  ...   \n",
       "SIDM00149         0.0   0.008756        0.04   0.008756    0.008756  ...   \n",
       "SIDM00848         0.0   0.004222        0.04   0.004222    0.004222  ...   \n",
       "\n",
       "           amTORC2_auc  amTORC2_median  amTORC2_tfc  amTORC2_tmax  \\\n",
       "SIDM01085     0.001717        0.001599     5.486629          0.96   \n",
       "SIDM00949     0.218305        0.226915     0.364546          0.96   \n",
       "SIDM00494     0.019850        0.020458     0.403167          0.96   \n",
       "SIDM00377     0.000361        0.000332     1.189183          0.96   \n",
       "SIDM00988     0.008990        0.009058     0.465354          0.96   \n",
       "...                ...             ...          ...           ...   \n",
       "SIDM00697     0.000116        0.000116     0.539425          0.96   \n",
       "SIDM01188     0.140425        0.146074     0.332654          0.96   \n",
       "SIDM00999     0.002991        0.002788     4.879114          0.96   \n",
       "SIDM00149     0.142652        0.147998     0.297572          0.96   \n",
       "SIDM00848     0.463970        0.483035     0.281069          0.96   \n",
       "\n",
       "           amTORC2_max  amTORC2_tmin  amTORC2_min  amTORC2_ttsv  amTORC2_tsv  \\\n",
       "SIDM01085     0.003834          0.00     0.000591          0.04     0.000591   \n",
       "SIDM00949     0.264206          0.00     0.193622          0.04     0.193622   \n",
       "SIDM00494     0.024825          0.00     0.017692          0.04     0.017692   \n",
       "SIDM00377     0.000639          0.00     0.000292          0.04     0.000292   \n",
       "SIDM00988     0.011839          0.08     0.008078          0.04     0.008079   \n",
       "...                ...           ...          ...           ...          ...   \n",
       "SIDM00697     0.000160          0.00     0.000104          0.04     0.000104   \n",
       "SIDM01188     0.167943          0.00     0.126022          0.04     0.126022   \n",
       "SIDM00999     0.006578          0.00     0.001119          0.04     0.001119   \n",
       "SIDM00149     0.170342          0.00     0.131277          0.04     0.131277   \n",
       "SIDM00848     0.544116          0.00     0.424736          0.04     0.424736   \n",
       "\n",
       "           amTORC2_init  \n",
       "SIDM01085      0.000591  \n",
       "SIDM00949      0.193622  \n",
       "SIDM00494      0.017692  \n",
       "SIDM00377      0.000292  \n",
       "SIDM00988      0.008079  \n",
       "...                 ...  \n",
       "SIDM00697      0.000104  \n",
       "SIDM01188      0.126022  \n",
       "SIDM00999      0.001119  \n",
       "SIDM00149      0.131277  \n",
       "SIDM00848      0.424736  \n",
       "\n",
       "[665 rows x 260 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "feature_data_numpy = feature_data.to_numpy()\n",
    "label_data_numpy = label_data.to_numpy()\n",
    "label_data_numpy = label_data_numpy.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 260)\n",
      "(665, 1)\n"
     ]
    }
   ],
   "source": [
    "print(feature_data_numpy.shape)\n",
    "print(label_data_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on all data test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_feat_size = 10\n",
    "total_feat_size = 260\n",
    "torch.manual_seed(0)\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    TorchModel,\n",
    "    module__group_feat_size=group_feat_size,\n",
    "    module__total_feat_size=total_feat_size,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=torch.nn.MSELoss,\n",
    "    max_epochs=100,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m33053.9213\u001b[0m       \u001b[32m19.8250\u001b[0m  0.1010\n",
      "      2    \u001b[36m16931.7875\u001b[0m        \u001b[32m9.9286\u001b[0m  0.1000\n",
      "      3     \u001b[36m8757.3404\u001b[0m        \u001b[32m5.8922\u001b[0m  0.0980\n",
      "      4     \u001b[36m5343.7950\u001b[0m        \u001b[32m4.2848\u001b[0m  0.0980\n",
      "      5      \u001b[36m685.8830\u001b[0m        \u001b[32m3.6916\u001b[0m  0.1010\n",
      "      6      \u001b[36m269.8084\u001b[0m        \u001b[32m3.2345\u001b[0m  0.1100\n",
      "      7       \u001b[36m24.1567\u001b[0m        \u001b[32m3.0239\u001b[0m  0.1010\n",
      "      8        \u001b[36m2.6646\u001b[0m        \u001b[32m2.9014\u001b[0m  0.0960\n",
      "      9        \u001b[36m2.0168\u001b[0m        \u001b[32m2.7221\u001b[0m  0.1140\n",
      "     10        \u001b[36m1.8903\u001b[0m        \u001b[32m2.6328\u001b[0m  0.1020\n",
      "     11        \u001b[36m1.7704\u001b[0m        \u001b[32m2.4555\u001b[0m  0.0990\n",
      "     12        \u001b[36m1.7113\u001b[0m        \u001b[32m2.3370\u001b[0m  0.1000\n",
      "     13        \u001b[36m1.5975\u001b[0m        \u001b[32m2.2330\u001b[0m  0.0990\n",
      "     14        \u001b[36m1.5232\u001b[0m        \u001b[32m2.1889\u001b[0m  0.1090\n",
      "     15        \u001b[36m1.4965\u001b[0m        \u001b[32m2.0825\u001b[0m  0.1030\n",
      "     16        \u001b[36m1.4336\u001b[0m        \u001b[32m2.0098\u001b[0m  0.0980\n",
      "     17        \u001b[36m1.3903\u001b[0m        \u001b[32m2.0085\u001b[0m  0.1050\n",
      "     18        1.4326        \u001b[32m1.9168\u001b[0m  0.0980\n",
      "     19        1.4419        1.9309  0.0970\n",
      "     20        \u001b[36m1.3153\u001b[0m        \u001b[32m1.8412\u001b[0m  0.1010\n",
      "     21        \u001b[36m1.2874\u001b[0m        \u001b[32m1.8407\u001b[0m  0.0990\n",
      "     22        \u001b[36m1.2645\u001b[0m        \u001b[32m1.7923\u001b[0m  0.1400\n",
      "     23        \u001b[36m1.2476\u001b[0m        \u001b[32m1.7500\u001b[0m  0.1020\n",
      "     24        \u001b[36m1.2284\u001b[0m        \u001b[32m1.7234\u001b[0m  0.1000\n",
      "     25        1.2312        \u001b[32m1.6913\u001b[0m  0.1000\n",
      "     26        \u001b[36m1.1901\u001b[0m        \u001b[32m1.6828\u001b[0m  0.1000\n",
      "     27        \u001b[36m1.1713\u001b[0m        \u001b[32m1.6663\u001b[0m  0.0997\n",
      "     28        1.1721        \u001b[32m1.6426\u001b[0m  0.1000\n",
      "     29        \u001b[36m1.1477\u001b[0m        \u001b[32m1.6293\u001b[0m  0.0980\n",
      "     30        \u001b[36m1.1440\u001b[0m        \u001b[32m1.5870\u001b[0m  0.0980\n",
      "     31        \u001b[36m1.1008\u001b[0m        \u001b[32m1.5781\u001b[0m  0.0980\n",
      "     32        \u001b[36m1.0989\u001b[0m        \u001b[32m1.5682\u001b[0m  0.0980\n",
      "     33        \u001b[36m1.0874\u001b[0m        \u001b[32m1.5472\u001b[0m  0.0980\n",
      "     34        \u001b[36m1.0772\u001b[0m        \u001b[32m1.5346\u001b[0m  0.1130\n",
      "     35        \u001b[36m1.0644\u001b[0m        \u001b[32m1.5210\u001b[0m  0.1060\n",
      "     36        \u001b[36m1.0497\u001b[0m        \u001b[32m1.5069\u001b[0m  0.0990\n",
      "     37        1.0545        \u001b[32m1.4997\u001b[0m  0.0970\n",
      "     38        1.0593        \u001b[32m1.4841\u001b[0m  0.0980\n",
      "     39        \u001b[36m1.0259\u001b[0m        1.4907  0.0980\n",
      "     40        \u001b[36m1.0214\u001b[0m        \u001b[32m1.4644\u001b[0m  0.0990\n",
      "     41        \u001b[36m1.0183\u001b[0m        \u001b[32m1.4487\u001b[0m  0.0980\n",
      "     42        \u001b[36m1.0138\u001b[0m        1.5026  0.0980\n",
      "     43        1.0493        \u001b[32m1.4363\u001b[0m  0.1000\n",
      "     44        \u001b[36m0.9912\u001b[0m        \u001b[32m1.4228\u001b[0m  0.0980\n",
      "     45        1.0032        \u001b[32m1.4201\u001b[0m  0.0980\n",
      "     46        \u001b[36m0.9894\u001b[0m        \u001b[32m1.4162\u001b[0m  0.0980\n",
      "     47        0.9919        \u001b[32m1.4113\u001b[0m  0.0980\n",
      "     48        \u001b[36m0.9714\u001b[0m        \u001b[32m1.4106\u001b[0m  0.1010\n",
      "     49        \u001b[36m0.9643\u001b[0m        \u001b[32m1.3989\u001b[0m  0.0980\n",
      "     50        \u001b[36m0.9572\u001b[0m        \u001b[32m1.3981\u001b[0m  0.0960\n",
      "     51        0.9620        \u001b[32m1.3962\u001b[0m  0.0960\n",
      "     52        \u001b[36m0.9509\u001b[0m        \u001b[32m1.3853\u001b[0m  0.0980\n",
      "     53        0.9562        1.4149  0.0990\n",
      "     54        0.9679        1.3887  0.0980\n",
      "     55        \u001b[36m0.9445\u001b[0m        \u001b[32m1.3720\u001b[0m  0.1090\n",
      "     56        \u001b[36m0.9428\u001b[0m        1.3757  0.1000\n",
      "     57        0.9449        1.3819  0.0980\n",
      "     58        \u001b[36m0.9404\u001b[0m        \u001b[32m1.3586\u001b[0m  0.0990\n",
      "     59        \u001b[36m0.9239\u001b[0m        1.3695  0.0990\n",
      "     60        \u001b[36m0.9237\u001b[0m        \u001b[32m1.3549\u001b[0m  0.0980\n",
      "     61        \u001b[36m0.9226\u001b[0m        1.3658  0.0990\n",
      "     62        \u001b[36m0.9162\u001b[0m        1.3583  0.0990\n",
      "     63        0.9165        \u001b[32m1.3516\u001b[0m  0.0990\n",
      "     64        0.9291        1.3719  0.0990\n",
      "     65        0.9375        \u001b[32m1.3515\u001b[0m  0.0990\n",
      "     66        0.9184        \u001b[32m1.3510\u001b[0m  0.0980\n",
      "     67        0.9204        \u001b[32m1.3481\u001b[0m  0.0992\n",
      "     68        \u001b[36m0.9041\u001b[0m        1.3530  0.1100\n",
      "     69        0.9090        \u001b[32m1.3331\u001b[0m  0.0980\n",
      "     70        0.9057        \u001b[32m1.3257\u001b[0m  0.0980\n",
      "     71        \u001b[36m0.8998\u001b[0m        1.3391  0.0990\n",
      "     72        0.9036        \u001b[32m1.3253\u001b[0m  0.0980\n",
      "     73        0.9221        \u001b[32m1.3243\u001b[0m  0.0980\n",
      "     74        0.9076        \u001b[32m1.3233\u001b[0m  0.0980\n",
      "     75        0.9076        \u001b[32m1.3176\u001b[0m  0.1020\n",
      "     76        \u001b[36m0.8939\u001b[0m        \u001b[32m1.3157\u001b[0m  0.1050\n",
      "     77        0.8999        1.3160  0.0980\n",
      "     78        0.9100        \u001b[32m1.3046\u001b[0m  0.0980\n",
      "     79        \u001b[36m0.8866\u001b[0m        \u001b[32m1.3028\u001b[0m  0.0980\n",
      "     80        0.8893        \u001b[32m1.3019\u001b[0m  0.0970\n",
      "     81        0.8932        1.3042  0.1000\n",
      "     82        0.8916        1.3368  0.0980\n",
      "     83        0.9021        \u001b[32m1.2965\u001b[0m  0.1000\n",
      "     84        \u001b[36m0.8834\u001b[0m        \u001b[32m1.2963\u001b[0m  0.1010\n",
      "     85        \u001b[36m0.8793\u001b[0m        1.3062  0.0990\n",
      "     86        0.8826        \u001b[32m1.2905\u001b[0m  0.0990\n",
      "     87        0.8848        \u001b[32m1.2902\u001b[0m  0.0980\n",
      "     88        0.8858        1.2928  0.1020\n",
      "     89        \u001b[36m0.8729\u001b[0m        1.2966  0.0990\n",
      "     90        0.8824        \u001b[32m1.2847\u001b[0m  0.1000\n",
      "     91        0.8802        \u001b[32m1.2843\u001b[0m  0.0980\n",
      "     92        0.8794        1.2885  0.1010\n",
      "     93        \u001b[36m0.8726\u001b[0m        \u001b[32m1.2797\u001b[0m  0.0990\n",
      "     94        0.8808        1.3130  0.1000\n",
      "     95        0.8796        1.2909  0.0980\n",
      "     96        0.8776        1.2999  0.1040\n",
      "     97        0.9148        1.2827  0.1370\n",
      "     98        0.9471        1.2920  0.0980\n",
      "     99        0.9979        \u001b[32m1.2735\u001b[0m  0.0980\n",
      "    100        1.1239        1.2902  0.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=TorchModel(\n",
       "    (group_layers): ModuleList(\n",
       "      (0-25): 26 x GroupLayer(\n",
       "        (fc1): Linear(in_features=10, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (fc1): Linear(in_features=26, out_features=13, bias=True)\n",
       "    (fc_out): Linear(in_features=13, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(feature_data_numpy, label_data_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make prediction \n",
    "\n",
    "y_pred = net.predict(feature_data_numpy)\n",
    "\n",
    "# plot the output against the target\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(label_data_numpy, y_pred)\n",
    "plt.xlabel('True Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.title('Predicted vs True Value')\n",
    "# plt.xlim(-2, 4)\n",
    "# plt.ylim(0, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.14310619537858338\n"
     ]
    }
   ],
   "source": [
    "# calculate pearson correlation\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr, _ = pearsonr(label_data_numpy.flatten(), y_pred.flatten())\n",
    "\n",
    "print(f'Pearsons correlation: {corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with Powerkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "from toolkit import *   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerkit = Powerkit(feature_data, label_data)\n",
    "rngs = list(range(100))\n",
    "\n",
    "def pipeline_func(X_train, y_train, rng, **kwargs):\n",
    "    group_feat_size = 10\n",
    "    total_feat_size = 260\n",
    "    torch.manual_seed(rng)\n",
    "\n",
    "    net = NeuralNetRegressor(\n",
    "        TorchModel,\n",
    "        module__group_feat_size=group_feat_size,\n",
    "        module__total_feat_size=total_feat_size,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        criterion=torch.nn.MSELoss,\n",
    "        max_epochs=20,\n",
    "        lr=0.001,\n",
    "        batch_size=32,\n",
    "        iterator_train__shuffle=True\n",
    "    )\n",
    "    \n",
    "    x_train_numpy = X_train.to_numpy()\n",
    "    y_train_numpy = y_train.to_numpy()\n",
    "    y_train_numpy = y_train_numpy.reshape(-1, 1)\n",
    "    net.fit(x_train_numpy, y_train_numpy)\n",
    "    return {'model': net}\n",
    "\n",
    "\n",
    "def eval_func(X_test, y_test, pipeline_components=None, **kwargs):\n",
    "    \n",
    "    # preprocess x and y \n",
    "    x_test_numpy = X_test.to_numpy()\n",
    "    y_test_numpy = y_test.to_numpy()\n",
    "    y_test_numpy = y_test_numpy.reshape(-1, 1)\n",
    "    \n",
    "    net = pipeline_components['model']\n",
    "    y_pred = net.predict(x_test_numpy)\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test_numpy.flatten(), y_pred.flatten())\n",
    "    return {'model_performance': corr, 'p_vals': p_vals, 'feature_importance': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerkit.add_condition('pytorch', False, pipeline_func, {}, eval_func, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.3686\u001b[0m        \u001b[32m2.2308\u001b[0m  0.0910\n",
      "      2        \u001b[36m1.5989\u001b[0m        \u001b[32m1.7191\u001b[0m  0.0900\n",
      "      3        \u001b[36m1.4232\u001b[0m        \u001b[32m1.5617\u001b[0m  0.0910\n",
      "      4        \u001b[36m1.3473\u001b[0m        \u001b[32m1.4113\u001b[0m  0.1030\n",
      "      5        \u001b[36m1.3119\u001b[0m        1.4172  0.0880\n",
      "      6        \u001b[36m1.2437\u001b[0m        \u001b[32m1.2961\u001b[0m  0.0860\n",
      "      7        \u001b[36m1.2114\u001b[0m        1.3042  0.0870\n",
      "      8        \u001b[36m1.2028\u001b[0m        1.2970  0.0860\n",
      "      9        \u001b[36m1.1733\u001b[0m        \u001b[32m1.2545\u001b[0m  0.0860\n",
      "     10        \u001b[36m1.1470\u001b[0m        \u001b[32m1.2088\u001b[0m  0.0850\n",
      "     11        \u001b[36m1.1240\u001b[0m        \u001b[32m1.1575\u001b[0m  0.0850\n",
      "     12        \u001b[36m1.1193\u001b[0m        1.1860  0.0860\n",
      "     13        \u001b[36m1.0905\u001b[0m        1.1783  0.0860\n",
      "     14        \u001b[36m1.0845\u001b[0m        1.2427  0.0850\n",
      "     15        \u001b[36m1.0617\u001b[0m        \u001b[32m1.1540\u001b[0m  0.0900\n",
      "     16        1.0637        1.1673  0.0900\n",
      "     17        \u001b[36m1.0508\u001b[0m        \u001b[32m1.1278\u001b[0m  0.0850\n",
      "     18        \u001b[36m1.0319\u001b[0m        \u001b[32m1.1048\u001b[0m  0.0930\n",
      "     19        1.0383        \u001b[32m1.0852\u001b[0m  0.1030\n",
      "     20        \u001b[36m1.0312\u001b[0m        1.1162  0.0870\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.0141\u001b[0m    \u001b[32m18537.4686\u001b[0m  0.0860\n",
      "      2        \u001b[36m1.1756\u001b[0m    27752.3260  0.0850\n",
      "      3        \u001b[36m1.0465\u001b[0m    38360.1385  0.0861\n",
      "      4        \u001b[36m0.9980\u001b[0m    52910.8635  0.0910\n",
      "      5        \u001b[36m0.9713\u001b[0m    59423.8319  0.0870\n",
      "      6        \u001b[36m0.9330\u001b[0m    69731.3569  0.0860\n",
      "      7        \u001b[36m0.9157\u001b[0m    80187.2458  0.0890\n",
      "      8        \u001b[36m0.9033\u001b[0m    97719.0642  0.0861\n",
      "      9        \u001b[36m0.8986\u001b[0m   108407.3083  0.0900\n",
      "     10        \u001b[36m0.8925\u001b[0m   121423.8940  0.0870\n",
      "     11        \u001b[36m0.8910\u001b[0m   119747.1013  0.0860\n",
      "     12        \u001b[36m0.8898\u001b[0m   152225.1545  0.0850\n",
      "     13        \u001b[36m0.8587\u001b[0m   141509.4843  0.0850\n",
      "     14        0.8637   179619.8622  0.0850\n",
      "     15        0.8696   169970.6137  0.0850\n",
      "     16        0.8659   187406.2025  0.0860\n",
      "     17        \u001b[36m0.8560\u001b[0m   203734.0999  0.0874\n",
      "     18        \u001b[36m0.8523\u001b[0m   195110.3326  0.0850\n",
      "     19        \u001b[36m0.8488\u001b[0m   217992.8153  0.0870\n",
      "     20        \u001b[36m0.8476\u001b[0m   208774.4219  0.0860\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m481074.6551\u001b[0m        \u001b[32m2.4627\u001b[0m  0.0900\n",
      "      2   \u001b[36m264896.1295\u001b[0m        \u001b[32m1.6142\u001b[0m  0.0976\n",
      "      3   \u001b[36m237969.5449\u001b[0m        2.1124  0.0890\n",
      "      4    \u001b[36m84515.4263\u001b[0m        1.7591  0.0860\n",
      "      5    \u001b[36m45766.9928\u001b[0m        1.6227  0.0850\n",
      "      6    \u001b[36m33541.4781\u001b[0m        2.1668  0.0850\n",
      "      7     \u001b[36m9198.2262\u001b[0m        1.9204  0.0850\n",
      "      8     \u001b[36m4521.4696\u001b[0m        1.8837  0.0860\n",
      "      9     \u001b[36m3132.6572\u001b[0m        2.0202  0.0840\n",
      "     10      \u001b[36m769.9030\u001b[0m        1.9561  0.0860\n",
      "     11      \u001b[36m175.5136\u001b[0m        1.8716  0.0920\n",
      "     12       \u001b[36m68.4363\u001b[0m        1.8107  0.0910\n",
      "     13       \u001b[36m17.6679\u001b[0m        1.7517  0.0870\n",
      "     14        \u001b[36m6.0828\u001b[0m        1.7007  0.0890\n",
      "     15        \u001b[36m3.1903\u001b[0m        1.6515  0.0860\n",
      "     16        \u001b[36m1.6997\u001b[0m        \u001b[32m1.6059\u001b[0m  0.0870\n",
      "     17        \u001b[36m1.5446\u001b[0m        \u001b[32m1.5611\u001b[0m  0.0870\n",
      "     18        \u001b[36m1.5048\u001b[0m        \u001b[32m1.5226\u001b[0m  0.0860\n",
      "     19        \u001b[36m1.4729\u001b[0m        \u001b[32m1.4855\u001b[0m  0.0920\n",
      "     20        \u001b[36m1.4356\u001b[0m        \u001b[32m1.4548\u001b[0m  0.0890\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m28933.6550\u001b[0m        \u001b[32m4.7411\u001b[0m  0.0860\n",
      "      2     \u001b[36m7901.6355\u001b[0m        \u001b[32m2.3167\u001b[0m  0.0880\n",
      "      3     \u001b[36m3108.2513\u001b[0m        \u001b[32m1.5741\u001b[0m  0.0900\n",
      "      4      \u001b[36m106.4910\u001b[0m        \u001b[32m1.2930\u001b[0m  0.0890\n",
      "      5      204.8479        \u001b[32m1.1680\u001b[0m  0.0900\n",
      "      6       \u001b[36m80.8207\u001b[0m        \u001b[32m1.0395\u001b[0m  0.0990\n",
      "      7       \u001b[36m23.8535\u001b[0m        \u001b[32m0.9391\u001b[0m  0.0890\n",
      "      8        \u001b[36m4.7398\u001b[0m        \u001b[32m0.8869\u001b[0m  0.1140\n",
      "      9        \u001b[36m2.9659\u001b[0m        \u001b[32m0.8205\u001b[0m  0.0970\n",
      "     10        \u001b[36m1.5380\u001b[0m        \u001b[32m0.8092\u001b[0m  0.0930\n",
      "     11        \u001b[36m1.4526\u001b[0m        0.8358  0.0900\n",
      "     12        \u001b[36m1.4051\u001b[0m        \u001b[32m0.8074\u001b[0m  0.0910\n",
      "     13        \u001b[36m1.3595\u001b[0m        0.8199  0.0910\n",
      "     14        \u001b[36m1.3039\u001b[0m        0.8151  0.0920\n",
      "     15        \u001b[36m1.2680\u001b[0m        0.8290  0.0910\n",
      "     16        \u001b[36m1.2528\u001b[0m        0.8138  0.0900\n",
      "     17        \u001b[36m1.2138\u001b[0m        0.8245  0.0910\n",
      "     18        \u001b[36m1.2045\u001b[0m        0.8093  0.0900\n",
      "     19        \u001b[36m1.1671\u001b[0m        0.8096  0.0890\n",
      "     20        \u001b[36m1.1593\u001b[0m        0.8170  0.0880\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1  \u001b[36m1230555.3709\u001b[0m       \u001b[32m41.2419\u001b[0m  0.0850\n",
      "      2  \u001b[36m1042140.0321\u001b[0m       \u001b[32m27.6489\u001b[0m  0.0890\n",
      "      3   \u001b[36m893122.3270\u001b[0m       \u001b[32m11.3356\u001b[0m  0.0890\n",
      "      4   \u001b[36m747375.3517\u001b[0m        \u001b[32m3.3529\u001b[0m  0.0920\n",
      "      5   \u001b[36m636202.9667\u001b[0m        \u001b[32m2.5904\u001b[0m  0.0910\n",
      "      6   \u001b[36m513743.0637\u001b[0m        \u001b[32m2.1608\u001b[0m  0.0880\n",
      "      7   \u001b[36m407159.7159\u001b[0m        \u001b[32m1.6902\u001b[0m  0.0890\n",
      "      8   \u001b[36m338325.0190\u001b[0m        \u001b[32m1.6397\u001b[0m  0.0980\n",
      "      9   \u001b[36m263246.2236\u001b[0m        \u001b[32m1.5180\u001b[0m  0.0870\n",
      "     10   \u001b[36m233303.6264\u001b[0m        1.8877  0.0870\n",
      "     11   \u001b[36m172819.5716\u001b[0m        1.8543  0.0870\n",
      "     12   \u001b[36m126078.8089\u001b[0m        1.7457  0.0880\n",
      "     13    \u001b[36m95471.6550\u001b[0m        1.8499  0.0870\n",
      "     14    \u001b[36m77994.7910\u001b[0m        2.5536  0.0900\n",
      "     15    \u001b[36m59563.8723\u001b[0m        2.6373  0.0880\n",
      "     16    \u001b[36m36657.2514\u001b[0m        2.0974  0.0910\n",
      "     17    \u001b[36m28244.5314\u001b[0m        2.0610  0.0880\n",
      "     18    \u001b[36m19056.4252\u001b[0m        2.0284  0.0930\n",
      "     19    \u001b[36m11093.5230\u001b[0m        1.7906  0.0890\n",
      "     20     \u001b[36m8861.4060\u001b[0m        1.9810  0.0870\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m11.9274\u001b[0m        \u001b[32m4.2760\u001b[0m  0.0870\n",
      "      2        \u001b[36m3.5666\u001b[0m        \u001b[32m2.4768\u001b[0m  0.0900\n",
      "      3        \u001b[36m2.3583\u001b[0m        \u001b[32m1.7455\u001b[0m  0.0870\n",
      "      4        \u001b[36m1.8609\u001b[0m        \u001b[32m1.4388\u001b[0m  0.0840\n",
      "      5        \u001b[36m1.6477\u001b[0m        \u001b[32m1.3587\u001b[0m  0.0870\n",
      "      6        \u001b[36m1.5520\u001b[0m        \u001b[32m1.3115\u001b[0m  0.0870\n",
      "      7        \u001b[36m1.4965\u001b[0m        \u001b[32m1.2779\u001b[0m  0.0880\n",
      "      8        \u001b[36m1.4561\u001b[0m        \u001b[32m1.2557\u001b[0m  0.0870\n",
      "      9        \u001b[36m1.4116\u001b[0m        \u001b[32m1.2163\u001b[0m  0.0880\n",
      "     10        \u001b[36m1.3770\u001b[0m        \u001b[32m1.1968\u001b[0m  0.0870\n",
      "     11        \u001b[36m1.3405\u001b[0m        \u001b[32m1.1766\u001b[0m  0.0930\n",
      "     12        \u001b[36m1.3134\u001b[0m        \u001b[32m1.1647\u001b[0m  0.0940\n",
      "     13        \u001b[36m1.2897\u001b[0m        \u001b[32m1.1550\u001b[0m  0.0870\n",
      "     14        \u001b[36m1.2626\u001b[0m        \u001b[32m1.1486\u001b[0m  0.0870\n",
      "     15        \u001b[36m1.2439\u001b[0m        \u001b[32m1.1177\u001b[0m  0.0870\n",
      "     16        \u001b[36m1.2317\u001b[0m        \u001b[32m1.1098\u001b[0m  0.0870\n",
      "     17        \u001b[36m1.2065\u001b[0m        \u001b[32m1.0968\u001b[0m  0.0880\n",
      "     18        \u001b[36m1.2039\u001b[0m        \u001b[32m1.0901\u001b[0m  0.0900\n",
      "     19        \u001b[36m1.1854\u001b[0m        \u001b[32m1.0673\u001b[0m  0.0860\n",
      "     20        \u001b[36m1.1733\u001b[0m        \u001b[32m1.0637\u001b[0m  0.0860\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m166412.4028\u001b[0m      \u001b[32m362.8886\u001b[0m  0.0910\n",
      "      2    \u001b[36m86855.2252\u001b[0m       \u001b[32m99.2759\u001b[0m  0.1140\n",
      "      3    \u001b[36m36903.9011\u001b[0m       \u001b[32m23.2252\u001b[0m  0.0870\n",
      "      4    \u001b[36m29506.7860\u001b[0m        \u001b[32m8.5447\u001b[0m  0.0870\n",
      "      5     \u001b[36m6061.9611\u001b[0m        \u001b[32m6.6006\u001b[0m  0.0880\n",
      "      6     \u001b[36m2785.0400\u001b[0m        \u001b[32m5.6275\u001b[0m  0.0880\n",
      "      7      \u001b[36m641.0234\u001b[0m        \u001b[32m5.1715\u001b[0m  0.0900\n",
      "      8       \u001b[36m72.0031\u001b[0m        \u001b[32m4.4336\u001b[0m  0.0850\n",
      "      9       \u001b[36m31.5414\u001b[0m        \u001b[32m3.9986\u001b[0m  0.0870\n",
      "     10        \u001b[36m6.7144\u001b[0m        \u001b[32m3.7273\u001b[0m  0.0880\n",
      "     11        6.7464        \u001b[32m3.5141\u001b[0m  0.0860\n",
      "     12        \u001b[36m5.1573\u001b[0m        \u001b[32m3.3325\u001b[0m  0.0870\n",
      "     13        \u001b[36m4.4927\u001b[0m        \u001b[32m3.1908\u001b[0m  0.0890\n",
      "     14        \u001b[36m3.9551\u001b[0m        \u001b[32m3.0698\u001b[0m  0.0910\n",
      "     15        \u001b[36m3.6863\u001b[0m        \u001b[32m2.9502\u001b[0m  0.0980\n",
      "     16        \u001b[36m3.4607\u001b[0m        \u001b[32m2.8491\u001b[0m  0.0850\n",
      "     17        \u001b[36m3.2714\u001b[0m        \u001b[32m2.7593\u001b[0m  0.0850\n",
      "     18        \u001b[36m3.0856\u001b[0m        \u001b[32m2.6678\u001b[0m  0.0870\n",
      "     19        \u001b[36m2.9036\u001b[0m        \u001b[32m2.5945\u001b[0m  0.0910\n",
      "     20        \u001b[36m2.7504\u001b[0m        \u001b[32m2.5259\u001b[0m  0.0880\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m23.6801\u001b[0m       \u001b[32m10.9453\u001b[0m  0.0880\n",
      "      2        \u001b[36m8.8261\u001b[0m        \u001b[32m4.7624\u001b[0m  0.0870\n",
      "      3        \u001b[36m4.2939\u001b[0m        \u001b[32m3.1832\u001b[0m  0.0870\n",
      "      4        \u001b[36m2.9841\u001b[0m        \u001b[32m2.3963\u001b[0m  0.0880\n",
      "      5        \u001b[36m2.2663\u001b[0m        \u001b[32m1.7863\u001b[0m  0.0850\n",
      "      6        \u001b[36m1.8667\u001b[0m        \u001b[32m1.5748\u001b[0m  0.0870\n",
      "      7        \u001b[36m1.6134\u001b[0m        \u001b[32m1.4481\u001b[0m  0.0850\n",
      "      8        \u001b[36m1.4487\u001b[0m        \u001b[32m1.3588\u001b[0m  0.0870\n",
      "      9        \u001b[36m1.3345\u001b[0m        \u001b[32m1.2310\u001b[0m  0.0850\n",
      "     10        \u001b[36m1.2122\u001b[0m        1.3272  0.0870\n",
      "     11        \u001b[36m1.1591\u001b[0m        \u001b[32m1.1692\u001b[0m  0.0890\n",
      "     12        \u001b[36m1.1097\u001b[0m        \u001b[32m1.1280\u001b[0m  0.0870\n",
      "     13        \u001b[36m1.0746\u001b[0m        1.1573  0.0880\n",
      "     14        \u001b[36m1.0375\u001b[0m        1.1937  0.0870\n",
      "     15        \u001b[36m0.9916\u001b[0m        \u001b[32m1.1085\u001b[0m  0.0870\n",
      "     16        \u001b[36m0.9605\u001b[0m        1.1464  0.0870\n",
      "     17        0.9892        1.1684  0.0870\n",
      "     18        \u001b[36m0.9536\u001b[0m        1.1388  0.1090\n",
      "     19        \u001b[36m0.9378\u001b[0m        \u001b[32m1.1003\u001b[0m  0.0870\n",
      "     20        \u001b[36m0.9285\u001b[0m        1.1052  0.0900\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m29496.4390\u001b[0m       \u001b[32m11.9322\u001b[0m  0.0850\n",
      "      2    \u001b[36m23292.3529\u001b[0m        \u001b[32m4.2844\u001b[0m  0.0890\n",
      "      3    \u001b[36m12293.3924\u001b[0m        \u001b[32m3.5019\u001b[0m  0.0880\n",
      "      4     \u001b[36m5783.5395\u001b[0m        \u001b[32m2.6268\u001b[0m  0.0880\n",
      "      5     \u001b[36m3632.1363\u001b[0m        \u001b[32m2.2863\u001b[0m  0.0870\n",
      "      6     \u001b[36m1686.0419\u001b[0m        \u001b[32m2.0623\u001b[0m  0.0880\n",
      "      7     \u001b[36m1060.9155\u001b[0m        \u001b[32m1.9609\u001b[0m  0.0880\n",
      "      8      \u001b[36m264.4200\u001b[0m        \u001b[32m1.8212\u001b[0m  0.0920\n",
      "      9      \u001b[36m104.6012\u001b[0m        \u001b[32m1.7169\u001b[0m  0.0880\n",
      "     10       \u001b[36m67.6143\u001b[0m        \u001b[32m1.6422\u001b[0m  0.0870\n",
      "     11       \u001b[36m15.3004\u001b[0m        \u001b[32m1.5784\u001b[0m  0.0870\n",
      "     12        \u001b[36m2.5622\u001b[0m        \u001b[32m1.5299\u001b[0m  0.0880\n",
      "     13        \u001b[36m1.9431\u001b[0m        \u001b[32m1.4929\u001b[0m  0.0890\n",
      "     14        \u001b[36m1.6979\u001b[0m        \u001b[32m1.4572\u001b[0m  0.0870\n",
      "     15        \u001b[36m1.6225\u001b[0m        \u001b[32m1.4431\u001b[0m  0.0880\n",
      "     16        \u001b[36m1.5889\u001b[0m        \u001b[32m1.4078\u001b[0m  0.0870\n",
      "     17        \u001b[36m1.5778\u001b[0m        \u001b[32m1.3868\u001b[0m  0.0880\n",
      "     18        \u001b[36m1.5375\u001b[0m        1.3901  0.0860\n",
      "     19        \u001b[36m1.5179\u001b[0m        \u001b[32m1.3565\u001b[0m  0.0910\n",
      "     20        \u001b[36m1.5012\u001b[0m        \u001b[32m1.3455\u001b[0m  0.0870\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m76.8498\u001b[0m        \u001b[32m5.2313\u001b[0m  0.1100\n",
      "      2      502.3118        \u001b[32m1.9824\u001b[0m  0.0890\n",
      "      3      263.0741        \u001b[32m1.6576\u001b[0m  0.0870\n",
      "      4        \u001b[36m1.7774\u001b[0m        \u001b[32m1.3097\u001b[0m  0.0880\n",
      "      5      177.9623        \u001b[32m1.2621\u001b[0m  0.0880\n",
      "      6        2.1837        \u001b[32m1.2569\u001b[0m  0.0870\n",
      "      7       61.0522        \u001b[32m1.1845\u001b[0m  0.0850\n",
      "      8       31.3266        \u001b[32m1.1678\u001b[0m  0.0920\n",
      "      9       18.8419        \u001b[32m1.1594\u001b[0m  0.0890\n",
      "     10        5.1921        \u001b[32m1.1440\u001b[0m  0.0900\n",
      "     11       61.2779        1.1641  0.1000\n",
      "     12       18.9757        1.1545  0.0930\n",
      "     13        \u001b[36m1.6241\u001b[0m        1.1650  0.0930\n",
      "     14        4.4977        1.1567  0.0910\n",
      "     15        2.3973        1.1915  0.0890\n",
      "     16        \u001b[36m1.0005\u001b[0m        1.1921  0.0860\n",
      "     17        1.9434        1.2013  0.0890\n",
      "     18        5.4468        1.2261  0.0910\n",
      "     19        7.7604        1.2391  0.0870\n",
      "     20       12.3261        1.2292  0.1100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rng</th>\n",
       "      <th>condition</th>\n",
       "      <th>model_performance</th>\n",
       "      <th>p_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.141459</td>\n",
       "      <td>0.253515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.015951</td>\n",
       "      <td>0.898061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.077332</td>\n",
       "      <td>0.533935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.133526</td>\n",
       "      <td>0.281383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.842729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.972786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.999064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>0.924571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>-0.023552</td>\n",
       "      <td>0.849952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>0.987965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rng condition  model_performance    p_vals\n",
       "0    0   pytorch           0.141459  0.253515\n",
       "1    1   pytorch           0.015951  0.898061\n",
       "2    2   pytorch           0.077332  0.533935\n",
       "3    3   pytorch           0.133526  0.281383\n",
       "4    4   pytorch           0.024700  0.842729\n",
       "5    5   pytorch           0.004248  0.972786\n",
       "6    6   pytorch           0.000146  0.999064\n",
       "7    7   pytorch           0.011788  0.924571\n",
       "8    8   pytorch          -0.023552  0.849952\n",
       "9    9   pytorch          -0.001878  0.987965"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerkit.run_selected_condition('pytorch', rngs, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n",
      "(665, 260)\n",
      "(665, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n",
    "# Bring in CCLE data\n",
    "\n",
    "from PathLoader import PathLoader\n",
    "from DataLink import DataLink\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "data_link = DataLink(path_loader, 'data_codes.csv')\n",
    "\n",
    "# load in original ccle data\n",
    "drug_target = 'FGFR_0939'\n",
    "dynamic_features_code = 'fgfr4_ccle_dynamic_features_v2'\n",
    "loading_code = f'generic-gdsc-1-{drug_target}-LN_IC50-{dynamic_features_code}-true-Unnamed: 0'\n",
    "# generic-gdsc-{number}-{drug_name}-{target_label}-{dataset_name}-{replace_index}-{row_index}\n",
    "feature_data, label_data = data_link.get_data_using_code(loading_code)\n",
    "# convert to numpy\n",
    "feature_data_numpy = feature_data.to_numpy()\n",
    "label_data_numpy = label_data.to_numpy()\n",
    "label_data_numpy = label_data_numpy.reshape(-1, 1)\n",
    "print(feature_data_numpy.shape)\n",
    "print(label_data_numpy.shape)\n",
    "\n",
    "# further config \n",
    "\n",
    "group_feat_size = 10\n",
    "total_feat_size = feature_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"FGFR4-pytorch-model-training\"\n",
    "exp_id = \"v1\"\n",
    "fixed_random_seed = 42 # -1 for no seed\n",
    "save_figure = False\n",
    "save_data = True\n",
    "show_figure = False\n",
    "\n",
    "if not os.path.exists(f'{path_loader.get_data_path()}data/results/{folder_name}'):\n",
    "    os.makedirs(f'{path_loader.get_data_path()}data/results/{folder_name}')\n",
    "\n",
    "file_save_path = f'{path_loader.get_data_path()}data/results/{folder_name}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cpu\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch # type: ignore\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(torch.__version__)\n",
    "    # Setup device agnostic code\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from toolkit import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "from torch import nn  # type: ignore\n",
    "import torch.nn.functional as F  # type: ignore\n",
    "\n",
    "class GroupLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, group_feat_size: int):\n",
    "        super(GroupLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(group_feat_size, 1).double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class TorchModel(nn.Module):\n",
    "\n",
    "    def __init__(self, group_feat_size: int, total_feat_size: int):\n",
    "\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.group_feat_size = group_feat_size\n",
    "        self.total_feat_size = total_feat_size\n",
    "\n",
    "        num_groups = self.total_feat_size // self.group_feat_size\n",
    "\n",
    "        # if num_groups not an integer, throw error\n",
    "        if num_groups != self.total_feat_size / self.group_feat_size:\n",
    "            raise ValueError(\"Total feature size must be divisible by group feature size\")\n",
    "\n",
    "        self.num_groups = num_groups\n",
    "        self.group_layers = nn.ModuleList()\n",
    "        i = 0\n",
    "        while i < num_groups:\n",
    "            self.group_layers.append(GroupLayer(group_feat_size))\n",
    "            i += 1\n",
    "        self.layer_2_size = int(num_groups / 2)\n",
    "        self.fc1 = nn.Linear(num_groups, self.layer_2_size).double()\n",
    "        self.fc_out = nn.Linear(self.layer_2_size, 1).double()\n",
    "\n",
    "\n",
    "    def forward(self, input_data):\n",
    "\n",
    "        # print(input_data.shape)\n",
    "\n",
    "        xs = []\n",
    "        i = 0\n",
    "        while i < self.total_feat_size:\n",
    "            xs.append(input_data[:, i:i+self.group_feat_size])\n",
    "            i += group_feat_size\n",
    "\n",
    "\n",
    "        outs = []\n",
    "        for i, x in enumerate(xs):\n",
    "            # print(i+1, x.shape)\n",
    "            outs.append(self.group_layers[i](x))\n",
    "\n",
    "\n",
    "        x = torch.cat(outs, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerkit = Powerkit(feature_data, label_data)\n",
    "rngs = list(range(100))\n",
    "\n",
    "def pipeline_func(X_train, y_train, rng, **kwargs):\n",
    "    group_feat_size = 10\n",
    "    total_feat_size = X_train.shape[1]\n",
    "    torch.manual_seed(rng)\n",
    "\n",
    "    net = NeuralNetRegressor(\n",
    "        TorchModel,\n",
    "        module__group_feat_size=group_feat_size,\n",
    "        module__total_feat_size=total_feat_size,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        criterion=torch.nn.MSELoss,\n",
    "        max_epochs=500,\n",
    "        lr=0.001,\n",
    "        batch_size=32,\n",
    "        iterator_train__shuffle=True\n",
    "    )\n",
    "    \n",
    "    x_train_numpy = X_train.to_numpy()\n",
    "    y_train_numpy = y_train.to_numpy()\n",
    "    y_train_numpy = y_train_numpy.reshape(-1, 1)\n",
    "    net.fit(x_train_numpy, y_train_numpy)\n",
    "    return {'model': net}\n",
    "\n",
    "\n",
    "def eval_func(X_test, y_test, pipeline_components=None, **kwargs):\n",
    "    \n",
    "    # preprocess x and y \n",
    "    x_test_numpy = X_test.to_numpy()\n",
    "    y_test_numpy = y_test.to_numpy()\n",
    "    y_test_numpy = y_test_numpy.reshape(-1, 1)\n",
    "    \n",
    "    net = pipeline_components['model']\n",
    "    y_pred = net.predict(x_test_numpy)\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test_numpy.flatten(), y_pred.flatten())\n",
    "    return {'model_performance': corr, 'p_vals': p_vals, 'feature_importance': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerkit.add_condition('pytorch', False, pipeline_func, {}, eval_func, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m28.1334\u001b[0m    \u001b[32m83048.5913\u001b[0m  0.4229\n",
      "      2       \u001b[36m10.0765\u001b[0m    \u001b[32m14610.3395\u001b[0m  0.1201\n",
      "      3        \u001b[36m3.4216\u001b[0m     \u001b[32m2410.5324\u001b[0m  0.1114\n",
      "      4        \u001b[36m2.1574\u001b[0m    13300.9514  0.1280\n",
      "      5        \u001b[36m1.6085\u001b[0m     8749.5121  0.1198\n",
      "      6        \u001b[36m1.3651\u001b[0m     7557.7609  0.1145\n",
      "      7        \u001b[36m1.2478\u001b[0m     7178.2494  0.1153\n",
      "      8        \u001b[36m1.1828\u001b[0m     5694.3690  0.1252\n",
      "      9        \u001b[36m1.1511\u001b[0m     4093.7305  0.1208\n",
      "     10        \u001b[36m1.1206\u001b[0m     4802.5108  0.1722\n",
      "     11        \u001b[36m1.0991\u001b[0m     6386.6136  0.1281\n",
      "     12        \u001b[36m1.0774\u001b[0m     5602.2282  0.1186\n",
      "     13        \u001b[36m1.0652\u001b[0m     6069.3954  0.1117\n",
      "     14        \u001b[36m1.0480\u001b[0m     7072.5656  0.1180\n",
      "     15        \u001b[36m1.0450\u001b[0m     8125.9363  0.1185\n",
      "     16        \u001b[36m1.0370\u001b[0m     8008.1032  0.1109\n",
      "     17        \u001b[36m1.0135\u001b[0m     5466.3339  0.1727\n",
      "     18        1.0199     7230.5917  0.1767\n",
      "     19        \u001b[36m1.0112\u001b[0m     8471.5858  0.1193\n",
      "     20        \u001b[36m1.0099\u001b[0m     8760.4574  0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:05<08:52,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m14.4865\u001b[0m  \u001b[32m1145032.7435\u001b[0m  0.1144\n",
      "      2        \u001b[36m3.7493\u001b[0m  1695689.1332  0.1238\n",
      "      3        \u001b[36m2.1531\u001b[0m  1569641.2528  0.1148\n",
      "      4        \u001b[36m1.4926\u001b[0m  1292329.9646  0.1177\n",
      "      5        \u001b[36m1.2675\u001b[0m  1221798.9880  0.1207\n",
      "      6        \u001b[36m1.2216\u001b[0m  \u001b[32m1119151.2273\u001b[0m  0.1101\n",
      "      7        \u001b[36m1.1559\u001b[0m  \u001b[32m1024163.6533\u001b[0m  0.1091\n",
      "      8        \u001b[36m1.1471\u001b[0m   \u001b[32m973204.9063\u001b[0m  0.1107\n",
      "      9        \u001b[36m1.0983\u001b[0m   \u001b[32m928794.5715\u001b[0m  0.1536\n",
      "     10        \u001b[36m1.0702\u001b[0m   \u001b[32m877602.9246\u001b[0m  0.1539\n",
      "     11        \u001b[36m1.0524\u001b[0m   \u001b[32m835491.4323\u001b[0m  0.1443\n",
      "     12        1.0555   \u001b[32m814129.4787\u001b[0m  0.1383\n",
      "     13        \u001b[36m1.0286\u001b[0m   \u001b[32m781360.1313\u001b[0m  0.1410\n",
      "     14        1.0294   \u001b[32m767919.2718\u001b[0m  0.1961\n",
      "     15        1.0425   \u001b[32m712257.8423\u001b[0m  0.1509\n",
      "     16        \u001b[36m0.9966\u001b[0m   724338.3983  0.1217\n",
      "     17        \u001b[36m0.9627\u001b[0m   713354.3622  0.1129\n",
      "     18        \u001b[36m0.9607\u001b[0m   \u001b[32m697192.7190\u001b[0m  0.1610\n",
      "     19        \u001b[36m0.9479\u001b[0m   \u001b[32m673871.1399\u001b[0m  0.1408\n",
      "     20        0.9484   \u001b[32m642458.8934\u001b[0m  0.1639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:08<06:17,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m4027.1273\u001b[0m        \u001b[32m6.5928\u001b[0m  0.1277\n",
      "      2      \u001b[36m812.5580\u001b[0m        \u001b[32m4.5761\u001b[0m  0.1485\n",
      "      3      \u001b[36m400.6700\u001b[0m        \u001b[32m3.7946\u001b[0m  0.1195\n",
      "      4       \u001b[36m19.1348\u001b[0m        \u001b[32m3.1202\u001b[0m  0.1108\n",
      "      5       \u001b[36m15.3202\u001b[0m        \u001b[32m2.4700\u001b[0m  0.1133\n",
      "      6        \u001b[36m9.3154\u001b[0m        \u001b[32m2.0648\u001b[0m  0.1165\n",
      "      7        \u001b[36m2.9512\u001b[0m        \u001b[32m1.8856\u001b[0m  0.1205\n",
      "      8        \u001b[36m2.3224\u001b[0m        \u001b[32m1.7910\u001b[0m  0.1183\n",
      "      9        \u001b[36m1.7716\u001b[0m        \u001b[32m1.6808\u001b[0m  0.1099\n",
      "     10        \u001b[36m1.5807\u001b[0m        \u001b[32m1.5963\u001b[0m  0.1255\n",
      "     11        \u001b[36m1.4802\u001b[0m        \u001b[32m1.5151\u001b[0m  0.2039\n",
      "     12        \u001b[36m1.3821\u001b[0m        \u001b[32m1.4590\u001b[0m  0.1283\n",
      "     13        \u001b[36m1.3148\u001b[0m        \u001b[32m1.4158\u001b[0m  0.1155\n",
      "     14        \u001b[36m1.2531\u001b[0m        \u001b[32m1.3629\u001b[0m  0.1189\n",
      "     15        \u001b[36m1.2031\u001b[0m        \u001b[32m1.3325\u001b[0m  0.1301\n",
      "     16        \u001b[36m1.1618\u001b[0m        \u001b[32m1.3131\u001b[0m  0.1140\n",
      "     17        \u001b[36m1.1308\u001b[0m        \u001b[32m1.2944\u001b[0m  0.1157\n",
      "     18        \u001b[36m1.1039\u001b[0m        \u001b[32m1.2675\u001b[0m  0.1146\n",
      "     19        \u001b[36m1.0807\u001b[0m        \u001b[32m1.2632\u001b[0m  0.1055\n",
      "     20        \u001b[36m1.0650\u001b[0m        1.2747  0.1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:10<05:15,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m1037.2568\u001b[0m        \u001b[32m2.8599\u001b[0m  0.1160\n",
      "      2      \u001b[36m390.6265\u001b[0m        \u001b[32m2.3857\u001b[0m  0.1181\n",
      "      3      \u001b[36m144.3261\u001b[0m        \u001b[32m1.9439\u001b[0m  0.1191\n",
      "      4       \u001b[36m35.6662\u001b[0m        \u001b[32m1.5684\u001b[0m  0.1117\n",
      "      5        \u001b[36m4.1007\u001b[0m        \u001b[32m1.2697\u001b[0m  0.1184\n",
      "      6        \u001b[36m2.1772\u001b[0m        \u001b[32m1.0971\u001b[0m  0.1109\n",
      "      7        \u001b[36m1.2987\u001b[0m        \u001b[32m1.0160\u001b[0m  0.1096\n",
      "      8        \u001b[36m1.2298\u001b[0m        \u001b[32m0.9630\u001b[0m  0.1114\n",
      "      9        \u001b[36m1.1866\u001b[0m        \u001b[32m0.9313\u001b[0m  0.1588\n",
      "     10        \u001b[36m1.1399\u001b[0m        \u001b[32m0.9107\u001b[0m  0.1802\n",
      "     11        \u001b[36m1.1198\u001b[0m        \u001b[32m0.8904\u001b[0m  0.2074\n",
      "     12        \u001b[36m1.1027\u001b[0m        \u001b[32m0.8695\u001b[0m  0.1147\n",
      "     13        \u001b[36m1.0925\u001b[0m        \u001b[32m0.8512\u001b[0m  0.1156\n",
      "     14        \u001b[36m1.0767\u001b[0m        \u001b[32m0.8494\u001b[0m  0.1061\n",
      "     15        \u001b[36m1.0695\u001b[0m        0.8513  0.1055\n",
      "     16        1.0719        \u001b[32m0.8275\u001b[0m  0.1117\n",
      "     17        \u001b[36m1.0518\u001b[0m        0.8301  0.1064\n",
      "     18        \u001b[36m1.0485\u001b[0m        \u001b[32m0.8230\u001b[0m  0.1034\n",
      "     19        \u001b[36m1.0424\u001b[0m        \u001b[32m0.8097\u001b[0m  0.1087\n",
      "     20        \u001b[36m1.0392\u001b[0m        0.8101  0.1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:13<04:43,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m702.4704\u001b[0m      \u001b[32m158.3576\u001b[0m  0.1115\n",
      "      2      \u001b[36m264.7259\u001b[0m       \u001b[32m83.6147\u001b[0m  0.1139\n",
      "      3      \u001b[36m140.1869\u001b[0m       \u001b[32m48.4322\u001b[0m  0.1020\n",
      "      4       \u001b[36m74.1780\u001b[0m       \u001b[32m30.8810\u001b[0m  0.1132\n",
      "      5       \u001b[36m47.9113\u001b[0m       \u001b[32m20.2083\u001b[0m  0.1070\n",
      "      6       \u001b[36m33.8137\u001b[0m       \u001b[32m12.5915\u001b[0m  0.1161\n",
      "      7       \u001b[36m18.7079\u001b[0m        \u001b[32m7.0960\u001b[0m  0.1041\n",
      "      8       \u001b[36m10.0500\u001b[0m        \u001b[32m4.1042\u001b[0m  0.1700\n",
      "      9        \u001b[36m6.3526\u001b[0m        \u001b[32m2.7532\u001b[0m  0.1299\n",
      "     10        \u001b[36m4.2167\u001b[0m        \u001b[32m2.2789\u001b[0m  0.1103\n",
      "     11        \u001b[36m3.2273\u001b[0m        \u001b[32m2.0005\u001b[0m  0.1142\n",
      "     12        \u001b[36m2.4315\u001b[0m        \u001b[32m1.8094\u001b[0m  0.1169\n",
      "     13        \u001b[36m1.9940\u001b[0m        \u001b[32m1.6844\u001b[0m  0.1158\n",
      "     14        \u001b[36m1.7415\u001b[0m        \u001b[32m1.6115\u001b[0m  0.1105\n",
      "     15        \u001b[36m1.5583\u001b[0m        \u001b[32m1.5559\u001b[0m  0.1153\n",
      "     16        \u001b[36m1.4195\u001b[0m        \u001b[32m1.4791\u001b[0m  0.1326\n",
      "     17        \u001b[36m1.3390\u001b[0m        \u001b[32m1.4501\u001b[0m  0.1430\n",
      "     18        \u001b[36m1.2806\u001b[0m        \u001b[32m1.4171\u001b[0m  0.1169\n",
      "     19        \u001b[36m1.2631\u001b[0m        \u001b[32m1.3949\u001b[0m  0.1101\n",
      "     20        \u001b[36m1.2276\u001b[0m        \u001b[32m1.3853\u001b[0m  0.1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:15<04:21,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m311.7685\u001b[0m      \u001b[32m182.4094\u001b[0m  0.1322\n",
      "      2       \u001b[36m89.3052\u001b[0m       \u001b[32m57.5547\u001b[0m  0.1412\n",
      "      3       \u001b[36m29.5665\u001b[0m       \u001b[32m18.3032\u001b[0m  0.1509\n",
      "      4        \u001b[36m9.5622\u001b[0m        \u001b[32m7.8977\u001b[0m  0.1091\n",
      "      5        \u001b[36m5.0141\u001b[0m        \u001b[32m4.2939\u001b[0m  0.1468\n",
      "      6        \u001b[36m3.2539\u001b[0m        \u001b[32m2.9158\u001b[0m  0.1318\n",
      "      7        \u001b[36m2.4461\u001b[0m        \u001b[32m2.1706\u001b[0m  0.1118\n",
      "      8        \u001b[36m2.0481\u001b[0m        \u001b[32m1.7925\u001b[0m  0.1195\n",
      "      9        \u001b[36m1.8105\u001b[0m        \u001b[32m1.5965\u001b[0m  0.1499\n",
      "     10        \u001b[36m1.6872\u001b[0m        \u001b[32m1.4752\u001b[0m  0.1085\n",
      "     11        \u001b[36m1.6088\u001b[0m        \u001b[32m1.4224\u001b[0m  0.1202\n",
      "     12        \u001b[36m1.5462\u001b[0m        \u001b[32m1.3748\u001b[0m  0.1089\n",
      "     13        \u001b[36m1.4982\u001b[0m        \u001b[32m1.3443\u001b[0m  0.1051\n",
      "     14        \u001b[36m1.4576\u001b[0m        \u001b[32m1.3199\u001b[0m  0.1109\n",
      "     15        \u001b[36m1.4274\u001b[0m        \u001b[32m1.3081\u001b[0m  0.1091\n",
      "     16        \u001b[36m1.3969\u001b[0m        \u001b[32m1.2899\u001b[0m  0.1001\n",
      "     17        \u001b[36m1.3666\u001b[0m        \u001b[32m1.2714\u001b[0m  0.1134\n",
      "     18        \u001b[36m1.3466\u001b[0m        \u001b[32m1.2565\u001b[0m  0.1274\n",
      "     19        \u001b[36m1.3149\u001b[0m        \u001b[32m1.2463\u001b[0m  0.1092\n",
      "     20        \u001b[36m1.2921\u001b[0m        \u001b[32m1.2301\u001b[0m  0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:18<04:10,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m812.9635\u001b[0m        \u001b[32m1.6057\u001b[0m  0.1110\n",
      "      2      \u001b[36m222.3090\u001b[0m        \u001b[32m1.3214\u001b[0m  0.1104\n",
      "      3        \u001b[36m4.2401\u001b[0m        1.3516  0.1097\n",
      "      4        \u001b[36m1.4289\u001b[0m        \u001b[32m1.2598\u001b[0m  0.1702\n",
      "      5        4.7623        \u001b[32m1.2263\u001b[0m  0.1303\n",
      "      6        1.8071        \u001b[32m1.1737\u001b[0m  0.1101\n",
      "      7        1.5018        \u001b[32m1.1674\u001b[0m  0.1102\n",
      "      8        1.4636        1.1703  0.1186\n",
      "      9        \u001b[36m1.2218\u001b[0m        \u001b[32m1.1527\u001b[0m  0.1279\n",
      "     10        \u001b[36m1.1976\u001b[0m        \u001b[32m1.1178\u001b[0m  0.1182\n",
      "     11        \u001b[36m1.1785\u001b[0m        1.1466  0.1108\n",
      "     12        \u001b[36m1.1384\u001b[0m        1.1518  0.1145\n",
      "     13        \u001b[36m1.1204\u001b[0m        1.1188  0.1157\n",
      "     14        \u001b[36m1.1140\u001b[0m        \u001b[32m1.1147\u001b[0m  0.1157\n",
      "     15        1.1197        \u001b[32m1.0867\u001b[0m  0.1203\n",
      "     16        \u001b[36m1.0957\u001b[0m        1.0960  0.1101\n",
      "     17        \u001b[36m1.0858\u001b[0m        1.1024  0.1109\n",
      "     18        1.1200        1.1118  0.1180\n",
      "     19        \u001b[36m1.0648\u001b[0m        \u001b[32m1.0775\u001b[0m  0.1098\n",
      "     20        1.0852        1.0927  0.1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:20<03:59,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m11.3950\u001b[0m        \u001b[32m4.2343\u001b[0m  0.1188\n",
      "      2        \u001b[36m2.7915\u001b[0m        \u001b[32m1.4542\u001b[0m  0.1673\n",
      "      3        \u001b[36m1.5524\u001b[0m        \u001b[32m1.2934\u001b[0m  0.1661\n",
      "      4        \u001b[36m1.3189\u001b[0m        \u001b[32m1.1958\u001b[0m  0.1326\n",
      "      5        \u001b[36m1.1721\u001b[0m        1.2266  0.1155\n",
      "      6        \u001b[36m1.0905\u001b[0m        \u001b[32m1.1956\u001b[0m  0.1124\n",
      "      7        \u001b[36m1.0674\u001b[0m        \u001b[32m1.1913\u001b[0m  0.1094\n",
      "      8        \u001b[36m1.0348\u001b[0m        \u001b[32m1.1834\u001b[0m  0.1197\n",
      "      9        \u001b[36m1.0108\u001b[0m        1.1918  0.1103\n",
      "     10        \u001b[36m0.9982\u001b[0m        \u001b[32m1.1827\u001b[0m  0.1146\n",
      "     11        \u001b[36m0.9815\u001b[0m        1.1877  0.1127\n",
      "     12        \u001b[36m0.9759\u001b[0m        \u001b[32m1.1788\u001b[0m  0.1217\n",
      "     13        1.0097        \u001b[32m1.1770\u001b[0m  0.1146\n",
      "     14        \u001b[36m0.9640\u001b[0m        \u001b[32m1.1678\u001b[0m  0.1119\n",
      "     15        \u001b[36m0.9629\u001b[0m        1.1679  0.1163\n",
      "     16        1.0021        1.1709  0.1100\n",
      "     17        1.0118        1.1851  0.1163\n",
      "     18        1.0440        1.1996  0.1143\n",
      "     19        0.9699        1.1871  0.1128\n",
      "     20        \u001b[36m0.9443\u001b[0m        \u001b[32m1.1506\u001b[0m  0.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:22<03:53,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m57215.6559\u001b[0m        \u001b[32m6.3475\u001b[0m  0.1803\n",
      "      2    \u001b[36m17843.5935\u001b[0m        \u001b[32m3.1927\u001b[0m  0.1297\n",
      "      3      \u001b[36m557.1202\u001b[0m        \u001b[32m2.0729\u001b[0m  0.1074\n",
      "      4       \u001b[36m37.8115\u001b[0m        \u001b[32m1.5463\u001b[0m  0.1071\n",
      "      5      218.9772        \u001b[32m1.3081\u001b[0m  0.1073\n",
      "      6       46.2887        \u001b[32m1.1968\u001b[0m  0.1123\n",
      "      7        \u001b[36m1.2771\u001b[0m        \u001b[32m1.1154\u001b[0m  0.1103\n",
      "      8       14.0194        \u001b[32m1.0651\u001b[0m  0.1000\n",
      "      9        5.2143        \u001b[32m1.0373\u001b[0m  0.1214\n",
      "     10        6.0000        \u001b[32m1.0310\u001b[0m  0.1085\n",
      "     11        \u001b[36m1.1236\u001b[0m        \u001b[32m1.0274\u001b[0m  0.1001\n",
      "     12        1.1625        \u001b[32m1.0239\u001b[0m  0.1011\n",
      "     13        \u001b[36m1.0501\u001b[0m        \u001b[32m1.0219\u001b[0m  0.1098\n",
      "     14        \u001b[36m1.0391\u001b[0m        \u001b[32m1.0200\u001b[0m  0.1089\n",
      "     15        \u001b[36m1.0341\u001b[0m        \u001b[32m1.0193\u001b[0m  0.1108\n",
      "     16        \u001b[36m1.0271\u001b[0m        \u001b[32m1.0187\u001b[0m  0.1006\n",
      "     17        \u001b[36m1.0259\u001b[0m        \u001b[32m1.0158\u001b[0m  0.1053\n",
      "     18        \u001b[36m1.0201\u001b[0m        1.0178  0.1056\n",
      "     19        \u001b[36m1.0190\u001b[0m        1.0197  0.1233\n",
      "     20        \u001b[36m1.0152\u001b[0m        1.0167  0.1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:25<03:44,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m16287.1780\u001b[0m        \u001b[32m4.7178\u001b[0m  0.1660\n",
      "      2     \u001b[36m1645.8173\u001b[0m        \u001b[32m3.5847\u001b[0m  0.1283\n",
      "      3       \u001b[36m18.2065\u001b[0m        \u001b[32m3.5083\u001b[0m  0.1124\n",
      "      4      100.0556        \u001b[32m1.9059\u001b[0m  0.1209\n",
      "      5       33.6979        \u001b[32m1.6499\u001b[0m  0.1274\n",
      "      6       22.4527        \u001b[32m1.4879\u001b[0m  0.1216\n",
      "      7        \u001b[36m6.9682\u001b[0m        \u001b[32m1.4303\u001b[0m  0.1084\n",
      "      8       32.1208        \u001b[32m1.2920\u001b[0m  0.1720\n",
      "      9        \u001b[36m2.0534\u001b[0m        \u001b[32m1.2074\u001b[0m  0.1281\n",
      "     10        7.1565        \u001b[32m1.1804\u001b[0m  0.1090\n",
      "     11        \u001b[36m1.3683\u001b[0m        \u001b[32m1.1263\u001b[0m  0.1148\n",
      "     12        2.4989        \u001b[32m1.0804\u001b[0m  0.1101\n",
      "     13        2.2181        \u001b[32m1.0503\u001b[0m  0.1100\n",
      "     14        1.7983        \u001b[32m1.0373\u001b[0m  0.1199\n",
      "     15        \u001b[36m1.1832\u001b[0m        \u001b[32m1.0229\u001b[0m  0.1183\n",
      "     16        3.8930        1.0252  0.1136\n",
      "     17        4.0210        \u001b[32m1.0024\u001b[0m  0.1052\n",
      "     18        2.9578        1.0232  0.1700\n",
      "     19        1.6402        \u001b[32m0.9759\u001b[0m  0.1590\n",
      "     20        \u001b[36m1.1030\u001b[0m        0.9951  0.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:27<03:45,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.9637\u001b[0m        \u001b[32m1.3375\u001b[0m  0.1966\n",
      "      2        \u001b[36m1.4661\u001b[0m        \u001b[32m1.2610\u001b[0m  0.1316\n",
      "      3        \u001b[36m1.1978\u001b[0m        \u001b[32m1.1306\u001b[0m  0.1185\n",
      "      4        \u001b[36m1.1097\u001b[0m        \u001b[32m1.1033\u001b[0m  0.1115\n",
      "      5        \u001b[36m1.0720\u001b[0m        \u001b[32m1.0807\u001b[0m  0.1125\n",
      "      6        \u001b[36m1.0375\u001b[0m        \u001b[32m1.0664\u001b[0m  0.1071\n",
      "      7        \u001b[36m1.0147\u001b[0m        \u001b[32m1.0229\u001b[0m  0.1113\n",
      "      8        \u001b[36m1.0056\u001b[0m        1.0358  0.1125\n",
      "      9        \u001b[36m0.9786\u001b[0m        \u001b[32m0.9870\u001b[0m  0.1085\n",
      "     10        \u001b[36m0.9688\u001b[0m        0.9989  0.1168\n",
      "     11        0.9690        1.0200  0.1192\n",
      "     12        \u001b[36m0.9516\u001b[0m        1.0209  0.1113\n",
      "     13        0.9526        \u001b[32m0.9735\u001b[0m  0.1090\n",
      "     14        \u001b[36m0.9394\u001b[0m        1.0133  0.1178\n",
      "     15        0.9442        0.9740  0.1132\n",
      "     16        \u001b[36m0.9334\u001b[0m        1.0089  0.1751\n",
      "     17        \u001b[36m0.9310\u001b[0m        0.9797  0.1501\n",
      "     18        0.9386        1.0150  0.1182\n",
      "     19        0.9378        0.9817  0.1107\n",
      "     20        0.9464        1.0203  0.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:30<03:43,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m1.8994\u001b[0m      \u001b[32m550.9790\u001b[0m  0.1227\n",
      "      2        \u001b[36m1.5128\u001b[0m      \u001b[32m125.0774\u001b[0m  0.1152\n",
      "      3        \u001b[36m1.3001\u001b[0m      357.8555  0.1165\n",
      "      4        \u001b[36m1.2138\u001b[0m      276.2114  0.1179\n",
      "      5        \u001b[36m1.1014\u001b[0m     1122.3857  0.1105\n",
      "      6        \u001b[36m1.0477\u001b[0m     2352.8915  0.1216\n",
      "      7        \u001b[36m1.0263\u001b[0m     4269.0736  0.1098\n",
      "      8        \u001b[36m0.9924\u001b[0m     5500.3527  0.1075\n",
      "      9        \u001b[36m0.9882\u001b[0m     8291.6677  0.1170\n",
      "     10        \u001b[36m0.9702\u001b[0m     9330.1579  0.1185\n",
      "     11        \u001b[36m0.9669\u001b[0m     9695.2136  0.1113\n",
      "     12        0.9755    13910.4345  0.1113\n",
      "     13        \u001b[36m0.9546\u001b[0m    14653.8911  0.1167\n",
      "     14        \u001b[36m0.9481\u001b[0m    15356.5763  0.1274\n",
      "     15        \u001b[36m0.9442\u001b[0m    19105.2969  0.1940\n",
      "     16        \u001b[36m0.9437\u001b[0m    20681.5324  0.1130\n",
      "     17        \u001b[36m0.9433\u001b[0m    22262.3135  0.1112\n",
      "     18        0.9532    21633.5172  0.1129\n",
      "     19        \u001b[36m0.9385\u001b[0m    27557.5059  0.1170\n",
      "     20        0.9437    26233.4225  0.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:32<03:39,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m160.9879\u001b[0m       \u001b[32m16.6983\u001b[0m  0.1191\n",
      "      2       \u001b[36m13.3566\u001b[0m       \u001b[32m13.0813\u001b[0m  0.1243\n",
      "      3       \u001b[36m10.3922\u001b[0m        \u001b[32m4.1114\u001b[0m  0.1170\n",
      "      4        \u001b[36m4.0778\u001b[0m        \u001b[32m3.4846\u001b[0m  0.1187\n",
      "      5        \u001b[36m2.6780\u001b[0m        \u001b[32m1.8222\u001b[0m  0.1143\n",
      "      6        \u001b[36m1.9811\u001b[0m        \u001b[32m1.3060\u001b[0m  0.1072\n",
      "      7        \u001b[36m1.6505\u001b[0m        \u001b[32m1.2776\u001b[0m  0.1057\n",
      "      8        \u001b[36m1.4494\u001b[0m        \u001b[32m1.0679\u001b[0m  0.1112\n",
      "      9        \u001b[36m1.3343\u001b[0m        \u001b[32m0.9823\u001b[0m  0.1199\n",
      "     10        \u001b[36m1.2443\u001b[0m        1.0015  0.1022\n",
      "     11        \u001b[36m1.1786\u001b[0m        \u001b[32m0.9273\u001b[0m  0.1111\n",
      "     12        \u001b[36m1.1232\u001b[0m        \u001b[32m0.9101\u001b[0m  0.1100\n",
      "     13        \u001b[36m1.0944\u001b[0m        \u001b[32m0.9045\u001b[0m  0.1502\n",
      "     14        \u001b[36m1.0747\u001b[0m        \u001b[32m0.8881\u001b[0m  0.1385\n",
      "     15        \u001b[36m1.0561\u001b[0m        \u001b[32m0.8777\u001b[0m  0.1141\n",
      "     16        \u001b[36m1.0488\u001b[0m        0.8840  0.1171\n",
      "     17        \u001b[36m1.0408\u001b[0m        \u001b[32m0.8764\u001b[0m  0.1110\n",
      "     18        \u001b[36m1.0351\u001b[0m        0.8770  0.1189\n",
      "     19        1.0353        \u001b[32m0.8755\u001b[0m  0.1239\n",
      "     20        \u001b[36m1.0323\u001b[0m        \u001b[32m0.8641\u001b[0m  0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:35<03:33,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.3702\u001b[0m   \u001b[32m173190.6361\u001b[0m  0.1193\n",
      "      2        \u001b[36m1.4823\u001b[0m    \u001b[32m41389.4563\u001b[0m  0.1217\n",
      "      3        \u001b[36m1.1556\u001b[0m     \u001b[32m5028.4489\u001b[0m  0.1100\n",
      "      4        \u001b[36m1.0311\u001b[0m     \u001b[32m3572.1991\u001b[0m  0.1140\n",
      "      5        \u001b[36m0.9831\u001b[0m    34355.0833  0.1202\n",
      "      6        \u001b[36m0.9486\u001b[0m    80815.7127  0.1133\n",
      "      7        \u001b[36m0.9353\u001b[0m   137545.5051  0.1105\n",
      "      8        \u001b[36m0.9131\u001b[0m   197375.9687  0.1194\n",
      "      9        \u001b[36m0.9055\u001b[0m   264222.3904  0.1142\n",
      "     10        \u001b[36m0.8964\u001b[0m   327697.3056  0.1221\n",
      "     11        \u001b[36m0.8862\u001b[0m   402761.0812  0.1428\n",
      "     12        \u001b[36m0.8828\u001b[0m   488968.6249  0.1783\n",
      "     13        0.8834   583473.5803  0.1123\n",
      "     14        \u001b[36m0.8766\u001b[0m   624551.4695  0.1178\n",
      "     15        \u001b[36m0.8698\u001b[0m   726239.1345  0.1200\n",
      "     16        0.8874   890735.3188  0.1091\n",
      "     17        \u001b[36m0.8654\u001b[0m   895752.4232  0.1122\n",
      "     18        0.8777  1027027.4827  0.1061\n",
      "     19        \u001b[36m0.8615\u001b[0m  1122287.1748  0.1136\n",
      "     20        \u001b[36m0.8573\u001b[0m  1265007.8882  0.1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:37<03:31,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m5737.8302\u001b[0m        \u001b[32m1.2874\u001b[0m  0.1279\n",
      "      2      \u001b[36m368.8468\u001b[0m        \u001b[32m1.1182\u001b[0m  0.1295\n",
      "      3      \u001b[36m128.7407\u001b[0m        \u001b[32m1.0830\u001b[0m  0.1107\n",
      "      4       \u001b[36m16.2413\u001b[0m        \u001b[32m1.0447\u001b[0m  0.1185\n",
      "      5        \u001b[36m6.5767\u001b[0m        \u001b[32m1.0239\u001b[0m  0.1105\n",
      "      6        8.1934        \u001b[32m1.0025\u001b[0m  0.1210\n",
      "      7        \u001b[36m3.4487\u001b[0m        \u001b[32m0.9985\u001b[0m  0.1164\n",
      "      8       44.5275        \u001b[32m0.9913\u001b[0m  0.1108\n",
      "      9       77.5101        \u001b[32m0.9715\u001b[0m  0.1116\n",
      "     10        \u001b[36m1.0631\u001b[0m        1.0046  0.1971\n",
      "     11        6.4622        0.9728  0.1343\n",
      "     12      303.3702        1.0092  0.1135\n",
      "     13     3175.0480        1.0844  0.1100\n",
      "     14     2122.6458        \u001b[32m0.9401\u001b[0m  0.1217\n",
      "     15       50.4456        1.0110  0.1182\n",
      "     16      135.0274        0.9666  0.1083\n",
      "     17      182.3947        0.9531  0.1187\n",
      "     18      179.1962        1.0094  0.1229\n",
      "     19       40.8019        0.9524  0.1084\n",
      "     20        \u001b[36m0.9588\u001b[0m        0.9890  0.1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:40<03:29,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1  \u001b[36m2142972.8713\u001b[0m       \u001b[32m13.4922\u001b[0m  0.1242\n",
      "      2  \u001b[36m1690658.1047\u001b[0m        \u001b[32m5.7312\u001b[0m  0.1218\n",
      "      3  \u001b[36m1391532.4802\u001b[0m        \u001b[32m2.8061\u001b[0m  0.1127\n",
      "      4  \u001b[36m1178914.9687\u001b[0m        \u001b[32m2.2447\u001b[0m  0.1117\n",
      "      5   \u001b[36m925150.1491\u001b[0m        \u001b[32m2.2229\u001b[0m  0.1107\n",
      "      6   \u001b[36m780085.8109\u001b[0m        \u001b[32m2.1615\u001b[0m  0.1115\n",
      "      7   \u001b[36m674442.6220\u001b[0m        \u001b[32m2.1106\u001b[0m  0.1099\n",
      "      8   \u001b[36m556435.7354\u001b[0m        \u001b[32m2.0803\u001b[0m  0.1367\n",
      "      9   \u001b[36m465914.5047\u001b[0m        2.1579  0.1814\n",
      "     10   \u001b[36m406559.5575\u001b[0m        2.1165  0.1164\n",
      "     11   \u001b[36m347869.6644\u001b[0m        2.1827  0.1256\n",
      "     12   \u001b[36m302949.3632\u001b[0m        2.2118  0.1115\n",
      "     13   \u001b[36m249523.6836\u001b[0m        2.1388  0.1175\n",
      "     14   \u001b[36m215098.6496\u001b[0m        \u001b[32m1.9392\u001b[0m  0.1199\n",
      "     15   \u001b[36m184556.4040\u001b[0m        \u001b[32m1.7664\u001b[0m  0.1179\n",
      "     16   \u001b[36m164579.2812\u001b[0m        \u001b[32m1.5804\u001b[0m  0.1165\n",
      "     17   \u001b[36m127423.2761\u001b[0m        \u001b[32m1.4810\u001b[0m  0.1134\n",
      "     18   \u001b[36m112354.2206\u001b[0m        \u001b[32m1.3968\u001b[0m  0.1125\n",
      "     19    \u001b[36m91708.4428\u001b[0m        \u001b[32m1.2939\u001b[0m  0.1064\n",
      "     20    \u001b[36m76316.0306\u001b[0m        \u001b[32m1.2416\u001b[0m  0.1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:42<03:26,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m7.8572\u001b[0m     \u001b[32m6251.7654\u001b[0m  0.1200\n",
      "      2        \u001b[36m3.3174\u001b[0m     8623.3599  0.1195\n",
      "      3        \u001b[36m2.3903\u001b[0m     9816.2820  0.1151\n",
      "      4        \u001b[36m1.9682\u001b[0m    10195.5567  0.1129\n",
      "      5        \u001b[36m1.7308\u001b[0m    10634.4668  0.1913\n",
      "      6        \u001b[36m1.5581\u001b[0m    10112.5956  0.1590\n",
      "      7        \u001b[36m1.4204\u001b[0m    10599.6228  0.1586\n",
      "      8        \u001b[36m1.3336\u001b[0m    10778.4394  0.1214\n",
      "      9        \u001b[36m1.2364\u001b[0m    11644.0205  0.1196\n",
      "     10        \u001b[36m1.1779\u001b[0m    12102.3738  0.1190\n",
      "     11        \u001b[36m1.1294\u001b[0m    12701.7442  0.1213\n",
      "     12        \u001b[36m1.0989\u001b[0m    13852.8718  0.1177\n",
      "     13        \u001b[36m1.0695\u001b[0m    14609.1020  0.1198\n",
      "     14        \u001b[36m1.0363\u001b[0m    16395.2163  0.1158\n",
      "     15        \u001b[36m1.0201\u001b[0m    18005.5439  0.1159\n",
      "     16        \u001b[36m1.0052\u001b[0m    19596.5475  0.1175\n",
      "     17        \u001b[36m0.9970\u001b[0m    21134.7463  0.1114\n",
      "     18        \u001b[36m0.9921\u001b[0m    24013.5698  0.1183\n",
      "     19        \u001b[36m0.9782\u001b[0m    25911.9485  0.1012\n",
      "     20        \u001b[36m0.9752\u001b[0m    28852.8890  0.1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:45<03:25,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m38.1949\u001b[0m        \u001b[32m7.5633\u001b[0m  0.1211\n",
      "      2        \u001b[36m4.2757\u001b[0m        \u001b[32m2.7174\u001b[0m  0.1192\n",
      "      3        \u001b[36m1.9636\u001b[0m        \u001b[32m1.8512\u001b[0m  0.1100\n",
      "      4        \u001b[36m1.5443\u001b[0m        \u001b[32m1.6791\u001b[0m  0.1212\n",
      "      5        \u001b[36m1.3890\u001b[0m        1.6865  0.1940\n",
      "      6        \u001b[36m1.3476\u001b[0m        \u001b[32m1.6127\u001b[0m  0.1351\n",
      "      7        \u001b[36m1.2923\u001b[0m        \u001b[32m1.5768\u001b[0m  0.1100\n",
      "      8        \u001b[36m1.2421\u001b[0m        \u001b[32m1.5205\u001b[0m  0.1174\n",
      "      9        \u001b[36m1.2004\u001b[0m        \u001b[32m1.4901\u001b[0m  0.1210\n",
      "     10        \u001b[36m1.1636\u001b[0m        \u001b[32m1.4509\u001b[0m  0.1149\n",
      "     11        \u001b[36m1.1424\u001b[0m        \u001b[32m1.4224\u001b[0m  0.1109\n",
      "     12        \u001b[36m1.1195\u001b[0m        \u001b[32m1.4140\u001b[0m  0.1140\n",
      "     13        \u001b[36m1.0892\u001b[0m        \u001b[32m1.4096\u001b[0m  0.1088\n",
      "     14        \u001b[36m1.0753\u001b[0m        \u001b[32m1.3899\u001b[0m  0.1111\n",
      "     15        \u001b[36m1.0577\u001b[0m        \u001b[32m1.3407\u001b[0m  0.1097\n",
      "     16        1.0608        1.3848  0.1297\n",
      "     17        \u001b[36m1.0372\u001b[0m        1.3743  0.1173\n",
      "     18        1.0473        \u001b[32m1.3077\u001b[0m  0.1085\n",
      "     19        \u001b[36m1.0151\u001b[0m        \u001b[32m1.3015\u001b[0m  0.1147\n",
      "     20        \u001b[36m1.0100\u001b[0m        1.3079  0.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:47<03:22,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m36001.6618\u001b[0m       \u001b[32m13.6395\u001b[0m  0.1171\n",
      "      2    \u001b[36m27534.8516\u001b[0m        \u001b[32m6.2412\u001b[0m  0.1254\n",
      "      3    \u001b[36m19030.7990\u001b[0m        \u001b[32m2.9431\u001b[0m  0.1803\n",
      "      4    \u001b[36m13762.6140\u001b[0m        \u001b[32m1.8499\u001b[0m  0.1774\n",
      "      5    \u001b[36m10311.0324\u001b[0m        1.9753  0.1098\n",
      "      6     \u001b[36m7728.1805\u001b[0m        2.3625  0.1108\n",
      "      7     \u001b[36m4712.0252\u001b[0m        2.2526  0.1109\n",
      "      8     \u001b[36m3838.1570\u001b[0m        2.3497  0.1109\n",
      "      9     \u001b[36m2309.2325\u001b[0m        2.2435  0.1210\n",
      "     10     \u001b[36m1572.5638\u001b[0m        2.4677  0.1189\n",
      "     11      \u001b[36m849.0052\u001b[0m        2.1142  0.1120\n",
      "     12      \u001b[36m662.9192\u001b[0m        2.1863  0.1173\n",
      "     13      \u001b[36m344.7995\u001b[0m        2.0628  0.1121\n",
      "     14      \u001b[36m217.4461\u001b[0m        1.8779  0.1089\n",
      "     15      \u001b[36m134.7489\u001b[0m        \u001b[32m1.7748\u001b[0m  0.1088\n",
      "     16       \u001b[36m72.1085\u001b[0m        \u001b[32m1.6932\u001b[0m  0.1109\n",
      "     17       \u001b[36m35.2530\u001b[0m        \u001b[32m1.6478\u001b[0m  0.1211\n",
      "     18       \u001b[36m23.4158\u001b[0m        \u001b[32m1.5810\u001b[0m  0.1104\n",
      "     19       \u001b[36m14.1628\u001b[0m        \u001b[32m1.5103\u001b[0m  0.1200\n",
      "     20       \u001b[36m10.2310\u001b[0m        \u001b[32m1.4482\u001b[0m  0.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:49<03:19,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m752444.9840\u001b[0m        \u001b[32m4.3881\u001b[0m  0.1498\n",
      "      2   \u001b[36m646840.1296\u001b[0m        \u001b[32m2.8490\u001b[0m  0.1813\n",
      "      3   \u001b[36m554560.9757\u001b[0m        \u001b[32m2.3373\u001b[0m  0.1194\n",
      "      4   \u001b[36m488946.1855\u001b[0m        \u001b[32m2.0684\u001b[0m  0.1121\n",
      "      5   \u001b[36m409460.1710\u001b[0m        \u001b[32m1.8928\u001b[0m  0.1101\n",
      "      6   \u001b[36m353712.1778\u001b[0m        \u001b[32m1.7982\u001b[0m  0.1224\n",
      "      7   \u001b[36m308952.7768\u001b[0m        \u001b[32m1.7207\u001b[0m  0.1193\n",
      "      8   \u001b[36m279114.8096\u001b[0m        \u001b[32m1.6548\u001b[0m  0.1185\n",
      "      9   \u001b[36m229667.3766\u001b[0m        \u001b[32m1.6004\u001b[0m  0.1220\n",
      "     10   \u001b[36m202712.1315\u001b[0m        \u001b[32m1.5349\u001b[0m  0.1196\n",
      "     11   \u001b[36m178835.4127\u001b[0m        \u001b[32m1.4981\u001b[0m  0.1134\n",
      "     12   \u001b[36m151013.7212\u001b[0m        \u001b[32m1.4458\u001b[0m  0.1064\n",
      "     13   \u001b[36m131131.9897\u001b[0m        \u001b[32m1.4002\u001b[0m  0.1108\n",
      "     14   \u001b[36m127314.6612\u001b[0m        \u001b[32m1.3925\u001b[0m  0.1110\n",
      "     15    \u001b[36m97858.3000\u001b[0m        \u001b[32m1.3354\u001b[0m  0.1289\n",
      "     16    \u001b[36m93884.4670\u001b[0m        1.3361  0.1096\n",
      "     17    \u001b[36m73469.0681\u001b[0m        \u001b[32m1.3039\u001b[0m  0.1159\n",
      "     18    \u001b[36m63834.2378\u001b[0m        \u001b[32m1.2752\u001b[0m  0.1101\n",
      "     19    \u001b[36m56329.4968\u001b[0m        \u001b[32m1.2670\u001b[0m  0.1119\n",
      "     20    \u001b[36m49170.8579\u001b[0m        \u001b[32m1.2347\u001b[0m  0.1697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:52<03:18,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m494.2038\u001b[0m      \u001b[32m228.4566\u001b[0m  0.1317\n",
      "      2      \u001b[36m200.4107\u001b[0m       \u001b[32m82.3184\u001b[0m  0.1236\n",
      "      3       \u001b[36m74.4803\u001b[0m       \u001b[32m31.9697\u001b[0m  0.1052\n",
      "      4       \u001b[36m38.7986\u001b[0m       \u001b[32m24.5493\u001b[0m  0.1201\n",
      "      5       \u001b[36m27.0829\u001b[0m       \u001b[32m17.4378\u001b[0m  0.1214\n",
      "      6       \u001b[36m19.7293\u001b[0m       \u001b[32m11.4064\u001b[0m  0.1105\n",
      "      7       \u001b[36m14.4516\u001b[0m        \u001b[32m7.4816\u001b[0m  0.1118\n",
      "      8       \u001b[36m10.4236\u001b[0m        \u001b[32m4.7050\u001b[0m  0.1126\n",
      "      9        \u001b[36m6.9896\u001b[0m        \u001b[32m2.7037\u001b[0m  0.1059\n",
      "     10        \u001b[36m4.7796\u001b[0m        \u001b[32m1.8976\u001b[0m  0.1150\n",
      "     11        \u001b[36m3.4577\u001b[0m        \u001b[32m1.6542\u001b[0m  0.1126\n",
      "     12        \u001b[36m2.9526\u001b[0m        \u001b[32m1.5465\u001b[0m  0.1186\n",
      "     13        \u001b[36m2.4944\u001b[0m        \u001b[32m1.5208\u001b[0m  0.1262\n",
      "     14        \u001b[36m2.2122\u001b[0m        \u001b[32m1.4644\u001b[0m  0.1122\n",
      "     15        \u001b[36m2.0374\u001b[0m        \u001b[32m1.4298\u001b[0m  0.1118\n",
      "     16        \u001b[36m1.8576\u001b[0m        \u001b[32m1.4083\u001b[0m  0.1100\n",
      "     17        \u001b[36m1.7015\u001b[0m        \u001b[32m1.3736\u001b[0m  0.1185\n",
      "     18        \u001b[36m1.5983\u001b[0m        \u001b[32m1.3557\u001b[0m  0.1147\n",
      "     19        \u001b[36m1.5092\u001b[0m        \u001b[32m1.3371\u001b[0m  0.1998\n",
      "     20        \u001b[36m1.4413\u001b[0m        \u001b[32m1.3082\u001b[0m  0.1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:54<03:16,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m39639.2929\u001b[0m        \u001b[32m2.2233\u001b[0m  0.1202\n",
      "      2     \u001b[36m5558.1401\u001b[0m        \u001b[32m1.3648\u001b[0m  0.1246\n",
      "      3      \u001b[36m233.0186\u001b[0m        \u001b[32m1.1921\u001b[0m  0.1222\n",
      "      4      \u001b[36m112.1649\u001b[0m        \u001b[32m1.1304\u001b[0m  0.1149\n",
      "      5      233.7803        1.1674  0.1104\n",
      "      6        \u001b[36m1.9119\u001b[0m        \u001b[32m1.0944\u001b[0m  0.1053\n",
      "      7        5.4424        \u001b[32m1.0488\u001b[0m  0.1200\n",
      "      8        \u001b[36m1.5372\u001b[0m        \u001b[32m1.0194\u001b[0m  0.1292\n",
      "      9        5.4881        1.0337  0.1219\n",
      "     10        1.5679        1.0393  0.1117\n",
      "     11        3.6296        \u001b[32m0.9913\u001b[0m  0.1080\n",
      "     12        \u001b[36m1.2535\u001b[0m        \u001b[32m0.9769\u001b[0m  0.1202\n",
      "     13        1.4821        0.9815  0.1154\n",
      "     14        \u001b[36m1.1899\u001b[0m        0.9847  0.1159\n",
      "     15        \u001b[36m1.1331\u001b[0m        \u001b[32m0.9726\u001b[0m  0.1101\n",
      "     16        \u001b[36m1.1175\u001b[0m        0.9762  0.1068\n",
      "     17        \u001b[36m1.0959\u001b[0m        \u001b[32m0.9704\u001b[0m  0.1698\n",
      "     18       12.8621        1.0102  0.1690\n",
      "     19       49.1512        \u001b[32m0.9505\u001b[0m  0.1185\n",
      "     20       11.0983        0.9549  0.1147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:57<03:13,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m64.0025\u001b[0m   \u001b[32m125550.1979\u001b[0m  0.1329\n",
      "      2       \u001b[36m22.2318\u001b[0m   \u001b[32m107380.8746\u001b[0m  0.1229\n",
      "      3        \u001b[36m9.8710\u001b[0m   216527.2012  0.1168\n",
      "      4        \u001b[36m6.0920\u001b[0m   426686.8817  0.1279\n",
      "      5        \u001b[36m4.3799\u001b[0m   580260.6523  0.1624\n",
      "      6        \u001b[36m3.4696\u001b[0m   501868.4482  0.1186\n",
      "      7        \u001b[36m2.7485\u001b[0m   388550.8039  0.1085\n",
      "      8        \u001b[36m2.2530\u001b[0m   293671.3073  0.1197\n",
      "      9        \u001b[36m1.9821\u001b[0m   269029.6297  0.1144\n",
      "     10        \u001b[36m1.7742\u001b[0m   254812.1695  0.1149\n",
      "     11        \u001b[36m1.6035\u001b[0m   233595.5380  0.1117\n",
      "     12        \u001b[36m1.4972\u001b[0m   214501.3857  0.1201\n",
      "     13        \u001b[36m1.4027\u001b[0m   196738.4262  0.1185\n",
      "     14        \u001b[36m1.3481\u001b[0m   176146.1997  0.1183\n",
      "     15        \u001b[36m1.2817\u001b[0m   170529.6818  0.1800\n",
      "     16        \u001b[36m1.2451\u001b[0m   168399.3295  0.1457\n",
      "     17        \u001b[36m1.2148\u001b[0m   156544.2507  0.1099\n",
      "     18        \u001b[36m1.1906\u001b[0m   153312.4749  0.1162\n",
      "     19        \u001b[36m1.1647\u001b[0m   146805.8129  0.1256\n",
      "     20        \u001b[36m1.1406\u001b[0m   157511.9381  0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:00<03:12,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m539255.9648\u001b[0m       \u001b[32m74.0320\u001b[0m  0.1338\n",
      "      2   \u001b[36m394134.3654\u001b[0m       \u001b[32m14.6067\u001b[0m  0.1214\n",
      "      3   \u001b[36m381813.0319\u001b[0m        \u001b[32m4.2026\u001b[0m  0.1112\n",
      "      4   \u001b[36m217372.0521\u001b[0m        \u001b[32m4.0727\u001b[0m  0.1149\n",
      "      5   \u001b[36m143208.8755\u001b[0m        4.1915  0.1098\n",
      "      6   \u001b[36m103665.6370\u001b[0m        6.0298  0.1203\n",
      "      7    \u001b[36m41100.1873\u001b[0m        \u001b[32m3.0744\u001b[0m  0.1141\n",
      "      8    \u001b[36m23830.5127\u001b[0m        \u001b[32m1.8561\u001b[0m  0.1170\n",
      "      9    \u001b[36m14373.3314\u001b[0m        1.9755  0.1198\n",
      "     10     \u001b[36m6953.3575\u001b[0m        2.0590  0.1404\n",
      "     11     \u001b[36m3475.2454\u001b[0m        2.0612  0.1203\n",
      "     12     \u001b[36m1290.2678\u001b[0m        2.0331  0.1307\n",
      "     13      \u001b[36m277.0462\u001b[0m        1.9419  0.2015\n",
      "     14       \u001b[36m79.3765\u001b[0m        \u001b[32m1.7976\u001b[0m  0.1352\n",
      "     15       \u001b[36m55.3505\u001b[0m        \u001b[32m1.6503\u001b[0m  0.1201\n",
      "     16        \u001b[36m6.7374\u001b[0m        \u001b[32m1.5400\u001b[0m  0.1086\n",
      "     17        \u001b[36m1.9637\u001b[0m        \u001b[32m1.4615\u001b[0m  0.1125\n",
      "     18        \u001b[36m1.3323\u001b[0m        \u001b[32m1.4082\u001b[0m  0.1159\n",
      "     19        \u001b[36m1.1898\u001b[0m        \u001b[32m1.3622\u001b[0m  0.1185\n",
      "     20        \u001b[36m1.1658\u001b[0m        \u001b[32m1.3367\u001b[0m  0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:02<03:10,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m13372.1802\u001b[0m        \u001b[32m1.7268\u001b[0m  0.1069\n",
      "      2     \u001b[36m2310.9857\u001b[0m        \u001b[32m1.2727\u001b[0m  0.1039\n",
      "      3      \u001b[36m824.7776\u001b[0m        \u001b[32m1.1102\u001b[0m  0.1097\n",
      "      4       \u001b[36m15.3809\u001b[0m        \u001b[32m1.0566\u001b[0m  0.1072\n",
      "      5       98.9238        \u001b[32m1.0388\u001b[0m  0.1127\n",
      "      6        \u001b[36m3.4551\u001b[0m        \u001b[32m1.0267\u001b[0m  0.1072\n",
      "      7        \u001b[36m1.5545\u001b[0m        \u001b[32m1.0088\u001b[0m  0.1111\n",
      "      8        \u001b[36m1.5247\u001b[0m        \u001b[32m0.9959\u001b[0m  0.0992\n",
      "      9        \u001b[36m1.0687\u001b[0m        \u001b[32m0.9849\u001b[0m  0.1061\n",
      "     10        1.2292        0.9880  0.1066\n",
      "     11       20.6121        \u001b[32m0.9797\u001b[0m  0.1049\n",
      "     12       31.6613        \u001b[32m0.9772\u001b[0m  0.1795\n",
      "     13        \u001b[36m1.0524\u001b[0m        \u001b[32m0.9716\u001b[0m  0.1305\n",
      "     14        2.9351        \u001b[32m0.9691\u001b[0m  0.1061\n",
      "     15        1.3455        0.9709  0.1001\n",
      "     16        \u001b[36m0.9471\u001b[0m        0.9753  0.1009\n",
      "     17        1.1339        0.9711  0.1109\n",
      "     18        \u001b[36m0.9387\u001b[0m        0.9796  0.1092\n",
      "     19        1.0540        0.9695  0.1071\n",
      "     20        0.9815        0.9705  0.1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:04<03:03,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m601654.9989\u001b[0m      \u001b[32m197.0087\u001b[0m  0.1140\n",
      "      2   \u001b[36m490622.0514\u001b[0m       \u001b[32m20.3008\u001b[0m  0.1154\n",
      "      3   \u001b[36m295005.6035\u001b[0m        \u001b[32m8.5994\u001b[0m  0.1080\n",
      "      4   \u001b[36m217867.3469\u001b[0m        \u001b[32m7.7583\u001b[0m  0.1041\n",
      "      5   \u001b[36m137043.2909\u001b[0m        \u001b[32m7.5913\u001b[0m  0.1065\n",
      "      6    \u001b[36m88326.9900\u001b[0m        \u001b[32m7.0007\u001b[0m  0.1106\n",
      "      7    \u001b[36m70425.5620\u001b[0m        \u001b[32m6.3874\u001b[0m  0.1088\n",
      "      8    \u001b[36m35740.6216\u001b[0m        \u001b[32m5.5450\u001b[0m  0.1032\n",
      "      9    \u001b[36m20756.3924\u001b[0m        \u001b[32m5.0751\u001b[0m  0.1136\n",
      "     10    \u001b[36m12198.7768\u001b[0m        \u001b[32m4.8041\u001b[0m  0.1018\n",
      "     11     \u001b[36m8001.0722\u001b[0m        \u001b[32m4.6179\u001b[0m  0.1337\n",
      "     12     \u001b[36m4237.1349\u001b[0m        \u001b[32m4.3194\u001b[0m  0.1501\n",
      "     13     \u001b[36m1893.7348\u001b[0m        \u001b[32m4.0857\u001b[0m  0.1177\n",
      "     14     \u001b[36m1047.1304\u001b[0m        \u001b[32m3.9517\u001b[0m  0.0988\n",
      "     15      \u001b[36m678.3833\u001b[0m        \u001b[32m3.7672\u001b[0m  0.1084\n",
      "     16      \u001b[36m194.9061\u001b[0m        \u001b[32m3.6236\u001b[0m  0.1132\n",
      "     17       \u001b[36m89.3257\u001b[0m        \u001b[32m3.4928\u001b[0m  0.1080\n",
      "     18       \u001b[36m71.7351\u001b[0m        \u001b[32m3.3407\u001b[0m  0.1100\n",
      "     19       \u001b[36m16.0960\u001b[0m        \u001b[32m3.2060\u001b[0m  0.1060\n",
      "     20        \u001b[36m8.1118\u001b[0m        \u001b[32m3.0709\u001b[0m  0.1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:07<02:57,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m36.4735\u001b[0m   \u001b[32m226959.2677\u001b[0m  0.1189\n",
      "      2        \u001b[36m9.5747\u001b[0m   \u001b[32m169236.9150\u001b[0m  0.1211\n",
      "      3        \u001b[36m3.9664\u001b[0m   \u001b[32m160548.3942\u001b[0m  0.1315\n",
      "      4        \u001b[36m2.3885\u001b[0m   169360.8671  0.1172\n",
      "      5        \u001b[36m1.8071\u001b[0m   180835.5399  0.1151\n",
      "      6        \u001b[36m1.5259\u001b[0m   199093.6469  0.1107\n",
      "      7        \u001b[36m1.4180\u001b[0m   213617.5643  0.1125\n",
      "      8        \u001b[36m1.3336\u001b[0m   238952.3993  0.1086\n",
      "      9        \u001b[36m1.2765\u001b[0m   260904.2783  0.1105\n",
      "     10        \u001b[36m1.2260\u001b[0m   277018.9843  0.1446\n",
      "     11        \u001b[36m1.1906\u001b[0m   295980.8542  0.1408\n",
      "     12        \u001b[36m1.1611\u001b[0m   309166.1683  0.1150\n",
      "     13        \u001b[36m1.1383\u001b[0m   317326.9793  0.1122\n",
      "     14        1.1409   323674.7696  0.1088\n",
      "     15        \u001b[36m1.1023\u001b[0m   329981.8101  0.1187\n",
      "     16        \u001b[36m1.0943\u001b[0m   333383.4722  0.1303\n",
      "     17        \u001b[36m1.0733\u001b[0m   335497.7202  0.1109\n",
      "     18        \u001b[36m1.0622\u001b[0m   333985.7523  0.1190\n",
      "     19        \u001b[36m1.0523\u001b[0m   329639.4212  0.1126\n",
      "     20        \u001b[36m1.0428\u001b[0m   329267.1300  0.1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:09<02:55,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m225.1913\u001b[0m      \u001b[32m113.3804\u001b[0m  0.1203\n",
      "      2       \u001b[36m95.1926\u001b[0m       \u001b[32m31.2676\u001b[0m  0.1197\n",
      "      3       \u001b[36m25.1450\u001b[0m       \u001b[32m12.2591\u001b[0m  0.1169\n",
      "      4       34.1443        \u001b[32m7.1153\u001b[0m  0.1234\n",
      "      5       99.9112        \u001b[32m4.0658\u001b[0m  0.1644\n",
      "      6       \u001b[36m22.2436\u001b[0m        \u001b[32m3.0444\u001b[0m  0.1170\n",
      "      7        \u001b[36m5.7955\u001b[0m        \u001b[32m2.5457\u001b[0m  0.1129\n",
      "      8        \u001b[36m3.4437\u001b[0m        \u001b[32m2.2843\u001b[0m  0.1865\n",
      "      9        4.3084        \u001b[32m1.8631\u001b[0m  0.1534\n",
      "     10        \u001b[36m2.3369\u001b[0m        \u001b[32m1.6087\u001b[0m  0.1169\n",
      "     11        \u001b[36m2.0291\u001b[0m        \u001b[32m1.4874\u001b[0m  0.1100\n",
      "     12        \u001b[36m1.8223\u001b[0m        \u001b[32m1.3588\u001b[0m  0.1198\n",
      "     13        \u001b[36m1.6776\u001b[0m        \u001b[32m1.2874\u001b[0m  0.1186\n",
      "     14        1.9764        \u001b[32m1.2101\u001b[0m  0.1215\n",
      "     15        3.8991        \u001b[32m1.1979\u001b[0m  0.1158\n",
      "     16        \u001b[36m1.4826\u001b[0m        \u001b[32m1.1697\u001b[0m  0.1132\n",
      "     17        1.5236        \u001b[32m1.1156\u001b[0m  0.1185\n",
      "     18        \u001b[36m1.3472\u001b[0m        \u001b[32m1.0981\u001b[0m  0.1100\n",
      "     19        \u001b[36m1.3412\u001b[0m        \u001b[32m1.0778\u001b[0m  0.1536\n",
      "     20        \u001b[36m1.2940\u001b[0m        \u001b[32m1.0469\u001b[0m  0.1166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:12<02:56,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m37.0278\u001b[0m        \u001b[32m1.6956\u001b[0m  0.1290\n",
      "      2      492.7786        \u001b[32m1.2877\u001b[0m  0.1112\n",
      "      3       \u001b[36m15.3141\u001b[0m        \u001b[32m1.1263\u001b[0m  0.1065\n",
      "      4       19.0416        1.2008  0.1057\n",
      "      5        \u001b[36m2.5313\u001b[0m        \u001b[32m1.1031\u001b[0m  0.1071\n",
      "      6        2.8730        \u001b[32m1.0454\u001b[0m  0.1258\n",
      "      7        \u001b[36m1.6049\u001b[0m        1.0498  0.1563\n",
      "      8        \u001b[36m1.3294\u001b[0m        \u001b[32m1.0230\u001b[0m  0.1202\n",
      "      9        1.4860        \u001b[32m0.9896\u001b[0m  0.1129\n",
      "     10        \u001b[36m1.3174\u001b[0m        \u001b[32m0.9562\u001b[0m  0.1045\n",
      "     11        \u001b[36m1.2213\u001b[0m        \u001b[32m0.9275\u001b[0m  0.1213\n",
      "     12        \u001b[36m1.1826\u001b[0m        \u001b[32m0.9225\u001b[0m  0.1184\n",
      "     13        \u001b[36m1.1577\u001b[0m        0.9229  0.1114\n",
      "     14        \u001b[36m1.1439\u001b[0m        \u001b[32m0.9067\u001b[0m  0.1142\n",
      "     15        \u001b[36m1.1246\u001b[0m        \u001b[32m0.9040\u001b[0m  0.1174\n",
      "     16        \u001b[36m1.1172\u001b[0m        \u001b[32m0.8984\u001b[0m  0.1064\n",
      "     17        \u001b[36m1.1078\u001b[0m        \u001b[32m0.8838\u001b[0m  0.1198\n",
      "     18        \u001b[36m1.0966\u001b[0m        \u001b[32m0.8778\u001b[0m  0.1126\n",
      "     19        \u001b[36m1.0879\u001b[0m        0.8938  0.1210\n",
      "     20        \u001b[36m1.0752\u001b[0m        \u001b[32m0.8629\u001b[0m  0.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:14<02:52,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m78177.3282\u001b[0m       \u001b[32m89.7905\u001b[0m  0.1172\n",
      "      2    \u001b[36m62670.3354\u001b[0m       \u001b[32m30.6170\u001b[0m  0.1207\n",
      "      3    \u001b[36m39829.8544\u001b[0m       \u001b[32m12.4037\u001b[0m  0.1101\n",
      "      4    \u001b[36m27338.9708\u001b[0m        \u001b[32m6.5815\u001b[0m  0.1189\n",
      "      5    \u001b[36m18036.9162\u001b[0m        \u001b[32m4.3209\u001b[0m  0.2012\n",
      "      6     \u001b[36m9062.8561\u001b[0m        \u001b[32m3.4275\u001b[0m  0.1301\n",
      "      7     \u001b[36m1069.9480\u001b[0m        \u001b[32m2.9907\u001b[0m  0.1279\n",
      "      8      \u001b[36m170.0841\u001b[0m        \u001b[32m2.6984\u001b[0m  0.1154\n",
      "      9      500.3564        \u001b[32m2.5448\u001b[0m  0.1146\n",
      "     10       \u001b[36m78.9562\u001b[0m        \u001b[32m2.4342\u001b[0m  0.1190\n",
      "     11        \u001b[36m4.7516\u001b[0m        \u001b[32m2.3170\u001b[0m  0.1199\n",
      "     12       11.9871        \u001b[32m2.2028\u001b[0m  0.1418\n",
      "     13        \u001b[36m2.5884\u001b[0m        \u001b[32m2.1152\u001b[0m  0.1131\n",
      "     14        \u001b[36m2.4086\u001b[0m        \u001b[32m2.0313\u001b[0m  0.1215\n",
      "     15        \u001b[36m2.1915\u001b[0m        \u001b[32m1.9547\u001b[0m  0.1176\n",
      "     16        \u001b[36m2.0550\u001b[0m        \u001b[32m1.8832\u001b[0m  0.1113\n",
      "     17        \u001b[36m1.8980\u001b[0m        \u001b[32m1.8061\u001b[0m  0.1098\n",
      "     18        \u001b[36m1.7821\u001b[0m        \u001b[32m1.7419\u001b[0m  0.1128\n",
      "     19        \u001b[36m1.6780\u001b[0m        \u001b[32m1.6890\u001b[0m  0.1129\n",
      "     20        \u001b[36m1.5959\u001b[0m        \u001b[32m1.6544\u001b[0m  0.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [01:16<02:51,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m12533.8816\u001b[0m      \u001b[32m215.9717\u001b[0m  0.1262\n",
      "      2     \u001b[36m9520.2142\u001b[0m       \u001b[32m90.6319\u001b[0m  0.1193\n",
      "      3     \u001b[36m5946.1319\u001b[0m       \u001b[32m49.6593\u001b[0m  0.2015\n",
      "      4     \u001b[36m4352.4736\u001b[0m       \u001b[32m37.6861\u001b[0m  0.1383\n",
      "      5     \u001b[36m3138.3634\u001b[0m       \u001b[32m31.4569\u001b[0m  0.1160\n",
      "      6     \u001b[36m2666.5363\u001b[0m       \u001b[32m28.3673\u001b[0m  0.1112\n",
      "      7     \u001b[36m1547.2403\u001b[0m       \u001b[32m25.0429\u001b[0m  0.1218\n",
      "      8     \u001b[36m1208.3560\u001b[0m       27.4410  0.1186\n",
      "      9      \u001b[36m756.2332\u001b[0m       26.6061  0.1111\n",
      "     10      \u001b[36m588.8322\u001b[0m       28.3342  0.1101\n",
      "     11      \u001b[36m362.6656\u001b[0m       28.3254  0.1188\n",
      "     12      \u001b[36m226.8693\u001b[0m       26.2828  0.1131\n",
      "     13      \u001b[36m154.1555\u001b[0m       26.4272  0.1062\n",
      "     14      \u001b[36m100.0581\u001b[0m       25.7903  0.1195\n",
      "     15       \u001b[36m63.6795\u001b[0m       25.9478  0.1160\n",
      "     16       \u001b[36m46.9121\u001b[0m       26.4942  0.1039\n",
      "     17       \u001b[36m21.1293\u001b[0m       25.5120  0.1108\n",
      "     18       \u001b[36m17.9912\u001b[0m       25.7761  0.1118\n",
      "     19        \u001b[36m8.6166\u001b[0m       25.4821  0.1130\n",
      "     20        \u001b[36m4.3172\u001b[0m       \u001b[32m24.8237\u001b[0m  0.1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [01:19<02:48,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m6901.7629\u001b[0m      \u001b[32m169.2476\u001b[0m  0.1276\n",
      "      2     \u001b[36m2359.3659\u001b[0m       \u001b[32m61.6366\u001b[0m  0.1901\n",
      "      3      \u001b[36m366.9935\u001b[0m       \u001b[32m31.9336\u001b[0m  0.1390\n",
      "      4     1428.4473       \u001b[32m14.8492\u001b[0m  0.1115\n",
      "      5      822.9275       \u001b[32m10.8370\u001b[0m  0.1193\n",
      "      6      \u001b[36m302.4293\u001b[0m        \u001b[32m8.0486\u001b[0m  0.1148\n",
      "      7       \u001b[36m58.3891\u001b[0m        \u001b[32m6.6050\u001b[0m  0.1159\n",
      "      8      118.0149        \u001b[32m5.5260\u001b[0m  0.1153\n",
      "      9       97.3924        \u001b[32m4.7492\u001b[0m  0.1102\n",
      "     10       \u001b[36m14.1915\u001b[0m        \u001b[32m4.0644\u001b[0m  0.1086\n",
      "     11        \u001b[36m6.0529\u001b[0m        \u001b[32m3.6311\u001b[0m  0.1173\n",
      "     12        \u001b[36m4.3033\u001b[0m        \u001b[32m3.2624\u001b[0m  0.1126\n",
      "     13        \u001b[36m3.6096\u001b[0m        \u001b[32m2.9534\u001b[0m  0.1106\n",
      "     14        6.5567        \u001b[32m2.8253\u001b[0m  0.1107\n",
      "     15       24.5453        \u001b[32m2.5044\u001b[0m  0.1131\n",
      "     16      187.7632        2.6437  0.1152\n",
      "     17      725.8669        \u001b[32m2.1726\u001b[0m  0.1099\n",
      "     18     4729.5996        3.2644  0.1144\n",
      "     19     6340.1497        \u001b[32m1.9929\u001b[0m  0.1124\n",
      "     20     5989.2407        2.6328  0.1294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [01:21<02:46,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m4188.8693\u001b[0m       \u001b[32m50.6525\u001b[0m  0.1829\n",
      "      2     \u001b[36m2123.5112\u001b[0m       \u001b[32m17.4622\u001b[0m  0.1817\n",
      "      3     \u001b[36m1297.6026\u001b[0m        \u001b[32m8.4997\u001b[0m  0.1380\n",
      "      4      \u001b[36m855.8677\u001b[0m        \u001b[32m5.4496\u001b[0m  0.1211\n",
      "      5      \u001b[36m615.6895\u001b[0m        \u001b[32m3.7241\u001b[0m  0.1273\n",
      "      6      \u001b[36m422.0806\u001b[0m        \u001b[32m2.7997\u001b[0m  0.1124\n",
      "      7      \u001b[36m397.7927\u001b[0m        \u001b[32m2.7545\u001b[0m  0.1118\n",
      "      8      \u001b[36m141.0944\u001b[0m        2.7703  0.1045\n",
      "      9       \u001b[36m95.0212\u001b[0m        2.9357  0.0998\n",
      "     10       \u001b[36m76.4099\u001b[0m        3.1187  0.1009\n",
      "     11       \u001b[36m48.5009\u001b[0m        3.3356  0.1042\n",
      "     12       \u001b[36m34.4960\u001b[0m        3.5049  0.1112\n",
      "     13       \u001b[36m27.2415\u001b[0m        3.6383  0.1000\n",
      "     14       \u001b[36m17.5728\u001b[0m        3.7544  0.1049\n",
      "     15       \u001b[36m12.6049\u001b[0m        3.8993  0.1071\n",
      "     16       \u001b[36m10.1120\u001b[0m        3.9979  0.0988\n",
      "     17        \u001b[36m7.2826\u001b[0m        4.1439  0.1128\n",
      "     18        \u001b[36m5.0801\u001b[0m        4.3111  0.1118\n",
      "     19        \u001b[36m3.8952\u001b[0m        4.8076  0.1669\n",
      "     20        \u001b[36m3.0407\u001b[0m        5.5503  0.1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [01:24<02:44,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m18240.2466\u001b[0m       \u001b[32m27.2419\u001b[0m  0.1218\n",
      "      2     \u001b[36m2576.5553\u001b[0m       \u001b[32m11.1335\u001b[0m  0.1183\n",
      "      3      \u001b[36m149.7517\u001b[0m        \u001b[32m5.5005\u001b[0m  0.1120\n",
      "      4      156.3684        \u001b[32m3.4013\u001b[0m  0.1190\n",
      "      5      221.2593        \u001b[32m2.3682\u001b[0m  0.1155\n",
      "      6       \u001b[36m35.4095\u001b[0m        \u001b[32m1.9690\u001b[0m  0.1130\n",
      "      7       43.5986        \u001b[32m1.8577\u001b[0m  0.1172\n",
      "      8        \u001b[36m9.0015\u001b[0m        \u001b[32m1.8225\u001b[0m  0.1095\n",
      "      9        \u001b[36m3.6033\u001b[0m        \u001b[32m1.7840\u001b[0m  0.1102\n",
      "     10        \u001b[36m1.2686\u001b[0m        \u001b[32m1.7563\u001b[0m  0.1189\n",
      "     11        \u001b[36m1.1666\u001b[0m        \u001b[32m1.7284\u001b[0m  0.1196\n",
      "     12        \u001b[36m1.1166\u001b[0m        \u001b[32m1.7249\u001b[0m  0.1102\n",
      "     13        \u001b[36m1.0896\u001b[0m        \u001b[32m1.6884\u001b[0m  0.1111\n",
      "     14        \u001b[36m1.0655\u001b[0m        \u001b[32m1.6810\u001b[0m  0.1249\n",
      "     15        \u001b[36m1.0522\u001b[0m        \u001b[32m1.6434\u001b[0m  0.1126\n",
      "     16        1.0531        1.6452  0.1700\n",
      "     17        1.0541        \u001b[32m1.6360\u001b[0m  0.1983\n",
      "     18        \u001b[36m1.0346\u001b[0m        \u001b[32m1.6053\u001b[0m  0.1341\n",
      "     19        \u001b[36m1.0012\u001b[0m        \u001b[32m1.5742\u001b[0m  0.1092\n",
      "     20        \u001b[36m0.9938\u001b[0m        \u001b[32m1.5740\u001b[0m  0.1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [01:26<02:42,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m5.2773\u001b[0m        \u001b[32m2.2816\u001b[0m  0.1204\n",
      "      2        \u001b[36m1.6237\u001b[0m        \u001b[32m1.2792\u001b[0m  0.1312\n",
      "      3        \u001b[36m1.1829\u001b[0m        \u001b[32m1.1434\u001b[0m  0.1186\n",
      "      4        \u001b[36m1.0431\u001b[0m        \u001b[32m1.0808\u001b[0m  0.1308\n",
      "      5        \u001b[36m1.0053\u001b[0m        \u001b[32m1.0467\u001b[0m  0.1784\n",
      "      6        \u001b[36m0.9864\u001b[0m        \u001b[32m1.0303\u001b[0m  0.1315\n",
      "      7        \u001b[36m0.9625\u001b[0m        \u001b[32m1.0173\u001b[0m  0.1068\n",
      "      8        \u001b[36m0.9544\u001b[0m        \u001b[32m1.0035\u001b[0m  0.1200\n",
      "      9        \u001b[36m0.9420\u001b[0m        \u001b[32m1.0025\u001b[0m  0.1186\n",
      "     10        \u001b[36m0.9305\u001b[0m        \u001b[32m0.9857\u001b[0m  0.1229\n",
      "     11        \u001b[36m0.9280\u001b[0m        0.9938  0.1093\n",
      "     12        \u001b[36m0.9217\u001b[0m        0.9897  0.1186\n",
      "     13        \u001b[36m0.9066\u001b[0m        \u001b[32m0.9845\u001b[0m  0.1133\n",
      "     14        0.9105        \u001b[32m0.9725\u001b[0m  0.1567\n",
      "     15        0.9106        \u001b[32m0.9699\u001b[0m  0.1787\n",
      "     16        \u001b[36m0.9016\u001b[0m        \u001b[32m0.9680\u001b[0m  0.1118\n",
      "     17        \u001b[36m0.8948\u001b[0m        \u001b[32m0.9564\u001b[0m  0.1262\n",
      "     18        \u001b[36m0.8936\u001b[0m        0.9748  0.1141\n",
      "     19        0.9065        1.0037  0.1168\n",
      "     20        0.9204        0.9573  0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [01:29<02:42,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m14.6863\u001b[0m     \u001b[32m7156.1762\u001b[0m  0.1171\n",
      "      2        \u001b[36m4.9048\u001b[0m    57192.0965  0.1289\n",
      "      3        \u001b[36m2.3684\u001b[0m   123717.0581  0.1126\n",
      "      4        \u001b[36m1.6854\u001b[0m   176881.9875  0.1160\n",
      "      5        \u001b[36m1.4554\u001b[0m   235879.1693  0.1202\n",
      "      6        \u001b[36m1.2113\u001b[0m   311128.9008  0.1296\n",
      "      7        \u001b[36m1.1022\u001b[0m   406793.1821  0.1079\n",
      "      8        \u001b[36m1.0389\u001b[0m   450127.2545  0.1113\n",
      "      9        \u001b[36m0.9946\u001b[0m   516988.2213  0.1178\n",
      "     10        \u001b[36m0.9631\u001b[0m   568272.7483  0.1083\n",
      "     11        \u001b[36m0.9427\u001b[0m   605849.2991  0.1103\n",
      "     12        \u001b[36m0.9223\u001b[0m   640212.9117  0.1495\n",
      "     13        \u001b[36m0.9094\u001b[0m   671448.8367  0.1702\n",
      "     14        \u001b[36m0.9007\u001b[0m   710974.3715  0.1243\n",
      "     15        \u001b[36m0.8951\u001b[0m   731806.6542  0.1166\n",
      "     16        \u001b[36m0.8904\u001b[0m   753070.8665  0.1189\n",
      "     17        \u001b[36m0.8894\u001b[0m   738122.8880  0.1098\n",
      "     18        \u001b[36m0.8774\u001b[0m   759605.3067  0.1185\n",
      "     19        \u001b[36m0.8738\u001b[0m   762408.0543  0.1117\n",
      "     20        \u001b[36m0.8721\u001b[0m   741221.0111  0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [01:31<02:39,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m19248.1110\u001b[0m        \u001b[32m4.3673\u001b[0m  0.1327\n",
      "      2     \u001b[36m8047.2490\u001b[0m        \u001b[32m2.6957\u001b[0m  0.1340\n",
      "      3     \u001b[36m1963.7711\u001b[0m        \u001b[32m1.8624\u001b[0m  0.1113\n",
      "      4      \u001b[36m172.7939\u001b[0m        \u001b[32m1.4853\u001b[0m  0.1173\n",
      "      5        \u001b[36m1.6889\u001b[0m        \u001b[32m1.3250\u001b[0m  0.1121\n",
      "      6        4.7893        \u001b[32m1.2090\u001b[0m  0.1103\n",
      "      7        3.7129        \u001b[32m1.1235\u001b[0m  0.1081\n",
      "      8        \u001b[36m1.2619\u001b[0m        \u001b[32m1.0725\u001b[0m  0.1124\n",
      "      9        1.2869        \u001b[32m1.0178\u001b[0m  0.1160\n",
      "     10        \u001b[36m1.1717\u001b[0m        1.0178  0.1107\n",
      "     11        \u001b[36m1.1403\u001b[0m        \u001b[32m0.9846\u001b[0m  0.1902\n",
      "     12        \u001b[36m1.1261\u001b[0m        \u001b[32m0.9663\u001b[0m  0.1498\n",
      "     13        \u001b[36m1.1043\u001b[0m        \u001b[32m0.9553\u001b[0m  0.1200\n",
      "     14        \u001b[36m1.0919\u001b[0m        \u001b[32m0.9494\u001b[0m  0.1111\n",
      "     15        \u001b[36m1.0831\u001b[0m        \u001b[32m0.9301\u001b[0m  0.1207\n",
      "     16        \u001b[36m1.0711\u001b[0m        0.9331  0.1239\n",
      "     17        \u001b[36m1.0666\u001b[0m        0.9335  0.1130\n",
      "     18        \u001b[36m1.0587\u001b[0m        0.9320  0.1202\n",
      "     19        1.0595        \u001b[32m0.9173\u001b[0m  0.1229\n",
      "     20        \u001b[36m1.0465\u001b[0m        0.9432  0.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [01:34<02:36,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m169.4119\u001b[0m  \u001b[32m1005528.3276\u001b[0m  0.1197\n",
      "      2       \u001b[36m31.6568\u001b[0m   \u001b[32m586319.1769\u001b[0m  0.1172\n",
      "      3        \u001b[36m6.2738\u001b[0m   \u001b[32m479686.4087\u001b[0m  0.1144\n",
      "      4        \u001b[36m4.0796\u001b[0m   \u001b[32m423572.4313\u001b[0m  0.1195\n",
      "      5        \u001b[36m3.5006\u001b[0m   \u001b[32m411880.2986\u001b[0m  0.1124\n",
      "      6        \u001b[36m2.9062\u001b[0m   \u001b[32m353954.8203\u001b[0m  0.1181\n",
      "      7        \u001b[36m2.5602\u001b[0m   \u001b[32m280836.3561\u001b[0m  0.1096\n",
      "      8        \u001b[36m2.1134\u001b[0m   \u001b[32m223420.0149\u001b[0m  0.1114\n",
      "      9        \u001b[36m1.8340\u001b[0m   \u001b[32m194042.2858\u001b[0m  0.1517\n",
      "     10        \u001b[36m1.6769\u001b[0m   \u001b[32m166991.1724\u001b[0m  0.1785\n",
      "     11        \u001b[36m1.4749\u001b[0m   \u001b[32m154519.7494\u001b[0m  0.1184\n",
      "     12        \u001b[36m1.3541\u001b[0m   \u001b[32m144940.8249\u001b[0m  0.1119\n",
      "     13        \u001b[36m1.2686\u001b[0m   \u001b[32m126604.8014\u001b[0m  0.1211\n",
      "     14        \u001b[36m1.2174\u001b[0m   \u001b[32m119178.9136\u001b[0m  0.1236\n",
      "     15        \u001b[36m1.1618\u001b[0m   \u001b[32m114538.1144\u001b[0m  0.1144\n",
      "     16        \u001b[36m1.1494\u001b[0m   \u001b[32m113820.5302\u001b[0m  0.1191\n",
      "     17        \u001b[36m1.1092\u001b[0m   \u001b[32m105984.7175\u001b[0m  0.1443\n",
      "     18        \u001b[36m1.0947\u001b[0m    \u001b[32m99677.1142\u001b[0m  0.1129\n",
      "     19        1.1002   108221.8999  0.1099\n",
      "     20        \u001b[36m1.0737\u001b[0m    \u001b[32m90860.5406\u001b[0m  0.1188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [01:36<02:34,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m15776.1121\u001b[0m       \u001b[32m18.9338\u001b[0m  0.1199\n",
      "      2     \u001b[36m3929.0937\u001b[0m        \u001b[32m9.4232\u001b[0m  0.1184\n",
      "      3      \u001b[36m702.7447\u001b[0m        \u001b[32m6.5198\u001b[0m  0.1044\n",
      "      4       \u001b[36m13.6700\u001b[0m        \u001b[32m4.8388\u001b[0m  0.1063\n",
      "      5       54.7046        \u001b[32m4.1365\u001b[0m  0.1071\n",
      "      6       37.7985        \u001b[32m3.7068\u001b[0m  0.1107\n",
      "      7        \u001b[36m8.8577\u001b[0m        \u001b[32m3.2967\u001b[0m  0.1068\n",
      "      8        \u001b[36m5.4928\u001b[0m        \u001b[32m2.9843\u001b[0m  0.1779\n",
      "      9        \u001b[36m3.5023\u001b[0m        \u001b[32m2.7643\u001b[0m  0.1411\n",
      "     10        \u001b[36m2.3635\u001b[0m        \u001b[32m2.5929\u001b[0m  0.1185\n",
      "     11        \u001b[36m2.1260\u001b[0m        \u001b[32m2.4186\u001b[0m  0.1172\n",
      "     12        \u001b[36m1.9750\u001b[0m        \u001b[32m2.2729\u001b[0m  0.1153\n",
      "     13        \u001b[36m1.8400\u001b[0m        \u001b[32m2.1432\u001b[0m  0.1171\n",
      "     14        \u001b[36m1.7392\u001b[0m        \u001b[32m2.0215\u001b[0m  0.1191\n",
      "     15        \u001b[36m1.6432\u001b[0m        \u001b[32m1.9336\u001b[0m  0.1097\n",
      "     16        \u001b[36m1.5649\u001b[0m        \u001b[32m1.8326\u001b[0m  0.1152\n",
      "     17        \u001b[36m1.4969\u001b[0m        \u001b[32m1.7557\u001b[0m  0.1111\n",
      "     18        \u001b[36m1.4320\u001b[0m        \u001b[32m1.6861\u001b[0m  0.1096\n",
      "     19        \u001b[36m1.3869\u001b[0m        \u001b[32m1.6299\u001b[0m  0.1210\n",
      "     20        \u001b[36m1.3396\u001b[0m        \u001b[32m1.5767\u001b[0m  0.1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [01:39<02:29,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m724609.2738\u001b[0m        \u001b[32m5.5335\u001b[0m  0.1197\n",
      "      2   \u001b[36m564176.1960\u001b[0m        \u001b[32m3.0336\u001b[0m  0.1712\n",
      "      3   \u001b[36m497537.4466\u001b[0m        3.4406  0.1122\n",
      "      4   \u001b[36m397096.6933\u001b[0m        \u001b[32m2.3393\u001b[0m  0.1122\n",
      "      5   \u001b[36m320590.2227\u001b[0m        \u001b[32m1.7594\u001b[0m  0.1149\n",
      "      6   \u001b[36m273504.6611\u001b[0m        \u001b[32m1.5933\u001b[0m  0.2002\n",
      "      7   \u001b[36m234192.2888\u001b[0m        \u001b[32m1.5488\u001b[0m  0.1320\n",
      "      8   \u001b[36m199023.5275\u001b[0m        \u001b[32m1.4963\u001b[0m  0.1112\n",
      "      9   \u001b[36m163056.5106\u001b[0m        \u001b[32m1.4152\u001b[0m  0.1114\n",
      "     10   \u001b[36m139444.3087\u001b[0m        \u001b[32m1.3441\u001b[0m  0.1109\n",
      "     11   \u001b[36m123433.4613\u001b[0m        1.4005  0.1196\n",
      "     12   \u001b[36m103651.6677\u001b[0m        1.3445  0.1148\n",
      "     13    \u001b[36m87961.2025\u001b[0m        \u001b[32m1.2853\u001b[0m  0.1109\n",
      "     14    \u001b[36m75862.0626\u001b[0m        \u001b[32m1.2216\u001b[0m  0.1104\n",
      "     15    \u001b[36m65428.0618\u001b[0m        1.2656  0.1184\n",
      "     16    \u001b[36m56371.5791\u001b[0m        1.2436  0.1192\n",
      "     17    \u001b[36m52838.4731\u001b[0m        \u001b[32m1.1452\u001b[0m  0.1118\n",
      "     18    \u001b[36m42314.8454\u001b[0m        \u001b[32m1.0996\u001b[0m  0.1200\n",
      "     19    \u001b[36m34909.7362\u001b[0m        1.2575  0.1099\n",
      "     20    \u001b[36m30255.1203\u001b[0m        1.1957  0.1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:41<02:28,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m231986.9597\u001b[0m        \u001b[32m2.4989\u001b[0m  0.1155\n",
      "      2   \u001b[36m214220.2299\u001b[0m        \u001b[32m2.4360\u001b[0m  0.1296\n",
      "      3    \u001b[36m50695.3912\u001b[0m        \u001b[32m1.9388\u001b[0m  0.1302\n",
      "      4    \u001b[36m25458.9028\u001b[0m        \u001b[32m1.7788\u001b[0m  0.1447\n",
      "      5     \u001b[36m4555.3012\u001b[0m        \u001b[32m1.7120\u001b[0m  0.1764\n",
      "      6      \u001b[36m879.0209\u001b[0m        \u001b[32m1.6629\u001b[0m  0.1148\n",
      "      7      \u001b[36m222.0814\u001b[0m        \u001b[32m1.6088\u001b[0m  0.1114\n",
      "      8       \u001b[36m22.7980\u001b[0m        \u001b[32m1.5865\u001b[0m  0.1086\n",
      "      9        \u001b[36m2.5617\u001b[0m        \u001b[32m1.5391\u001b[0m  0.1211\n",
      "     10        2.9975        \u001b[32m1.4991\u001b[0m  0.1092\n",
      "     11        2.8611        \u001b[32m1.4714\u001b[0m  0.1113\n",
      "     12        \u001b[36m1.6916\u001b[0m        \u001b[32m1.4293\u001b[0m  0.1075\n",
      "     13        \u001b[36m1.4072\u001b[0m        \u001b[32m1.3954\u001b[0m  0.1100\n",
      "     14        \u001b[36m1.3643\u001b[0m        \u001b[32m1.3693\u001b[0m  0.1077\n",
      "     15        \u001b[36m1.3389\u001b[0m        \u001b[32m1.3498\u001b[0m  0.1199\n",
      "     16     1461.7399        1.3672  0.1194\n",
      "     17        8.5899        1.3588  0.1112\n",
      "     18      673.6880        \u001b[32m1.2716\u001b[0m  0.1218\n",
      "     19       58.2664        \u001b[32m1.2246\u001b[0m  0.1158\n",
      "     20        9.9414        \u001b[32m1.1976\u001b[0m  0.1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [01:44<02:25,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m7.8523\u001b[0m        \u001b[32m3.2269\u001b[0m  0.1141\n",
      "      2        \u001b[36m2.3010\u001b[0m        \u001b[32m2.3723\u001b[0m  0.1260\n",
      "      3        \u001b[36m1.8961\u001b[0m        \u001b[32m1.8434\u001b[0m  0.1923\n",
      "      4        \u001b[36m1.5554\u001b[0m        \u001b[32m1.5941\u001b[0m  0.1391\n",
      "      5        \u001b[36m1.4051\u001b[0m        \u001b[32m1.4820\u001b[0m  0.1083\n",
      "      6        \u001b[36m1.2957\u001b[0m        \u001b[32m1.3614\u001b[0m  0.1117\n",
      "      7        \u001b[36m1.1942\u001b[0m        \u001b[32m1.3058\u001b[0m  0.1187\n",
      "      8        \u001b[36m1.1101\u001b[0m        \u001b[32m1.2639\u001b[0m  0.1213\n",
      "      9        \u001b[36m1.0560\u001b[0m        \u001b[32m1.2297\u001b[0m  0.1147\n",
      "     10        \u001b[36m1.0285\u001b[0m        \u001b[32m1.2189\u001b[0m  0.1130\n",
      "     11        \u001b[36m1.0171\u001b[0m        \u001b[32m1.1977\u001b[0m  0.1104\n",
      "     12        \u001b[36m1.0097\u001b[0m        1.2658  0.1096\n",
      "     13        \u001b[36m0.9996\u001b[0m        1.1989  0.1114\n",
      "     14        1.0008        1.2208  0.1110\n",
      "     15        \u001b[36m0.9884\u001b[0m        1.2051  0.1219\n",
      "     16        0.9898        1.2137  0.1218\n",
      "     17        \u001b[36m0.9806\u001b[0m        \u001b[32m1.1954\u001b[0m  0.1137\n",
      "     18        0.9840        \u001b[32m1.1770\u001b[0m  0.1086\n",
      "     19        \u001b[36m0.9745\u001b[0m        1.1951  0.1184\n",
      "     20        0.9807        1.2152  0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [01:46<02:22,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m80531.0938\u001b[0m      \u001b[32m978.5050\u001b[0m  0.1514\n",
      "      2    \u001b[36m64600.2539\u001b[0m      \u001b[32m396.9413\u001b[0m  0.1796\n",
      "      3    \u001b[36m58477.8839\u001b[0m      \u001b[32m197.0089\u001b[0m  0.1260\n",
      "      4    \u001b[36m47742.4692\u001b[0m      \u001b[32m109.7021\u001b[0m  0.1107\n",
      "      5    \u001b[36m41861.8164\u001b[0m       \u001b[32m75.1270\u001b[0m  0.1157\n",
      "      6    \u001b[36m34913.0702\u001b[0m       \u001b[32m53.3730\u001b[0m  0.1126\n",
      "      7    \u001b[36m31444.7927\u001b[0m       \u001b[32m43.8394\u001b[0m  0.1171\n",
      "      8    \u001b[36m27199.0585\u001b[0m       \u001b[32m36.2213\u001b[0m  0.1100\n",
      "      9    \u001b[36m24765.2269\u001b[0m       \u001b[32m31.5363\u001b[0m  0.1127\n",
      "     10    \u001b[36m20560.2134\u001b[0m       \u001b[32m25.2493\u001b[0m  0.1123\n",
      "     11    \u001b[36m20066.1257\u001b[0m       \u001b[32m20.4427\u001b[0m  0.1200\n",
      "     12    \u001b[36m16221.8573\u001b[0m       \u001b[32m14.4436\u001b[0m  0.1175\n",
      "     13    \u001b[36m15053.4240\u001b[0m       \u001b[32m12.5882\u001b[0m  0.1106\n",
      "     14    \u001b[36m13461.1466\u001b[0m       \u001b[32m11.1085\u001b[0m  0.1195\n",
      "     15    \u001b[36m11755.6650\u001b[0m       \u001b[32m10.1239\u001b[0m  0.1134\n",
      "     16    \u001b[36m10859.2785\u001b[0m        \u001b[32m9.5522\u001b[0m  0.1160\n",
      "     17     \u001b[36m9813.3582\u001b[0m        \u001b[32m9.2048\u001b[0m  0.1100\n",
      "     18     \u001b[36m9011.6987\u001b[0m        \u001b[32m8.7906\u001b[0m  0.1097\n",
      "     19     \u001b[36m7902.8742\u001b[0m        \u001b[32m8.0574\u001b[0m  0.1102\n",
      "     20     \u001b[36m7246.9351\u001b[0m        \u001b[32m7.5075\u001b[0m  0.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [01:49<02:20,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m18.7227\u001b[0m        \u001b[32m5.8560\u001b[0m  0.1426\n",
      "      2        \u001b[36m4.2677\u001b[0m        \u001b[32m3.2288\u001b[0m  0.1282\n",
      "      3        \u001b[36m2.3345\u001b[0m        \u001b[32m1.9632\u001b[0m  0.1117\n",
      "      4        \u001b[36m1.8640\u001b[0m        \u001b[32m1.7151\u001b[0m  0.1111\n",
      "      5        \u001b[36m1.6580\u001b[0m        \u001b[32m1.5805\u001b[0m  0.1117\n",
      "      6        \u001b[36m1.5187\u001b[0m        \u001b[32m1.4267\u001b[0m  0.1190\n",
      "      7        \u001b[36m1.4217\u001b[0m        \u001b[32m1.3156\u001b[0m  0.1197\n",
      "      8        \u001b[36m1.3488\u001b[0m        \u001b[32m1.2224\u001b[0m  0.1214\n",
      "      9        \u001b[36m1.2874\u001b[0m        \u001b[32m1.1601\u001b[0m  0.1182\n",
      "     10        \u001b[36m1.2458\u001b[0m        \u001b[32m1.0810\u001b[0m  0.1118\n",
      "     11        \u001b[36m1.1902\u001b[0m        \u001b[32m1.0468\u001b[0m  0.1184\n",
      "     12        \u001b[36m1.1660\u001b[0m        \u001b[32m0.9928\u001b[0m  0.1105\n",
      "     13        \u001b[36m1.1398\u001b[0m        \u001b[32m0.9745\u001b[0m  0.1092\n",
      "     14        \u001b[36m1.1212\u001b[0m        \u001b[32m0.9494\u001b[0m  0.1141\n",
      "     15        \u001b[36m1.1055\u001b[0m        \u001b[32m0.9384\u001b[0m  0.1113\n",
      "     16        \u001b[36m1.0952\u001b[0m        \u001b[32m0.9294\u001b[0m  0.1066\n",
      "     17        \u001b[36m1.0915\u001b[0m        \u001b[32m0.9090\u001b[0m  0.1216\n",
      "     18        \u001b[36m1.0811\u001b[0m        0.9143  0.1175\n",
      "     19        \u001b[36m1.0770\u001b[0m        \u001b[32m0.8934\u001b[0m  0.1909\n",
      "     20        \u001b[36m1.0592\u001b[0m        0.9077  0.1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [01:51<02:18,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m252661.9899\u001b[0m        \u001b[32m5.9922\u001b[0m  0.1199\n",
      "      2   \u001b[36m187495.6270\u001b[0m        \u001b[32m3.4144\u001b[0m  0.1255\n",
      "      3   \u001b[36m155356.3388\u001b[0m        \u001b[32m2.3575\u001b[0m  0.1268\n",
      "      4   \u001b[36m111447.3764\u001b[0m        \u001b[32m1.8581\u001b[0m  0.1218\n",
      "      5    \u001b[36m95506.3288\u001b[0m        \u001b[32m1.4444\u001b[0m  0.1127\n",
      "      6    \u001b[36m73905.0318\u001b[0m        \u001b[32m1.3986\u001b[0m  0.1123\n",
      "      7    \u001b[36m60760.2589\u001b[0m        1.5354  0.1161\n",
      "      8    \u001b[36m44052.6099\u001b[0m        1.6010  0.1098\n",
      "      9    \u001b[36m34160.9878\u001b[0m        1.7442  0.1202\n",
      "     10    \u001b[36m30409.7886\u001b[0m        1.6791  0.1130\n",
      "     11    \u001b[36m17952.8266\u001b[0m        1.5606  0.1171\n",
      "     12    \u001b[36m11981.8829\u001b[0m        \u001b[32m1.1690\u001b[0m  0.1079\n",
      "     13     \u001b[36m8132.7889\u001b[0m        \u001b[32m1.1194\u001b[0m  0.1212\n",
      "     14     \u001b[36m4706.7413\u001b[0m        \u001b[32m1.0882\u001b[0m  0.1054\n",
      "     15     \u001b[36m4012.5781\u001b[0m        \u001b[32m1.0880\u001b[0m  0.1110\n",
      "     16     \u001b[36m1313.0856\u001b[0m        \u001b[32m1.0671\u001b[0m  0.1113\n",
      "     17      \u001b[36m726.5691\u001b[0m        \u001b[32m1.0584\u001b[0m  0.1700\n",
      "     18      \u001b[36m525.0457\u001b[0m        \u001b[32m1.0540\u001b[0m  0.1619\n",
      "     19      \u001b[36m185.4639\u001b[0m        \u001b[32m1.0444\u001b[0m  0.1169\n",
      "     20       \u001b[36m58.1180\u001b[0m        \u001b[32m1.0322\u001b[0m  0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [01:54<02:16,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m155.1159\u001b[0m   \u001b[32m188693.3792\u001b[0m  0.1229\n",
      "      2       \u001b[36m38.0286\u001b[0m   424301.4883  0.1277\n",
      "      3       \u001b[36m12.2639\u001b[0m   348307.0602  0.1111\n",
      "      4        \u001b[36m6.0484\u001b[0m   \u001b[32m176883.1210\u001b[0m  0.1107\n",
      "      5        \u001b[36m3.8347\u001b[0m    \u001b[32m81623.2570\u001b[0m  0.1102\n",
      "      6        \u001b[36m2.9465\u001b[0m    \u001b[32m32226.9215\u001b[0m  0.1202\n",
      "      7        \u001b[36m2.5435\u001b[0m     \u001b[32m7208.6227\u001b[0m  0.1140\n",
      "      8        \u001b[36m2.2662\u001b[0m        \u001b[32m4.4084\u001b[0m  0.1095\n",
      "      9        \u001b[36m2.0594\u001b[0m     5357.3379  0.1167\n",
      "     10        \u001b[36m1.8978\u001b[0m    27676.9067  0.1154\n",
      "     11        \u001b[36m1.7618\u001b[0m    61087.1122  0.1114\n",
      "     12        \u001b[36m1.6463\u001b[0m    91150.4980  0.1209\n",
      "     13        \u001b[36m1.5499\u001b[0m   136743.1177  0.1693\n",
      "     14        \u001b[36m1.4606\u001b[0m   166572.7607  0.1203\n",
      "     15        \u001b[36m1.3957\u001b[0m   205875.0538  0.1698\n",
      "     16        \u001b[36m1.3279\u001b[0m   246373.4721  0.1786\n",
      "     17        \u001b[36m1.2775\u001b[0m   263694.1818  0.1295\n",
      "     18        \u001b[36m1.2247\u001b[0m   299522.6255  0.1703\n",
      "     19        \u001b[36m1.1834\u001b[0m   298704.8252  0.1388\n",
      "     20        \u001b[36m1.1442\u001b[0m   336520.6669  0.1232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [01:56<02:15,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m18970.7381\u001b[0m        \u001b[32m3.7015\u001b[0m  0.1300\n",
      "      2     \u001b[36m3387.2954\u001b[0m        \u001b[32m2.4903\u001b[0m  0.1240\n",
      "      3      \u001b[36m126.9339\u001b[0m        \u001b[32m2.1255\u001b[0m  0.1152\n",
      "      4        \u001b[36m4.0827\u001b[0m        \u001b[32m1.9877\u001b[0m  0.1170\n",
      "      5       21.8013        \u001b[32m1.9528\u001b[0m  0.1139\n",
      "      6        7.7599        \u001b[32m1.9248\u001b[0m  0.1211\n",
      "      7        \u001b[36m2.3638\u001b[0m        \u001b[32m1.8500\u001b[0m  0.1150\n",
      "      8        \u001b[36m2.0774\u001b[0m        \u001b[32m1.8031\u001b[0m  0.1113\n",
      "      9        \u001b[36m1.8189\u001b[0m        \u001b[32m1.7738\u001b[0m  0.1306\n",
      "     10        \u001b[36m1.7714\u001b[0m        \u001b[32m1.7236\u001b[0m  0.1102\n",
      "     11        \u001b[36m1.6901\u001b[0m        \u001b[32m1.6560\u001b[0m  0.1179\n",
      "     12        \u001b[36m1.6404\u001b[0m        \u001b[32m1.6067\u001b[0m  0.1288\n",
      "     13        \u001b[36m1.5791\u001b[0m        \u001b[32m1.5764\u001b[0m  0.1584\n",
      "     14        \u001b[36m1.5453\u001b[0m        \u001b[32m1.5707\u001b[0m  0.1101\n",
      "     15        \u001b[36m1.4928\u001b[0m        \u001b[32m1.5166\u001b[0m  0.1106\n",
      "     16      114.2488        \u001b[32m1.4921\u001b[0m  0.1091\n",
      "     17      239.5795        \u001b[32m1.4679\u001b[0m  0.1116\n",
      "     18       16.4279        \u001b[32m1.4637\u001b[0m  0.1098\n",
      "     19        7.4088        \u001b[32m1.4530\u001b[0m  0.1128\n",
      "     20       13.3490        \u001b[32m1.4108\u001b[0m  0.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [01:59<02:11,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m46088.2818\u001b[0m        \u001b[32m1.4651\u001b[0m  0.1068\n",
      "      2    \u001b[36m29846.0539\u001b[0m        \u001b[32m1.1640\u001b[0m  0.1169\n",
      "      3    \u001b[36m19751.2086\u001b[0m        \u001b[32m1.0870\u001b[0m  0.1051\n",
      "      4    \u001b[36m14823.7551\u001b[0m        1.0915  0.1082\n",
      "      5     \u001b[36m7908.0332\u001b[0m        \u001b[32m1.0827\u001b[0m  0.1079\n",
      "      6     \u001b[36m6773.6524\u001b[0m        1.1061  0.1025\n",
      "      7     \u001b[36m2364.0887\u001b[0m        1.1032  0.1084\n",
      "      8     \u001b[36m1689.3275\u001b[0m        1.1046  0.1108\n",
      "      9      \u001b[36m562.6812\u001b[0m        1.0937  0.1129\n",
      "     10      \u001b[36m354.8835\u001b[0m        \u001b[32m1.0771\u001b[0m  0.1011\n",
      "     11      \u001b[36m114.1564\u001b[0m        \u001b[32m1.0755\u001b[0m  0.1092\n",
      "     12       \u001b[36m44.1882\u001b[0m        \u001b[32m1.0514\u001b[0m  0.1419\n",
      "     13        \u001b[36m8.8905\u001b[0m        \u001b[32m1.0446\u001b[0m  0.1460\n",
      "     14        \u001b[36m2.1517\u001b[0m        \u001b[32m1.0175\u001b[0m  0.1105\n",
      "     15        7.1874        \u001b[32m1.0073\u001b[0m  0.1062\n",
      "     16        \u001b[36m0.9571\u001b[0m        1.0153  0.1012\n",
      "     17        1.1258        1.0150  0.1101\n",
      "     18        1.0390        1.0253  0.1133\n",
      "     19        \u001b[36m0.9554\u001b[0m        1.0152  0.1085\n",
      "     20        \u001b[36m0.9176\u001b[0m        1.0104  0.1082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [02:01<02:05,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m20.9940\u001b[0m   \u001b[32m256456.6209\u001b[0m  0.1100\n",
      "      2        \u001b[36m4.3286\u001b[0m   331659.1481  0.1135\n",
      "      3        \u001b[36m2.0460\u001b[0m   365457.6388  0.0966\n",
      "      4        \u001b[36m1.6900\u001b[0m   365056.4665  0.1076\n",
      "      5        \u001b[36m1.4316\u001b[0m   422471.1309  0.1092\n",
      "      6        \u001b[36m1.3302\u001b[0m   486910.9842  0.1217\n",
      "      7        \u001b[36m1.2180\u001b[0m   560090.3143  0.1067\n",
      "      8        \u001b[36m1.1521\u001b[0m   615617.9372  0.1074\n",
      "      9        \u001b[36m1.1074\u001b[0m   645202.1369  0.1019\n",
      "     10        \u001b[36m1.0928\u001b[0m   736721.0928  0.1119\n",
      "     11        \u001b[36m1.0511\u001b[0m   758684.3926  0.1175\n",
      "     12        \u001b[36m1.0152\u001b[0m   814025.6377  0.1621\n",
      "     13        \u001b[36m1.0029\u001b[0m   899582.2620  0.1315\n",
      "     14        \u001b[36m0.9949\u001b[0m   945338.3352  0.1216\n",
      "     15        \u001b[36m0.9674\u001b[0m  1058276.1344  0.1223\n",
      "     16        \u001b[36m0.9629\u001b[0m  1115742.6059  0.1138\n",
      "     17        \u001b[36m0.9616\u001b[0m  1127033.8802  0.1216\n",
      "     18        0.9644  1207848.2613  0.1123\n",
      "     19        \u001b[36m0.9452\u001b[0m  1259270.2890  0.1147\n",
      "     20        \u001b[36m0.9380\u001b[0m  1243652.0008  0.1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [02:03<02:02,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m37040.6828\u001b[0m      \u001b[32m167.1799\u001b[0m  0.1199\n",
      "      2    \u001b[36m21320.8843\u001b[0m       \u001b[32m62.7691\u001b[0m  0.1407\n",
      "      3    \u001b[36m17308.8322\u001b[0m       \u001b[32m33.0473\u001b[0m  0.1281\n",
      "      4     \u001b[36m5582.0663\u001b[0m       \u001b[32m20.5285\u001b[0m  0.1105\n",
      "      5     \u001b[36m2923.2092\u001b[0m       \u001b[32m14.3674\u001b[0m  0.1126\n",
      "      6      \u001b[36m708.5132\u001b[0m        \u001b[32m9.6250\u001b[0m  0.1125\n",
      "      7       \u001b[36m10.0418\u001b[0m        \u001b[32m6.7173\u001b[0m  0.1096\n",
      "      8       21.8297        \u001b[32m5.2978\u001b[0m  0.1082\n",
      "      9        \u001b[36m6.9927\u001b[0m        \u001b[32m4.5542\u001b[0m  0.1499\n",
      "     10        \u001b[36m6.4971\u001b[0m        \u001b[32m3.9883\u001b[0m  0.1813\n",
      "     11        \u001b[36m4.9624\u001b[0m        \u001b[32m3.6136\u001b[0m  0.1267\n",
      "     12        \u001b[36m4.4645\u001b[0m        \u001b[32m3.3870\u001b[0m  0.1122\n",
      "     13        \u001b[36m4.1461\u001b[0m        \u001b[32m3.2076\u001b[0m  0.1177\n",
      "     14        \u001b[36m3.9051\u001b[0m        \u001b[32m3.0525\u001b[0m  0.1204\n",
      "     15        \u001b[36m3.7199\u001b[0m        \u001b[32m2.9555\u001b[0m  0.1189\n",
      "     16        \u001b[36m3.5474\u001b[0m        \u001b[32m2.8515\u001b[0m  0.1101\n",
      "     17        \u001b[36m3.4066\u001b[0m        \u001b[32m2.7626\u001b[0m  0.1212\n",
      "     18        \u001b[36m3.2867\u001b[0m        \u001b[32m2.6854\u001b[0m  0.1843\n",
      "     19        \u001b[36m3.1807\u001b[0m        \u001b[32m2.6290\u001b[0m  0.1358\n",
      "     20        \u001b[36m3.0719\u001b[0m        \u001b[32m2.5286\u001b[0m  0.1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [02:06<02:03,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m82.7122\u001b[0m  \u001b[32m1882330.0080\u001b[0m  0.1547\n",
      "      2       \u001b[36m32.0290\u001b[0m  \u001b[32m1269783.2846\u001b[0m  0.1401\n",
      "      3       \u001b[36m11.5693\u001b[0m  \u001b[32m1028647.7739\u001b[0m  0.1202\n",
      "      4        \u001b[36m5.1530\u001b[0m   \u001b[32m904150.1554\u001b[0m  0.1182\n",
      "      5        \u001b[36m2.8970\u001b[0m   \u001b[32m853323.6947\u001b[0m  0.1297\n",
      "      6        \u001b[36m2.3608\u001b[0m   \u001b[32m814932.1045\u001b[0m  0.1987\n",
      "      7        \u001b[36m1.9467\u001b[0m   \u001b[32m790320.4298\u001b[0m  0.1418\n",
      "      8        \u001b[36m1.6897\u001b[0m   \u001b[32m738216.0361\u001b[0m  0.1099\n",
      "      9        \u001b[36m1.5044\u001b[0m   \u001b[32m708796.0440\u001b[0m  0.1182\n",
      "     10        \u001b[36m1.3734\u001b[0m   \u001b[32m673620.2461\u001b[0m  0.1181\n",
      "     11        \u001b[36m1.2732\u001b[0m   \u001b[32m651776.4871\u001b[0m  0.1204\n",
      "     12        \u001b[36m1.2072\u001b[0m   \u001b[32m625926.8626\u001b[0m  0.1095\n",
      "     13        \u001b[36m1.1804\u001b[0m   \u001b[32m602020.7519\u001b[0m  0.1325\n",
      "     14        \u001b[36m1.1416\u001b[0m   \u001b[32m580243.5087\u001b[0m  0.1313\n",
      "     15        \u001b[36m1.1080\u001b[0m   \u001b[32m549537.0772\u001b[0m  0.1159\n",
      "     16        \u001b[36m1.0874\u001b[0m   \u001b[32m528433.7280\u001b[0m  0.1101\n",
      "     17        \u001b[36m1.0790\u001b[0m   \u001b[32m517489.4038\u001b[0m  0.1134\n",
      "     18        \u001b[36m1.0610\u001b[0m   \u001b[32m475660.1985\u001b[0m  0.1077\n",
      "     19        \u001b[36m1.0475\u001b[0m   \u001b[32m397814.8471\u001b[0m  0.1123\n",
      "     20        \u001b[36m1.0359\u001b[0m   \u001b[32m349607.8002\u001b[0m  0.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [02:08<02:02,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m205293.4053\u001b[0m     \u001b[32m2647.2925\u001b[0m  0.1177\n",
      "      2   \u001b[36m154793.5083\u001b[0m      \u001b[32m785.6968\u001b[0m  0.1245\n",
      "      3   \u001b[36m112744.6833\u001b[0m      \u001b[32m117.3274\u001b[0m  0.1145\n",
      "      4    \u001b[36m85327.3992\u001b[0m       \u001b[32m38.1275\u001b[0m  0.1877\n",
      "      5    \u001b[36m59964.8209\u001b[0m       \u001b[32m31.9756\u001b[0m  0.1421\n",
      "      6    \u001b[36m43716.6833\u001b[0m       \u001b[32m19.0526\u001b[0m  0.1145\n",
      "      7    \u001b[36m25699.5366\u001b[0m       \u001b[32m15.8193\u001b[0m  0.1103\n",
      "      8    \u001b[36m17447.3809\u001b[0m       \u001b[32m13.3625\u001b[0m  0.1286\n",
      "      9    \u001b[36m14914.6625\u001b[0m       \u001b[32m11.6463\u001b[0m  0.1193\n",
      "     10     \u001b[36m6056.7187\u001b[0m       \u001b[32m10.0201\u001b[0m  0.1159\n",
      "     11     \u001b[36m2692.1626\u001b[0m        \u001b[32m8.9816\u001b[0m  0.1146\n",
      "     12     \u001b[36m1621.2669\u001b[0m        \u001b[32m7.9040\u001b[0m  0.1122\n",
      "     13      \u001b[36m680.4759\u001b[0m        \u001b[32m7.1782\u001b[0m  0.1145\n",
      "     14      \u001b[36m330.2616\u001b[0m        \u001b[32m6.4817\u001b[0m  0.1094\n",
      "     15      \u001b[36m210.4753\u001b[0m        \u001b[32m5.9228\u001b[0m  0.1114\n",
      "     16       \u001b[36m54.4918\u001b[0m        \u001b[32m5.4351\u001b[0m  0.1102\n",
      "     17       \u001b[36m20.9041\u001b[0m        \u001b[32m5.0614\u001b[0m  0.1111\n",
      "     18       \u001b[36m10.1748\u001b[0m        \u001b[32m4.6762\u001b[0m  0.1248\n",
      "     19        \u001b[36m6.0469\u001b[0m        \u001b[32m4.3243\u001b[0m  0.1182\n",
      "     20        \u001b[36m5.4148\u001b[0m        \u001b[32m4.0416\u001b[0m  0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [02:11<01:59,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m32054.0727\u001b[0m       \u001b[32m17.3888\u001b[0m  0.1648\n",
      "      2     \u001b[36m3298.0456\u001b[0m        \u001b[32m8.1760\u001b[0m  0.2555\n",
      "      3       \u001b[36m80.5898\u001b[0m        \u001b[32m5.3197\u001b[0m  0.1569\n",
      "      4      115.2071        \u001b[32m3.5662\u001b[0m  0.1185\n",
      "      5       \u001b[36m64.9318\u001b[0m        \u001b[32m2.9556\u001b[0m  0.1100\n",
      "      6       \u001b[36m29.7879\u001b[0m        \u001b[32m2.2428\u001b[0m  0.1101\n",
      "      7        \u001b[36m2.4052\u001b[0m        \u001b[32m1.7349\u001b[0m  0.1200\n",
      "      8        2.9431        \u001b[32m1.5316\u001b[0m  0.1124\n",
      "      9        \u001b[36m1.6500\u001b[0m        \u001b[32m1.4499\u001b[0m  0.1132\n",
      "     10        \u001b[36m1.6332\u001b[0m        \u001b[32m1.3703\u001b[0m  0.1142\n",
      "     11        \u001b[36m1.4547\u001b[0m        \u001b[32m1.2987\u001b[0m  0.1161\n",
      "     12        1.4667        \u001b[32m1.2767\u001b[0m  0.1330\n",
      "     13        \u001b[36m1.4043\u001b[0m        \u001b[32m1.2698\u001b[0m  0.1111\n",
      "     14        \u001b[36m1.3424\u001b[0m        \u001b[32m1.2061\u001b[0m  0.1101\n",
      "     15        \u001b[36m1.2940\u001b[0m        \u001b[32m1.1795\u001b[0m  0.1188\n",
      "     16        1.2944        \u001b[32m1.1504\u001b[0m  0.1114\n",
      "     17        6.6667        1.1598  0.1200\n",
      "     18       31.4334        1.2121  0.1099\n",
      "     19        4.1152        \u001b[32m1.1010\u001b[0m  0.1107\n",
      "     20       12.9326        \u001b[32m1.1009\u001b[0m  0.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [02:14<01:59,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m180914.4853\u001b[0m       \u001b[32m28.2698\u001b[0m  0.1694\n",
      "      2   \u001b[36m122638.6247\u001b[0m       \u001b[32m22.1714\u001b[0m  0.1279\n",
      "      3    \u001b[36m77348.2184\u001b[0m       \u001b[32m17.9106\u001b[0m  0.1113\n",
      "      4    \u001b[36m39821.6653\u001b[0m       \u001b[32m12.9410\u001b[0m  0.1200\n",
      "      5    \u001b[36m27648.5483\u001b[0m       \u001b[32m10.7021\u001b[0m  0.1104\n",
      "      6    \u001b[36m13033.1934\u001b[0m        \u001b[32m9.3342\u001b[0m  0.1147\n",
      "      7     \u001b[36m4719.9740\u001b[0m        \u001b[32m6.7764\u001b[0m  0.1142\n",
      "      8     \u001b[36m1790.0851\u001b[0m        \u001b[32m4.1384\u001b[0m  0.1156\n",
      "      9      \u001b[36m728.2384\u001b[0m        \u001b[32m3.6794\u001b[0m  0.1200\n",
      "     10      \u001b[36m182.5023\u001b[0m        \u001b[32m2.9329\u001b[0m  0.1099\n",
      "     11       \u001b[36m79.0712\u001b[0m        \u001b[32m2.6105\u001b[0m  0.1130\n",
      "     12       \u001b[36m15.1790\u001b[0m        \u001b[32m2.3348\u001b[0m  0.1173\n",
      "     13        \u001b[36m4.1370\u001b[0m        \u001b[32m2.0791\u001b[0m  0.1139\n",
      "     14        \u001b[36m3.3774\u001b[0m        \u001b[32m1.8804\u001b[0m  0.1119\n",
      "     15        \u001b[36m3.0539\u001b[0m        \u001b[32m1.7424\u001b[0m  0.1099\n",
      "     16        \u001b[36m2.8419\u001b[0m        \u001b[32m1.6440\u001b[0m  0.1104\n",
      "     17        \u001b[36m2.6347\u001b[0m        \u001b[32m1.5519\u001b[0m  0.1232\n",
      "     18        \u001b[36m2.4591\u001b[0m        \u001b[32m1.4365\u001b[0m  0.1143\n",
      "     19        \u001b[36m2.3146\u001b[0m        \u001b[32m1.3488\u001b[0m  0.2012\n",
      "     20        \u001b[36m2.2027\u001b[0m        \u001b[32m1.2835\u001b[0m  0.1253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [02:16<01:56,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m118.6081\u001b[0m       \u001b[32m35.4102\u001b[0m  0.1284\n",
      "      2       \u001b[36m18.5044\u001b[0m        \u001b[32m5.2115\u001b[0m  0.1202\n",
      "      3        \u001b[36m3.8903\u001b[0m        \u001b[32m2.1250\u001b[0m  0.1327\n",
      "      4        \u001b[36m2.5154\u001b[0m        \u001b[32m1.6718\u001b[0m  0.1380\n",
      "      5        \u001b[36m1.8991\u001b[0m        \u001b[32m1.1869\u001b[0m  0.1119\n",
      "      6        \u001b[36m1.5630\u001b[0m        \u001b[32m1.0087\u001b[0m  0.1129\n",
      "      7        \u001b[36m1.4290\u001b[0m        \u001b[32m0.9740\u001b[0m  0.1101\n",
      "      8        \u001b[36m1.3755\u001b[0m        \u001b[32m0.9583\u001b[0m  0.1156\n",
      "      9        \u001b[36m1.3079\u001b[0m        \u001b[32m0.9481\u001b[0m  0.1096\n",
      "     10        \u001b[36m1.2615\u001b[0m        \u001b[32m0.9280\u001b[0m  0.1092\n",
      "     11        \u001b[36m1.2248\u001b[0m        \u001b[32m0.9075\u001b[0m  0.1149\n",
      "     12        \u001b[36m1.1753\u001b[0m        \u001b[32m0.9045\u001b[0m  0.1189\n",
      "     13        \u001b[36m1.1410\u001b[0m        \u001b[32m0.8900\u001b[0m  0.1198\n",
      "     14        \u001b[36m1.1233\u001b[0m        \u001b[32m0.8633\u001b[0m  0.1192\n",
      "     15        \u001b[36m1.0768\u001b[0m        \u001b[32m0.8535\u001b[0m  0.1102\n",
      "     16        \u001b[36m1.0602\u001b[0m        0.8582  0.1108\n",
      "     17        \u001b[36m1.0455\u001b[0m        \u001b[32m0.8409\u001b[0m  0.1989\n",
      "     18        \u001b[36m1.0155\u001b[0m        \u001b[32m0.8375\u001b[0m  0.1291\n",
      "     19        \u001b[36m1.0073\u001b[0m        \u001b[32m0.8253\u001b[0m  0.1115\n",
      "     20        \u001b[36m0.9913\u001b[0m        \u001b[32m0.8206\u001b[0m  0.1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [02:19<01:53,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0203\u001b[0m        \u001b[32m2.0696\u001b[0m  0.1207\n",
      "      2        \u001b[36m2.0803\u001b[0m        \u001b[32m1.1393\u001b[0m  0.1188\n",
      "      3        \u001b[36m1.5146\u001b[0m        \u001b[32m0.9524\u001b[0m  0.1100\n",
      "      4        \u001b[36m1.3801\u001b[0m        \u001b[32m0.9357\u001b[0m  0.1160\n",
      "      5        \u001b[36m1.3182\u001b[0m        \u001b[32m0.9066\u001b[0m  0.1087\n",
      "      6        \u001b[36m1.2720\u001b[0m        \u001b[32m0.8769\u001b[0m  0.1131\n",
      "      7        \u001b[36m1.2237\u001b[0m        \u001b[32m0.8626\u001b[0m  0.1128\n",
      "      8        \u001b[36m1.1893\u001b[0m        \u001b[32m0.8508\u001b[0m  0.1056\n",
      "      9        \u001b[36m1.1391\u001b[0m        \u001b[32m0.8442\u001b[0m  0.1505\n",
      "     10        \u001b[36m1.1017\u001b[0m        0.8496  0.1099\n",
      "     11        \u001b[36m1.0682\u001b[0m        \u001b[32m0.8368\u001b[0m  0.1073\n",
      "     12        \u001b[36m1.0528\u001b[0m        0.8446  0.1189\n",
      "     13        \u001b[36m1.0275\u001b[0m        0.8372  0.1158\n",
      "     14        \u001b[36m1.0047\u001b[0m        0.8503  0.1136\n",
      "     15        \u001b[36m0.9928\u001b[0m        0.8789  0.1720\n",
      "     16        \u001b[36m0.9889\u001b[0m        0.8757  0.1614\n",
      "     17        \u001b[36m0.9673\u001b[0m        0.9281  0.1242\n",
      "     18        \u001b[36m0.9613\u001b[0m        0.8917  0.1160\n",
      "     19        \u001b[36m0.9566\u001b[0m        0.9083  0.1354\n",
      "     20        \u001b[36m0.9519\u001b[0m        0.9076  0.1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [02:21<01:50,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m2815.1046\u001b[0m        \u001b[32m4.5216\u001b[0m  0.1319\n",
      "      2        \u001b[36m4.7253\u001b[0m        \u001b[32m2.2376\u001b[0m  0.1253\n",
      "      3       85.8286        \u001b[32m1.7441\u001b[0m  0.1070\n",
      "      4        5.3209        \u001b[32m1.5309\u001b[0m  0.1210\n",
      "      5       16.6272        \u001b[32m1.3983\u001b[0m  0.1100\n",
      "      6      137.1342        \u001b[32m1.3906\u001b[0m  0.1056\n",
      "      7      143.8905        \u001b[32m1.3163\u001b[0m  0.0990\n",
      "      8      687.7694        1.4302  0.1158\n",
      "      9      670.6852        \u001b[32m1.2836\u001b[0m  0.1055\n",
      "     10      265.5122        \u001b[32m1.2721\u001b[0m  0.1103\n",
      "     11        8.7169        1.3832  0.1099\n",
      "     12      524.2257        \u001b[32m1.2598\u001b[0m  0.1073\n",
      "     13      362.3825        1.3244  0.1090\n",
      "     14      190.9054        \u001b[32m1.2317\u001b[0m  0.1627\n",
      "     15       69.0290        1.2544  0.1207\n",
      "     16       17.0281        \u001b[32m1.2299\u001b[0m  0.1108\n",
      "     17        \u001b[36m2.3849\u001b[0m        1.2367  0.1073\n",
      "     18        \u001b[36m1.4005\u001b[0m        \u001b[32m1.2256\u001b[0m  0.1094\n",
      "     19        1.4608        \u001b[32m1.2230\u001b[0m  0.1189\n",
      "     20        \u001b[36m1.2270\u001b[0m        \u001b[32m1.2167\u001b[0m  0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [02:23<01:45,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m229317.3166\u001b[0m        \u001b[32m3.3138\u001b[0m  0.1208\n",
      "      2   \u001b[36m131457.0193\u001b[0m        \u001b[32m3.0468\u001b[0m  0.1300\n",
      "      3    \u001b[36m96232.7915\u001b[0m        \u001b[32m2.7916\u001b[0m  0.1083\n",
      "      4    \u001b[36m58520.6074\u001b[0m        \u001b[32m2.5858\u001b[0m  0.1063\n",
      "      5    \u001b[36m36895.2201\u001b[0m        \u001b[32m2.3467\u001b[0m  0.1035\n",
      "      6    \u001b[36m19813.9490\u001b[0m        \u001b[32m1.8612\u001b[0m  0.1099\n",
      "      7     \u001b[36m7977.5283\u001b[0m        \u001b[32m1.6915\u001b[0m  0.1081\n",
      "      8     \u001b[36m2594.8508\u001b[0m        1.7006  0.1112\n",
      "      9     \u001b[36m1356.0193\u001b[0m        \u001b[32m1.6830\u001b[0m  0.1022\n",
      "     10      \u001b[36m247.8560\u001b[0m        \u001b[32m1.5728\u001b[0m  0.1103\n",
      "     11       \u001b[36m88.7988\u001b[0m        \u001b[32m1.4972\u001b[0m  0.1097\n",
      "     12        \u001b[36m1.8967\u001b[0m        \u001b[32m1.4422\u001b[0m  0.1079\n",
      "     13        \u001b[36m1.5795\u001b[0m        \u001b[32m1.4281\u001b[0m  0.1315\n",
      "     14        \u001b[36m1.5504\u001b[0m        \u001b[32m1.3656\u001b[0m  0.1430\n",
      "     15        \u001b[36m1.4060\u001b[0m        \u001b[32m1.3510\u001b[0m  0.1241\n",
      "     16        \u001b[36m1.3505\u001b[0m        \u001b[32m1.3355\u001b[0m  0.1071\n",
      "     17        \u001b[36m1.3177\u001b[0m        \u001b[32m1.2893\u001b[0m  0.1105\n",
      "     18        \u001b[36m1.2872\u001b[0m        \u001b[32m1.2726\u001b[0m  0.1198\n",
      "     19        \u001b[36m1.2687\u001b[0m        \u001b[32m1.2579\u001b[0m  0.1301\n",
      "     20        \u001b[36m1.2426\u001b[0m        \u001b[32m1.2217\u001b[0m  0.1754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [02:26<01:42,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m16.1935\u001b[0m        \u001b[32m8.2247\u001b[0m  0.1378\n",
      "      2        \u001b[36m4.6940\u001b[0m        \u001b[32m3.4655\u001b[0m  0.1217\n",
      "      3        \u001b[36m2.3645\u001b[0m        \u001b[32m2.5592\u001b[0m  0.1174\n",
      "      4        \u001b[36m1.8476\u001b[0m        \u001b[32m2.1381\u001b[0m  0.1140\n",
      "      5        \u001b[36m1.6043\u001b[0m        \u001b[32m1.7332\u001b[0m  0.1109\n",
      "      6        \u001b[36m1.4884\u001b[0m        \u001b[32m1.5563\u001b[0m  0.1163\n",
      "      7        \u001b[36m1.3708\u001b[0m        \u001b[32m1.3876\u001b[0m  0.1211\n",
      "      8        \u001b[36m1.2838\u001b[0m        \u001b[32m1.2938\u001b[0m  0.1145\n",
      "      9        \u001b[36m1.2357\u001b[0m        \u001b[32m1.2278\u001b[0m  0.1155\n",
      "     10        \u001b[36m1.1919\u001b[0m        \u001b[32m1.1769\u001b[0m  0.1147\n",
      "     11        \u001b[36m1.1589\u001b[0m        \u001b[32m1.1400\u001b[0m  0.1969\n",
      "     12        \u001b[36m1.1300\u001b[0m        \u001b[32m1.1018\u001b[0m  0.1360\n",
      "     13        \u001b[36m1.1186\u001b[0m        \u001b[32m1.0611\u001b[0m  0.1100\n",
      "     14        \u001b[36m1.1153\u001b[0m        1.0736  0.1306\n",
      "     15        \u001b[36m1.0715\u001b[0m        \u001b[32m1.0351\u001b[0m  0.1207\n",
      "     16        \u001b[36m1.0547\u001b[0m        \u001b[32m1.0259\u001b[0m  0.1150\n",
      "     17        \u001b[36m1.0515\u001b[0m        \u001b[32m1.0051\u001b[0m  0.1199\n",
      "     18        \u001b[36m1.0357\u001b[0m        1.0159  0.1143\n",
      "     19        \u001b[36m1.0262\u001b[0m        \u001b[32m0.9987\u001b[0m  0.1157\n",
      "     20        1.0309        \u001b[32m0.9934\u001b[0m  0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [02:28<01:40,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m16447.9916\u001b[0m       \u001b[32m13.3437\u001b[0m  0.1872\n",
      "      2     \u001b[36m4881.7183\u001b[0m       \u001b[32m11.3525\u001b[0m  0.1302\n",
      "      3     \u001b[36m3147.7282\u001b[0m        \u001b[32m8.7033\u001b[0m  0.1110\n",
      "      4      \u001b[36m436.9249\u001b[0m        \u001b[32m6.1957\u001b[0m  0.1085\n",
      "      5      \u001b[36m100.6121\u001b[0m        \u001b[32m4.2561\u001b[0m  0.1185\n",
      "      6       \u001b[36m60.2484\u001b[0m        \u001b[32m2.6636\u001b[0m  0.1103\n",
      "      7        \u001b[36m2.2747\u001b[0m        \u001b[32m1.8423\u001b[0m  0.1129\n",
      "      8        7.0045        \u001b[32m1.6100\u001b[0m  0.1084\n",
      "      9     1523.9977        1.6643  0.2038\n",
      "     10      593.8541        \u001b[32m1.5826\u001b[0m  0.1502\n",
      "     11       45.6665        \u001b[32m1.4113\u001b[0m  0.1070\n",
      "     12      109.1532        \u001b[32m1.3502\u001b[0m  0.1192\n",
      "     13      169.9455        \u001b[32m1.3273\u001b[0m  0.1198\n",
      "     14      114.2615        \u001b[32m1.2816\u001b[0m  0.1130\n",
      "     15       18.5249        \u001b[32m1.2582\u001b[0m  0.1149\n",
      "     16        4.2994        \u001b[32m1.2304\u001b[0m  0.1109\n",
      "     17        5.2202        \u001b[32m1.2109\u001b[0m  0.1187\n",
      "     18        2.2845        \u001b[32m1.1981\u001b[0m  0.1199\n",
      "     19        \u001b[36m2.0807\u001b[0m        \u001b[32m1.1864\u001b[0m  0.1196\n",
      "     20        2.6127        \u001b[32m1.1717\u001b[0m  0.1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [02:31<01:39,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m182.6740\u001b[0m     \u001b[32m5070.6043\u001b[0m  0.1418\n",
      "      2       \u001b[36m49.3446\u001b[0m     7119.7791  0.1259\n",
      "      3        \u001b[36m6.7520\u001b[0m      \u001b[32m995.2454\u001b[0m  0.1320\n",
      "      4        \u001b[36m1.6591\u001b[0m    42084.7015  0.1328\n",
      "      5        \u001b[36m1.6041\u001b[0m    37966.0251  0.1202\n",
      "      6        \u001b[36m1.3721\u001b[0m    14021.7802  0.1759\n",
      "      7        \u001b[36m1.2572\u001b[0m     7201.9718  0.1399\n",
      "      8        \u001b[36m1.2148\u001b[0m     3649.1571  0.1056\n",
      "      9        \u001b[36m1.1867\u001b[0m     1232.8068  0.1092\n",
      "     10        \u001b[36m1.1549\u001b[0m     8943.1618  0.1089\n",
      "     11        \u001b[36m1.1311\u001b[0m    17908.9323  0.1109\n",
      "     12        \u001b[36m1.1122\u001b[0m    10478.5511  0.1072\n",
      "     13        \u001b[36m1.0970\u001b[0m    24144.7398  0.1120\n",
      "     14        \u001b[36m1.0875\u001b[0m    26872.1268  0.1091\n",
      "     15        \u001b[36m1.0763\u001b[0m    22745.5045  0.1070\n",
      "     16        \u001b[36m1.0680\u001b[0m    31302.3985  0.1104\n",
      "     17        \u001b[36m1.0604\u001b[0m    18534.0619  0.1080\n",
      "     18        \u001b[36m1.0575\u001b[0m    27912.8010  0.1081\n",
      "     19        \u001b[36m1.0484\u001b[0m    18744.2342  0.1078\n",
      "     20        \u001b[36m1.0477\u001b[0m    18982.0176  0.1083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [02:33<01:36,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m7.2102\u001b[0m  \u001b[32m1977870.4430\u001b[0m  0.1075\n",
      "      2        \u001b[36m3.4036\u001b[0m  \u001b[32m1668952.9547\u001b[0m  0.1194\n",
      "      3        \u001b[36m2.1556\u001b[0m  1834520.5080  0.1225\n",
      "      4        \u001b[36m1.6261\u001b[0m  \u001b[32m1559130.2476\u001b[0m  0.1049\n",
      "      5        \u001b[36m1.3939\u001b[0m  \u001b[32m1546432.7563\u001b[0m  0.1300\n",
      "      6        \u001b[36m1.1967\u001b[0m  \u001b[32m1375459.7303\u001b[0m  0.1498\n",
      "      7        \u001b[36m1.1409\u001b[0m  \u001b[32m1122624.3953\u001b[0m  0.1124\n",
      "      8        \u001b[36m1.0239\u001b[0m   \u001b[32m818583.6045\u001b[0m  0.1072\n",
      "      9        \u001b[36m0.9882\u001b[0m   \u001b[32m679308.9165\u001b[0m  0.1103\n",
      "     10        \u001b[36m0.9446\u001b[0m   \u001b[32m524308.6728\u001b[0m  0.1096\n",
      "     11        \u001b[36m0.9308\u001b[0m   \u001b[32m402799.3604\u001b[0m  0.1086\n",
      "     12        \u001b[36m0.9182\u001b[0m   \u001b[32m311069.1024\u001b[0m  0.1072\n",
      "     13        0.9642   \u001b[32m240442.4231\u001b[0m  0.1098\n",
      "     14        \u001b[36m0.9086\u001b[0m   \u001b[32m214172.5729\u001b[0m  0.1075\n",
      "     15        \u001b[36m0.8824\u001b[0m   \u001b[32m134000.7452\u001b[0m  0.1023\n",
      "     16        0.8983   \u001b[32m111995.5256\u001b[0m  0.1067\n",
      "     17        \u001b[36m0.8670\u001b[0m   \u001b[32m111424.0883\u001b[0m  0.1096\n",
      "     18        0.8857    \u001b[32m96252.3656\u001b[0m  0.1102\n",
      "     19        \u001b[36m0.8514\u001b[0m    99086.0992  0.1055\n",
      "     20        0.8643    \u001b[32m78978.0161\u001b[0m  0.1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [02:36<01:32,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.5449\u001b[0m        \u001b[32m1.8097\u001b[0m  0.1178\n",
      "      2        \u001b[36m1.7202\u001b[0m        \u001b[32m1.1529\u001b[0m  0.1121\n",
      "      3        \u001b[36m1.2741\u001b[0m        \u001b[32m1.0384\u001b[0m  0.1181\n",
      "      4        \u001b[36m1.1192\u001b[0m        \u001b[32m0.9774\u001b[0m  0.1301\n",
      "      5        \u001b[36m1.0667\u001b[0m        \u001b[32m0.9349\u001b[0m  0.1715\n",
      "      6        \u001b[36m1.0045\u001b[0m        \u001b[32m0.8866\u001b[0m  0.1220\n",
      "      7        \u001b[36m0.9817\u001b[0m        \u001b[32m0.8803\u001b[0m  0.1061\n",
      "      8        \u001b[36m0.9686\u001b[0m        \u001b[32m0.8688\u001b[0m  0.1178\n",
      "      9        0.9699        \u001b[32m0.8685\u001b[0m  0.1097\n",
      "     10        \u001b[36m0.9652\u001b[0m        \u001b[32m0.8552\u001b[0m  0.1163\n",
      "     11        \u001b[36m0.9465\u001b[0m        \u001b[32m0.8492\u001b[0m  0.1082\n",
      "     12        0.9525        \u001b[32m0.8416\u001b[0m  0.1069\n",
      "     13        0.9510        0.8431  0.1104\n",
      "     14        \u001b[36m0.9323\u001b[0m        0.8554  0.1084\n",
      "     15        \u001b[36m0.9313\u001b[0m        \u001b[32m0.8395\u001b[0m  0.1011\n",
      "     16        0.9407        0.8452  0.1094\n",
      "     17        \u001b[36m0.9275\u001b[0m        0.8412  0.1196\n",
      "     18        0.9326        \u001b[32m0.8247\u001b[0m  0.1142\n",
      "     19        \u001b[36m0.9208\u001b[0m        0.8615  0.1105\n",
      "     20        0.9343        0.8771  0.1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [02:38<01:28,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m1966.8316\u001b[0m        \u001b[32m1.9793\u001b[0m  0.1123\n",
      "      2      \u001b[36m526.4039\u001b[0m        \u001b[32m1.5083\u001b[0m  0.1111\n",
      "      3       \u001b[36m61.4398\u001b[0m        \u001b[32m1.3580\u001b[0m  0.1164\n",
      "      4        \u001b[36m1.4261\u001b[0m        \u001b[32m1.2011\u001b[0m  0.1703\n",
      "      5        6.3394        \u001b[32m1.1090\u001b[0m  0.1312\n",
      "      6       37.2209        \u001b[32m1.0323\u001b[0m  0.1186\n",
      "      7        4.5602        \u001b[32m0.9389\u001b[0m  0.1113\n",
      "      8        2.4284        \u001b[32m0.9239\u001b[0m  0.1130\n",
      "      9        2.9861        \u001b[32m0.9100\u001b[0m  0.1157\n",
      "     10        1.7143        \u001b[32m0.8773\u001b[0m  0.1129\n",
      "     11        \u001b[36m1.1081\u001b[0m        \u001b[32m0.8658\u001b[0m  0.1186\n",
      "     12        1.1179        \u001b[32m0.8596\u001b[0m  0.1102\n",
      "     13        1.1138        \u001b[32m0.8550\u001b[0m  0.1110\n",
      "     14        1.1406        \u001b[32m0.8535\u001b[0m  0.1226\n",
      "     15        1.1147        \u001b[32m0.8417\u001b[0m  0.1118\n",
      "     16        \u001b[36m1.0708\u001b[0m        \u001b[32m0.8398\u001b[0m  0.1111\n",
      "     17        1.0820        \u001b[32m0.8199\u001b[0m  0.1075\n",
      "     18        1.1231        0.8888  0.1106\n",
      "     19        1.3153        0.8215  0.1087\n",
      "     20        1.6010        0.8293  0.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [02:40<01:26,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m6674.9997\u001b[0m       \u001b[32m45.0355\u001b[0m  0.1212\n",
      "      2      \u001b[36m162.5371\u001b[0m       \u001b[32m24.0916\u001b[0m  0.1898\n",
      "      3       \u001b[36m20.5091\u001b[0m       \u001b[32m11.8088\u001b[0m  0.1358\n",
      "      4      165.9207        \u001b[32m6.3994\u001b[0m  0.1142\n",
      "      5       \u001b[36m14.3456\u001b[0m        \u001b[32m4.2114\u001b[0m  0.1113\n",
      "      6      188.2099        \u001b[32m2.9842\u001b[0m  0.1185\n",
      "      7      110.9947        \u001b[32m2.2482\u001b[0m  0.1398\n",
      "      8       24.6272        \u001b[32m1.7924\u001b[0m  0.1146\n",
      "      9        \u001b[36m3.8780\u001b[0m        \u001b[32m1.5058\u001b[0m  0.1145\n",
      "     10       12.0239        \u001b[32m1.3298\u001b[0m  0.1292\n",
      "     11        5.0256        \u001b[32m1.1559\u001b[0m  0.1098\n",
      "     12        \u001b[36m2.7513\u001b[0m        \u001b[32m1.0857\u001b[0m  0.1122\n",
      "     13        \u001b[36m2.7142\u001b[0m        \u001b[32m1.0229\u001b[0m  0.1120\n",
      "     14        \u001b[36m2.6653\u001b[0m        \u001b[32m0.9519\u001b[0m  0.1110\n",
      "     15        2.9875        \u001b[32m0.9054\u001b[0m  0.1147\n",
      "     16        \u001b[36m2.5766\u001b[0m        0.9252  0.1414\n",
      "     17        \u001b[36m2.3792\u001b[0m        0.9197  0.1570\n",
      "     18        2.9567        \u001b[32m0.8914\u001b[0m  0.1456\n",
      "     19        4.0679        0.9045  0.1188\n",
      "     20       10.1613        0.9019  0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [02:43<01:26,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m265.1525\u001b[0m   \u001b[32m649837.3857\u001b[0m  0.1341\n",
      "      2       \u001b[36m94.8719\u001b[0m   864123.0787  0.1410\n",
      "      3       \u001b[36m29.3205\u001b[0m   859564.1777  0.1728\n",
      "      4        \u001b[36m8.3872\u001b[0m   867110.8068  0.1668\n",
      "      5        \u001b[36m3.2522\u001b[0m   850558.0620  0.1124\n",
      "      6        \u001b[36m2.1596\u001b[0m   823162.9744  0.1227\n",
      "      7        \u001b[36m1.9343\u001b[0m   796987.9813  0.1158\n",
      "      8        \u001b[36m1.7797\u001b[0m   792944.6753  0.1113\n",
      "      9        \u001b[36m1.6431\u001b[0m   763736.1480  0.1201\n",
      "     10        \u001b[36m1.5625\u001b[0m   742579.4002  0.1335\n",
      "     11        \u001b[36m1.4958\u001b[0m   710873.1814  0.1661\n",
      "     12        \u001b[36m1.4627\u001b[0m   694005.1833  0.1601\n",
      "     13        \u001b[36m1.4197\u001b[0m   667538.5640  0.1633\n",
      "     14        \u001b[36m1.3777\u001b[0m   658681.2061  0.1649\n",
      "     15        \u001b[36m1.3627\u001b[0m   \u001b[32m634524.6852\u001b[0m  0.2175\n",
      "     16        \u001b[36m1.3217\u001b[0m   \u001b[32m615487.8482\u001b[0m  0.2101\n",
      "     17        \u001b[36m1.3004\u001b[0m   \u001b[32m595228.0430\u001b[0m  0.1481\n",
      "     18        \u001b[36m1.2727\u001b[0m   \u001b[32m580023.7465\u001b[0m  0.1302\n",
      "     19        \u001b[36m1.2596\u001b[0m   \u001b[32m566498.7265\u001b[0m  0.1272\n",
      "     20        \u001b[36m1.2332\u001b[0m   \u001b[32m558018.3709\u001b[0m  0.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [02:46<01:29,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m3226.4152\u001b[0m        \u001b[32m2.7901\u001b[0m  0.1754\n",
      "      2      \u001b[36m641.5009\u001b[0m        \u001b[32m2.2086\u001b[0m  0.1807\n",
      "      3       \u001b[36m20.4228\u001b[0m        \u001b[32m1.4416\u001b[0m  0.1186\n",
      "      4       73.2880        \u001b[32m1.1922\u001b[0m  0.1263\n",
      "      5        \u001b[36m1.3097\u001b[0m        \u001b[32m1.1000\u001b[0m  0.1346\n",
      "      6        \u001b[36m1.1393\u001b[0m        \u001b[32m1.0554\u001b[0m  0.1199\n",
      "      7        1.6286        \u001b[32m1.0233\u001b[0m  0.1244\n",
      "      8        \u001b[36m1.0556\u001b[0m        \u001b[32m1.0130\u001b[0m  0.1247\n",
      "      9        1.1208        \u001b[32m0.9917\u001b[0m  0.1298\n",
      "     10        \u001b[36m1.0336\u001b[0m        \u001b[32m0.9729\u001b[0m  0.1220\n",
      "     11        \u001b[36m1.0247\u001b[0m        \u001b[32m0.9655\u001b[0m  0.2033\n",
      "     12        \u001b[36m1.0071\u001b[0m        \u001b[32m0.9477\u001b[0m  0.1683\n",
      "     13        \u001b[36m1.0062\u001b[0m        0.9527  0.1306\n",
      "     14        \u001b[36m0.9971\u001b[0m        \u001b[32m0.9428\u001b[0m  0.1223\n",
      "     15        \u001b[36m0.9896\u001b[0m        \u001b[32m0.9328\u001b[0m  0.1159\n",
      "     16        \u001b[36m0.9867\u001b[0m        \u001b[32m0.9321\u001b[0m  0.1174\n",
      "     17        \u001b[36m0.9848\u001b[0m        0.9479  0.1101\n",
      "     18        \u001b[36m0.9781\u001b[0m        \u001b[32m0.9288\u001b[0m  0.1128\n",
      "     19        \u001b[36m0.9744\u001b[0m        0.9495  0.1121\n",
      "     20        0.9792        0.9374  0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [02:49<01:28,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m13252.8550\u001b[0m        \u001b[32m1.1481\u001b[0m  0.1308\n",
      "      2    \u001b[36m10263.0825\u001b[0m        1.1933  0.1213\n",
      "      3     \u001b[36m6788.2090\u001b[0m        \u001b[32m1.0958\u001b[0m  0.1089\n",
      "      4     \u001b[36m4769.8287\u001b[0m        \u001b[32m1.0784\u001b[0m  0.1329\n",
      "      5     \u001b[36m3615.6357\u001b[0m        1.1211  0.1542\n",
      "      6     \u001b[36m2723.7124\u001b[0m        \u001b[32m1.0739\u001b[0m  0.1285\n",
      "      7     \u001b[36m2128.1220\u001b[0m        1.0828  0.1587\n",
      "      8     \u001b[36m1743.5939\u001b[0m        1.0765  0.2316\n",
      "      9     \u001b[36m1283.1678\u001b[0m        \u001b[32m1.0659\u001b[0m  0.1998\n",
      "     10     \u001b[36m1003.7174\u001b[0m        1.0942  0.1282\n",
      "     11      \u001b[36m863.5020\u001b[0m        \u001b[32m1.0639\u001b[0m  0.1310\n",
      "     12      \u001b[36m668.4444\u001b[0m        1.0671  0.1184\n",
      "     13      \u001b[36m554.6128\u001b[0m        \u001b[32m1.0588\u001b[0m  0.1204\n",
      "     14      \u001b[36m540.3736\u001b[0m        1.0825  0.1106\n",
      "     15      \u001b[36m370.0522\u001b[0m        \u001b[32m1.0554\u001b[0m  0.1192\n",
      "     16      \u001b[36m305.7727\u001b[0m        \u001b[32m1.0497\u001b[0m  0.1114\n",
      "     17      \u001b[36m245.4876\u001b[0m        1.0590  0.1086\n",
      "     18      \u001b[36m201.2513\u001b[0m        1.0583  0.0997\n",
      "     19      \u001b[36m182.5540\u001b[0m        1.0528  0.1019\n",
      "     20      \u001b[36m147.4202\u001b[0m        1.0565  0.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [02:51<01:25,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m22.4058\u001b[0m        \u001b[32m4.3606\u001b[0m  0.1253\n",
      "      2     1695.0891        \u001b[32m1.4732\u001b[0m  0.1498\n",
      "      3        \u001b[36m2.8451\u001b[0m        \u001b[32m1.2496\u001b[0m  0.1413\n",
      "      4      113.5772        \u001b[32m1.2366\u001b[0m  0.1655\n",
      "      5       42.9979        \u001b[32m1.1977\u001b[0m  0.2345\n",
      "      6        \u001b[36m1.4441\u001b[0m        1.2102  0.1783\n",
      "      7        \u001b[36m1.3973\u001b[0m        1.2098  0.1645\n",
      "      8        1.5660        1.2153  0.1310\n",
      "      9        1.8192        1.2030  0.1244\n",
      "     10        2.2654        \u001b[32m1.1910\u001b[0m  0.1160\n",
      "     11        2.9784        1.1913  0.1242\n",
      "     12        \u001b[36m1.0727\u001b[0m        \u001b[32m1.1729\u001b[0m  0.1224\n",
      "     13       14.0019        \u001b[32m1.1706\u001b[0m  0.1163\n",
      "     14       54.5041        1.1834  0.1738\n",
      "     15        1.8451        \u001b[32m1.1502\u001b[0m  0.2107\n",
      "     16      250.4568        1.3615  0.1492\n",
      "     17      603.0796        1.1524  0.1623\n",
      "     18      916.2915        1.3218  0.1502\n",
      "     19      790.9725        1.1922  0.1204\n",
      "     20      157.9888        1.1574  0.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [02:55<01:26,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.3676\u001b[0m        \u001b[32m1.5261\u001b[0m  0.1630\n",
      "      2        \u001b[36m1.9396\u001b[0m        \u001b[32m1.3733\u001b[0m  0.1325\n",
      "      3        \u001b[36m1.7267\u001b[0m        \u001b[32m1.2842\u001b[0m  0.1391\n",
      "      4        \u001b[36m1.5601\u001b[0m        \u001b[32m1.2412\u001b[0m  0.1370\n",
      "      5        \u001b[36m1.4340\u001b[0m        \u001b[32m1.2027\u001b[0m  0.1252\n",
      "      6        \u001b[36m1.3272\u001b[0m        \u001b[32m1.1213\u001b[0m  0.1124\n",
      "      7        \u001b[36m1.2560\u001b[0m        \u001b[32m1.0842\u001b[0m  0.1586\n",
      "      8        \u001b[36m1.1901\u001b[0m        \u001b[32m1.0586\u001b[0m  0.1739\n",
      "      9        \u001b[36m1.1515\u001b[0m        \u001b[32m1.0387\u001b[0m  0.1341\n",
      "     10        \u001b[36m1.1087\u001b[0m        \u001b[32m0.9981\u001b[0m  0.1377\n",
      "     11        \u001b[36m1.0823\u001b[0m        \u001b[32m0.9853\u001b[0m  0.1491\n",
      "     12        \u001b[36m1.0644\u001b[0m        \u001b[32m0.9647\u001b[0m  0.1104\n",
      "     13        \u001b[36m1.0441\u001b[0m        \u001b[32m0.9617\u001b[0m  0.1187\n",
      "     14        \u001b[36m1.0418\u001b[0m        \u001b[32m0.9497\u001b[0m  0.1116\n",
      "     15        \u001b[36m1.0233\u001b[0m        \u001b[32m0.9389\u001b[0m  0.1184\n",
      "     16        \u001b[36m1.0096\u001b[0m        0.9430  0.1496\n",
      "     17        1.0116        \u001b[32m0.9209\u001b[0m  0.1702\n",
      "     18        \u001b[36m0.9910\u001b[0m        0.9411  0.1222\n",
      "     19        \u001b[36m0.9899\u001b[0m        0.9258  0.1227\n",
      "     20        \u001b[36m0.9809\u001b[0m        \u001b[32m0.9095\u001b[0m  0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [02:57<01:23,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m246.2570\u001b[0m      \u001b[32m107.4308\u001b[0m  0.1201\n",
      "      2       \u001b[36m53.9080\u001b[0m       \u001b[32m20.9045\u001b[0m  0.1298\n",
      "      3        \u001b[36m9.9270\u001b[0m        \u001b[32m5.5755\u001b[0m  0.1259\n",
      "      4        \u001b[36m3.3504\u001b[0m        \u001b[32m3.6174\u001b[0m  0.1058\n",
      "      5        \u001b[36m2.7452\u001b[0m        \u001b[32m3.1491\u001b[0m  0.1192\n",
      "      6        \u001b[36m2.4234\u001b[0m        \u001b[32m2.7525\u001b[0m  0.1102\n",
      "      7        \u001b[36m2.2210\u001b[0m        \u001b[32m2.5248\u001b[0m  0.1110\n",
      "      8        \u001b[36m2.0823\u001b[0m        \u001b[32m2.3391\u001b[0m  0.1189\n",
      "      9        \u001b[36m1.9303\u001b[0m        \u001b[32m2.2088\u001b[0m  0.1142\n",
      "     10        \u001b[36m1.8177\u001b[0m        \u001b[32m2.0665\u001b[0m  0.1149\n",
      "     11        \u001b[36m1.7003\u001b[0m        \u001b[32m1.9298\u001b[0m  0.1713\n",
      "     12        \u001b[36m1.6041\u001b[0m        \u001b[32m1.8464\u001b[0m  0.1187\n",
      "     13        \u001b[36m1.5175\u001b[0m        \u001b[32m1.7428\u001b[0m  0.1109\n",
      "     14        \u001b[36m1.4456\u001b[0m        \u001b[32m1.6312\u001b[0m  0.1715\n",
      "     15        \u001b[36m1.3774\u001b[0m        \u001b[32m1.5526\u001b[0m  0.1485\n",
      "     16        \u001b[36m1.3207\u001b[0m        \u001b[32m1.4851\u001b[0m  0.1099\n",
      "     17        \u001b[36m1.2737\u001b[0m        \u001b[32m1.4315\u001b[0m  0.1063\n",
      "     18        \u001b[36m1.2338\u001b[0m        \u001b[32m1.3764\u001b[0m  0.1217\n",
      "     19        \u001b[36m1.1988\u001b[0m        \u001b[32m1.3452\u001b[0m  0.1287\n",
      "     20        \u001b[36m1.1741\u001b[0m        \u001b[32m1.2687\u001b[0m  0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [03:00<01:18,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m16535.7194\u001b[0m        \u001b[32m6.9730\u001b[0m  0.1222\n",
      "      2     \u001b[36m3479.2372\u001b[0m        \u001b[32m6.6228\u001b[0m  0.1916\n",
      "      3      \u001b[36m161.8993\u001b[0m        \u001b[32m6.0413\u001b[0m  0.1168\n",
      "      4        \u001b[36m6.1674\u001b[0m        \u001b[32m5.4828\u001b[0m  0.1101\n",
      "      5       22.6388        \u001b[32m5.1689\u001b[0m  0.1093\n",
      "      6       11.0572        \u001b[32m5.0662\u001b[0m  0.1154\n",
      "      7        \u001b[36m4.5534\u001b[0m        \u001b[32m4.9528\u001b[0m  0.1145\n",
      "      8        \u001b[36m4.4766\u001b[0m        \u001b[32m4.8810\u001b[0m  0.1112\n",
      "      9        \u001b[36m3.6145\u001b[0m        \u001b[32m4.8634\u001b[0m  0.1122\n",
      "     10        \u001b[36m3.3365\u001b[0m        \u001b[32m4.8013\u001b[0m  0.1099\n",
      "     11        \u001b[36m3.1714\u001b[0m        \u001b[32m4.6693\u001b[0m  0.1115\n",
      "     12        \u001b[36m3.0280\u001b[0m        4.7844  0.1656\n",
      "     13        \u001b[36m2.9214\u001b[0m        4.7318  0.1600\n",
      "     14        \u001b[36m2.8498\u001b[0m        4.6887  0.1204\n",
      "     15        \u001b[36m2.7420\u001b[0m        4.6725  0.1180\n",
      "     16        \u001b[36m2.6560\u001b[0m        \u001b[32m4.6047\u001b[0m  0.1103\n",
      "     17        \u001b[36m2.5724\u001b[0m        \u001b[32m4.5438\u001b[0m  0.1140\n",
      "     18        \u001b[36m2.4664\u001b[0m        \u001b[32m4.4898\u001b[0m  0.1152\n",
      "     19        \u001b[36m2.3811\u001b[0m        \u001b[32m4.4292\u001b[0m  0.1166\n",
      "     20        \u001b[36m2.2939\u001b[0m        \u001b[32m4.3988\u001b[0m  0.1147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [03:02<01:14,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.4645\u001b[0m        \u001b[32m1.9365\u001b[0m  0.1249\n",
      "      2        \u001b[36m1.7372\u001b[0m        \u001b[32m1.6437\u001b[0m  0.1262\n",
      "      3        \u001b[36m1.4301\u001b[0m        \u001b[32m1.5299\u001b[0m  0.1137\n",
      "      4        \u001b[36m1.3148\u001b[0m        \u001b[32m1.4840\u001b[0m  0.1200\n",
      "      5        \u001b[36m1.2261\u001b[0m        \u001b[32m1.4338\u001b[0m  0.1366\n",
      "      6        \u001b[36m1.1735\u001b[0m        \u001b[32m1.3819\u001b[0m  0.1117\n",
      "      7        \u001b[36m1.1187\u001b[0m        \u001b[32m1.3379\u001b[0m  0.1079\n",
      "      8        \u001b[36m1.0628\u001b[0m        \u001b[32m1.3014\u001b[0m  0.1104\n",
      "      9        \u001b[36m1.0266\u001b[0m        \u001b[32m1.2689\u001b[0m  0.1154\n",
      "     10        \u001b[36m0.9937\u001b[0m        \u001b[32m1.2389\u001b[0m  0.1345\n",
      "     11        \u001b[36m0.9690\u001b[0m        \u001b[32m1.2264\u001b[0m  0.1785\n",
      "     12        \u001b[36m0.9598\u001b[0m        \u001b[32m1.2159\u001b[0m  0.1206\n",
      "     13        \u001b[36m0.9399\u001b[0m        \u001b[32m1.2076\u001b[0m  0.1141\n",
      "     14        0.9490        1.2408  0.1150\n",
      "     15        \u001b[36m0.9352\u001b[0m        \u001b[32m1.2032\u001b[0m  0.1197\n",
      "     16        \u001b[36m0.9200\u001b[0m        \u001b[32m1.1955\u001b[0m  0.1118\n",
      "     17        \u001b[36m0.9136\u001b[0m        \u001b[32m1.1943\u001b[0m  0.1085\n",
      "     18        0.9169        1.2054  0.1099\n",
      "     19        \u001b[36m0.9076\u001b[0m        1.1977  0.1254\n",
      "     20        0.9145        1.2114  0.1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [03:05<01:09,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m607834.2901\u001b[0m       \u001b[32m40.5628\u001b[0m  0.1290\n",
      "      2   \u001b[36m530985.0448\u001b[0m       \u001b[32m31.7684\u001b[0m  0.1297\n",
      "      3   \u001b[36m331190.5902\u001b[0m       \u001b[32m26.1078\u001b[0m  0.1143\n",
      "      4   \u001b[36m227305.2383\u001b[0m       \u001b[32m21.0903\u001b[0m  0.1109\n",
      "      5   \u001b[36m144704.5722\u001b[0m       \u001b[32m16.3799\u001b[0m  0.1113\n",
      "      6    \u001b[36m89426.1357\u001b[0m       \u001b[32m12.6741\u001b[0m  0.1073\n",
      "      7    \u001b[36m50053.0649\u001b[0m        \u001b[32m9.8352\u001b[0m  0.1296\n",
      "      8    \u001b[36m28265.9400\u001b[0m        \u001b[32m8.1644\u001b[0m  0.1190\n",
      "      9    \u001b[36m17449.9042\u001b[0m        \u001b[32m6.5738\u001b[0m  0.1991\n",
      "     10     \u001b[36m5393.4349\u001b[0m        \u001b[32m4.9539\u001b[0m  0.1293\n",
      "     11      \u001b[36m978.8106\u001b[0m        \u001b[32m3.7680\u001b[0m  0.1118\n",
      "     12      \u001b[36m380.9073\u001b[0m        \u001b[32m3.3483\u001b[0m  0.1084\n",
      "     13      \u001b[36m217.0955\u001b[0m        \u001b[32m3.1667\u001b[0m  0.1183\n",
      "     14       \u001b[36m24.5566\u001b[0m        \u001b[32m3.0059\u001b[0m  0.1109\n",
      "     15        \u001b[36m3.1565\u001b[0m        \u001b[32m2.8777\u001b[0m  0.1144\n",
      "     16        3.2122        \u001b[32m2.7973\u001b[0m  0.1091\n",
      "     17        \u001b[36m2.8353\u001b[0m        \u001b[32m2.7220\u001b[0m  0.1145\n",
      "     18        \u001b[36m2.6601\u001b[0m        \u001b[32m2.6568\u001b[0m  0.1137\n",
      "     19        \u001b[36m2.5115\u001b[0m        \u001b[32m2.5891\u001b[0m  0.1062\n",
      "     20        \u001b[36m2.4407\u001b[0m        \u001b[32m2.5312\u001b[0m  0.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [03:07<01:06,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m14793.0702\u001b[0m        \u001b[32m4.0877\u001b[0m  0.1264\n",
      "      2     \u001b[36m9242.1152\u001b[0m        \u001b[32m2.6277\u001b[0m  0.1224\n",
      "      3       \u001b[36m30.2324\u001b[0m        \u001b[32m2.3964\u001b[0m  0.1241\n",
      "      4      907.1162        \u001b[32m2.1366\u001b[0m  0.1188\n",
      "      5      328.1957        \u001b[32m1.9509\u001b[0m  0.1181\n",
      "      6     4449.2664        1.9919  0.1059\n",
      "      7     3958.3516        \u001b[32m1.7047\u001b[0m  0.1228\n",
      "      8     1336.9572        \u001b[32m1.6042\u001b[0m  0.1539\n",
      "      9    19726.6969        1.7562  0.1139\n",
      "     10     3296.6152        \u001b[32m1.3852\u001b[0m  0.1166\n",
      "     11      527.2243        \u001b[32m1.3513\u001b[0m  0.1127\n",
      "     12     1262.8549        \u001b[32m1.2740\u001b[0m  0.1181\n",
      "     13      841.6743        \u001b[32m1.1896\u001b[0m  0.1124\n",
      "     14       69.5113        \u001b[32m1.1641\u001b[0m  0.1100\n",
      "     15     2003.4238        1.1903  0.1088\n",
      "     16     1989.0152        \u001b[32m1.0687\u001b[0m  0.1098\n",
      "     17      661.6490        1.1097  0.1078\n",
      "     18       \u001b[36m15.3024\u001b[0m        \u001b[32m1.0480\u001b[0m  0.1083\n",
      "     19       \u001b[36m11.2650\u001b[0m        1.0536  0.1182\n",
      "     20       21.6501        \u001b[32m1.0243\u001b[0m  0.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [03:10<01:02,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m296515.3335\u001b[0m       \u001b[32m25.7194\u001b[0m  0.1378\n",
      "      2   \u001b[36m218593.7415\u001b[0m        \u001b[32m6.3965\u001b[0m  0.1221\n",
      "      3   \u001b[36m175570.5586\u001b[0m        \u001b[32m2.1535\u001b[0m  0.1085\n",
      "      4   \u001b[36m111683.1859\u001b[0m        2.5027  0.1085\n",
      "      5    \u001b[36m72904.9692\u001b[0m        2.7033  0.1217\n",
      "      6    \u001b[36m58553.3132\u001b[0m        3.9169  0.1590\n",
      "      7    \u001b[36m38396.0482\u001b[0m        4.5953  0.1565\n",
      "      8    \u001b[36m23245.6617\u001b[0m        4.6470  0.1171\n",
      "      9    \u001b[36m17171.4538\u001b[0m        4.8918  0.1295\n",
      "     10     \u001b[36m9057.9483\u001b[0m        4.3590  0.1072\n",
      "     11     \u001b[36m7382.8842\u001b[0m        4.3792  0.1186\n",
      "     12     \u001b[36m3488.8212\u001b[0m        3.9831  0.1071\n",
      "     13     \u001b[36m2083.3346\u001b[0m        3.1896  0.1219\n",
      "     14      \u001b[36m994.7134\u001b[0m        \u001b[32m1.9916\u001b[0m  0.1101\n",
      "     15      \u001b[36m720.3730\u001b[0m        \u001b[32m1.8456\u001b[0m  0.1044\n",
      "     16     2149.4694        \u001b[32m1.7470\u001b[0m  0.1216\n",
      "     17       \u001b[36m22.8676\u001b[0m        \u001b[32m1.7285\u001b[0m  0.1201\n",
      "     18        \u001b[36m8.5637\u001b[0m        \u001b[32m1.7154\u001b[0m  0.1064\n",
      "     19        \u001b[36m5.7782\u001b[0m        \u001b[32m1.6977\u001b[0m  0.1191\n",
      "     20        \u001b[36m2.1487\u001b[0m        \u001b[32m1.6843\u001b[0m  0.1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [03:12<00:59,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m926.9807\u001b[0m     \u001b[32m2064.7693\u001b[0m  0.1188\n",
      "      2      \u001b[36m282.9863\u001b[0m      \u001b[32m156.7105\u001b[0m  0.1197\n",
      "      3       \u001b[36m78.5353\u001b[0m       \u001b[32m41.8162\u001b[0m  0.1143\n",
      "      4       \u001b[36m20.2554\u001b[0m       \u001b[32m12.2144\u001b[0m  0.1157\n",
      "      5        \u001b[36m7.0863\u001b[0m        \u001b[32m5.4943\u001b[0m  0.1885\n",
      "      6        \u001b[36m4.9667\u001b[0m        \u001b[32m4.2632\u001b[0m  0.1304\n",
      "      7        \u001b[36m4.3620\u001b[0m        \u001b[32m3.7672\u001b[0m  0.1127\n",
      "      8        \u001b[36m3.8288\u001b[0m        \u001b[32m3.4172\u001b[0m  0.1170\n",
      "      9        \u001b[36m3.4170\u001b[0m        \u001b[32m3.1368\u001b[0m  0.1102\n",
      "     10        \u001b[36m3.1119\u001b[0m        \u001b[32m2.8807\u001b[0m  0.1227\n",
      "     11        \u001b[36m2.8566\u001b[0m        \u001b[32m2.6497\u001b[0m  0.1135\n",
      "     12        \u001b[36m2.6358\u001b[0m        \u001b[32m2.3889\u001b[0m  0.1124\n",
      "     13        \u001b[36m2.4348\u001b[0m        \u001b[32m2.2231\u001b[0m  0.1302\n",
      "     14        \u001b[36m2.2611\u001b[0m        \u001b[32m2.0649\u001b[0m  0.1157\n",
      "     15        \u001b[36m2.1169\u001b[0m        \u001b[32m1.9272\u001b[0m  0.1153\n",
      "     16        \u001b[36m1.9946\u001b[0m        \u001b[32m1.8199\u001b[0m  0.1083\n",
      "     17        \u001b[36m1.8927\u001b[0m        \u001b[32m1.7095\u001b[0m  0.1093\n",
      "     18        \u001b[36m1.8016\u001b[0m        \u001b[32m1.6406\u001b[0m  0.1100\n",
      "     19        \u001b[36m1.7084\u001b[0m        \u001b[32m1.5308\u001b[0m  0.1098\n",
      "     20        \u001b[36m1.6329\u001b[0m        \u001b[32m1.4827\u001b[0m  0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [03:15<00:56,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.8118\u001b[0m        \u001b[32m1.9614\u001b[0m  0.1263\n",
      "      2        \u001b[36m1.7594\u001b[0m        \u001b[32m1.7112\u001b[0m  0.1205\n",
      "      3        \u001b[36m1.4149\u001b[0m        \u001b[32m1.7008\u001b[0m  0.1504\n",
      "      4        \u001b[36m1.3177\u001b[0m        1.7206  0.1500\n",
      "      5        \u001b[36m1.2553\u001b[0m        1.7415  0.1113\n",
      "      6        \u001b[36m1.2223\u001b[0m        1.7499  0.1140\n",
      "      7        \u001b[36m1.1872\u001b[0m        1.7525  0.1149\n",
      "      8        \u001b[36m1.1665\u001b[0m        1.8198  0.1141\n",
      "      9        \u001b[36m1.1337\u001b[0m        1.8212  0.1259\n",
      "     10        \u001b[36m1.1144\u001b[0m        1.7760  0.1197\n",
      "     11        \u001b[36m1.0991\u001b[0m        1.8015  0.1084\n",
      "     12        \u001b[36m1.0854\u001b[0m        1.8252  0.1099\n",
      "     13        \u001b[36m1.0628\u001b[0m        1.7163  0.1134\n",
      "     14        \u001b[36m1.0492\u001b[0m        1.7597  0.1099\n",
      "     15        \u001b[36m1.0347\u001b[0m        \u001b[32m1.6946\u001b[0m  0.1214\n",
      "     16        \u001b[36m1.0305\u001b[0m        1.7012  0.1145\n",
      "     17        1.0457        1.7010  0.1120\n",
      "     18        \u001b[36m1.0130\u001b[0m        \u001b[32m1.5738\u001b[0m  0.1170\n",
      "     19        \u001b[36m0.9862\u001b[0m        1.5751  0.1128\n",
      "     20        \u001b[36m0.9777\u001b[0m        \u001b[32m1.5239\u001b[0m  0.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [03:17<00:53,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m65425.6096\u001b[0m        \u001b[32m1.7747\u001b[0m  0.2087\n",
      "      2    \u001b[36m40284.0511\u001b[0m        \u001b[32m1.3862\u001b[0m  0.1733\n",
      "      3    \u001b[36m29291.0040\u001b[0m        \u001b[32m1.2566\u001b[0m  0.1112\n",
      "      4    \u001b[36m18974.8377\u001b[0m        \u001b[32m1.1797\u001b[0m  0.1095\n",
      "      5    \u001b[36m10407.5157\u001b[0m        \u001b[32m1.1489\u001b[0m  0.1334\n",
      "      6     \u001b[36m8899.9168\u001b[0m        \u001b[32m1.1421\u001b[0m  0.1162\n",
      "      7     \u001b[36m4914.0089\u001b[0m        1.1460  0.1102\n",
      "      8     \u001b[36m2598.3950\u001b[0m        1.1479  0.1208\n",
      "      9     \u001b[36m1723.4381\u001b[0m        \u001b[32m1.1311\u001b[0m  0.1259\n",
      "     10     \u001b[36m1023.7724\u001b[0m        \u001b[32m1.1157\u001b[0m  0.1198\n",
      "     11      \u001b[36m777.7936\u001b[0m        \u001b[32m1.1113\u001b[0m  0.1220\n",
      "     12      \u001b[36m417.2251\u001b[0m        \u001b[32m1.1029\u001b[0m  0.1022\n",
      "     13      \u001b[36m317.7851\u001b[0m        1.1623  0.1118\n",
      "     14      \u001b[36m174.0331\u001b[0m        1.1710  0.1081\n",
      "     15       \u001b[36m59.6800\u001b[0m        1.2191  0.1109\n",
      "     16       \u001b[36m16.6942\u001b[0m        1.2421  0.1171\n",
      "     17        \u001b[36m7.1758\u001b[0m        1.2326  0.1092\n",
      "     18        \u001b[36m3.2506\u001b[0m        1.2203  0.1094\n",
      "     19        \u001b[36m2.1165\u001b[0m        1.2112  0.1102\n",
      "     20        \u001b[36m1.4579\u001b[0m        1.2080  0.1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [03:19<00:51,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m5.6550\u001b[0m   \u001b[32m376049.6988\u001b[0m  0.1538\n",
      "      2        \u001b[36m2.5367\u001b[0m   \u001b[32m335514.4058\u001b[0m  0.1358\n",
      "      3        \u001b[36m1.5994\u001b[0m   368991.1524  0.1130\n",
      "      4        \u001b[36m1.2620\u001b[0m   353823.1614  0.1174\n",
      "      5        \u001b[36m1.1073\u001b[0m   356646.7428  0.1111\n",
      "      6        \u001b[36m1.0291\u001b[0m   357997.6173  0.1185\n",
      "      7        \u001b[36m0.9746\u001b[0m   376365.8571  0.1139\n",
      "      8        \u001b[36m0.9428\u001b[0m   363647.5466  0.1059\n",
      "      9        \u001b[36m0.9295\u001b[0m   376946.9464  0.1120\n",
      "     10        0.9331   373103.9820  0.1205\n",
      "     11        \u001b[36m0.9165\u001b[0m   396511.2445  0.1135\n",
      "     12        \u001b[36m0.9135\u001b[0m   370671.1488  0.1143\n",
      "     13        \u001b[36m0.9040\u001b[0m   403146.9846  0.1097\n",
      "     14        \u001b[36m0.9005\u001b[0m   385043.2155  0.1139\n",
      "     15        \u001b[36m0.8903\u001b[0m   383040.5321  0.1131\n",
      "     16        0.9006   400914.9580  0.1034\n",
      "     17        \u001b[36m0.8825\u001b[0m   390280.2687  0.1140\n",
      "     18        0.8999   405932.9377  0.1168\n",
      "     19        0.8839   411803.2120  0.1991\n",
      "     20        \u001b[36m0.8784\u001b[0m   386146.4518  0.1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [03:22<00:49,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m4298.2517\u001b[0m        \u001b[32m1.1798\u001b[0m  0.1230\n",
      "      2       \u001b[36m70.5376\u001b[0m        \u001b[32m1.0977\u001b[0m  0.1248\n",
      "      3       \u001b[36m21.6108\u001b[0m        \u001b[32m1.0926\u001b[0m  0.1239\n",
      "      4       61.1782        \u001b[32m1.0458\u001b[0m  0.1115\n",
      "      5       25.2971        1.0564  0.1159\n",
      "      6        \u001b[36m2.8282\u001b[0m        \u001b[32m1.0310\u001b[0m  0.1205\n",
      "      7        \u001b[36m1.1278\u001b[0m        1.0468  0.1154\n",
      "      8        1.9426        1.0407  0.1115\n",
      "      9        4.8991        \u001b[32m1.0248\u001b[0m  0.1181\n",
      "     10        1.3425        \u001b[32m1.0239\u001b[0m  0.1107\n",
      "     11       10.2282        1.0368  0.1122\n",
      "     12       45.0504        \u001b[32m1.0152\u001b[0m  0.1094\n",
      "     13      181.8463        1.0483  0.1119\n",
      "     14      273.0933        \u001b[32m1.0083\u001b[0m  0.1084\n",
      "     15      305.8691        1.0620  0.1210\n",
      "     16     1163.6638        1.0146  0.1144\n",
      "     17      155.7486        1.0363  0.1503\n",
      "     18     1214.7851        1.0904  0.1612\n",
      "     19     1079.6474        1.0140  0.1113\n",
      "     20      130.8786        1.0562  0.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [03:24<00:46,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m178378.7118\u001b[0m        \u001b[32m6.0805\u001b[0m  0.1170\n",
      "      2   \u001b[36m104918.7587\u001b[0m        \u001b[32m5.4146\u001b[0m  0.1286\n",
      "      3    \u001b[36m81564.3523\u001b[0m        \u001b[32m3.9509\u001b[0m  0.1218\n",
      "      4    \u001b[36m40247.3435\u001b[0m        \u001b[32m3.5028\u001b[0m  0.1130\n",
      "      5    \u001b[36m26470.3835\u001b[0m        \u001b[32m3.1870\u001b[0m  0.1134\n",
      "      6    \u001b[36m14325.1785\u001b[0m        \u001b[32m2.9801\u001b[0m  0.1165\n",
      "      7     \u001b[36m9618.6547\u001b[0m        \u001b[32m2.7660\u001b[0m  0.1080\n",
      "      8     \u001b[36m5342.1430\u001b[0m        \u001b[32m2.4326\u001b[0m  0.1109\n",
      "      9     \u001b[36m3388.1101\u001b[0m        \u001b[32m2.2640\u001b[0m  0.1099\n",
      "     10     \u001b[36m1859.7560\u001b[0m        \u001b[32m2.0727\u001b[0m  0.1095\n",
      "     11     \u001b[36m1389.5852\u001b[0m        \u001b[32m1.9419\u001b[0m  0.1096\n",
      "     12      \u001b[36m499.1926\u001b[0m        \u001b[32m1.8482\u001b[0m  0.1797\n",
      "     13      \u001b[36m346.5980\u001b[0m        \u001b[32m1.7980\u001b[0m  0.1389\n",
      "     14      \u001b[36m128.1722\u001b[0m        \u001b[32m1.6995\u001b[0m  0.1177\n",
      "     15       \u001b[36m59.1800\u001b[0m        \u001b[32m1.6487\u001b[0m  0.1691\n",
      "     16       \u001b[36m25.0929\u001b[0m        \u001b[32m1.5643\u001b[0m  0.1561\n",
      "     17        \u001b[36m9.1907\u001b[0m        \u001b[32m1.5354\u001b[0m  0.1111\n",
      "     18     1542.6690        1.6074  0.1097\n",
      "     19        \u001b[36m1.6579\u001b[0m        1.6301  0.1271\n",
      "     20      224.5781        1.5626  0.1147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [03:27<00:44,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m5.0430\u001b[0m        \u001b[32m1.6537\u001b[0m  0.1311\n",
      "      2        \u001b[36m2.9043\u001b[0m        \u001b[32m1.1779\u001b[0m  0.1129\n",
      "      3        \u001b[36m2.0227\u001b[0m        \u001b[32m1.1329\u001b[0m  0.1055\n",
      "      4        \u001b[36m1.7365\u001b[0m        1.1785  0.1112\n",
      "      5        \u001b[36m1.4966\u001b[0m        1.1911  0.1154\n",
      "      6        \u001b[36m1.4216\u001b[0m        1.1945  0.1138\n",
      "      7        \u001b[36m1.2755\u001b[0m        1.1864  0.1250\n",
      "      8        \u001b[36m1.2093\u001b[0m        1.1920  0.1167\n",
      "      9        \u001b[36m1.1506\u001b[0m        1.1695  0.1073\n",
      "     10        \u001b[36m1.0904\u001b[0m        1.1714  0.1176\n",
      "     11        \u001b[36m1.0674\u001b[0m        1.1519  0.1097\n",
      "     12        \u001b[36m1.0182\u001b[0m        1.1625  0.1103\n",
      "     13        \u001b[36m0.9872\u001b[0m        1.1411  0.1118\n",
      "     14        \u001b[36m0.9834\u001b[0m        1.1571  0.1993\n",
      "     15        \u001b[36m0.9496\u001b[0m        \u001b[32m1.1273\u001b[0m  0.1336\n",
      "     16        \u001b[36m0.9352\u001b[0m        1.1296  0.1043\n",
      "     17        \u001b[36m0.9246\u001b[0m        \u001b[32m1.1205\u001b[0m  0.1217\n",
      "     18        \u001b[36m0.9151\u001b[0m        1.1593  0.1085\n",
      "     19        \u001b[36m0.9001\u001b[0m        \u001b[32m1.1076\u001b[0m  0.1216\n",
      "     20        0.9035        1.1335  0.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [03:29<00:41,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m4699.6422\u001b[0m        \u001b[32m4.9120\u001b[0m  0.1287\n",
      "      2     \u001b[36m2847.6308\u001b[0m        \u001b[32m2.6067\u001b[0m  0.1184\n",
      "      3     \u001b[36m1925.2617\u001b[0m        \u001b[32m1.7494\u001b[0m  0.1113\n",
      "      4     \u001b[36m1041.4345\u001b[0m        \u001b[32m1.3993\u001b[0m  0.1263\n",
      "      5      \u001b[36m650.2945\u001b[0m        \u001b[32m1.2940\u001b[0m  0.1108\n",
      "      6      \u001b[36m330.0623\u001b[0m        \u001b[32m1.2691\u001b[0m  0.1203\n",
      "      7      \u001b[36m203.7781\u001b[0m        \u001b[32m1.2653\u001b[0m  0.1124\n",
      "      8      \u001b[36m116.5093\u001b[0m        \u001b[32m1.2308\u001b[0m  0.1103\n",
      "      9       \u001b[36m71.1816\u001b[0m        \u001b[32m1.2124\u001b[0m  0.1126\n",
      "     10       \u001b[36m23.0922\u001b[0m        \u001b[32m1.2002\u001b[0m  0.1093\n",
      "     11        \u001b[36m5.5903\u001b[0m        1.2012  0.1205\n",
      "     12       21.3950        \u001b[32m1.1813\u001b[0m  0.1907\n",
      "     13        \u001b[36m1.1022\u001b[0m        \u001b[32m1.1735\u001b[0m  0.1566\n",
      "     14        7.1255        1.1889  0.1093\n",
      "     15        1.3866        1.1762  0.1099\n",
      "     16        1.2011        1.1803  0.1200\n",
      "     17        \u001b[36m1.0510\u001b[0m        1.1860  0.1201\n",
      "     18        1.0818        1.1917  0.1099\n",
      "     19        \u001b[36m1.0341\u001b[0m        1.1838  0.1100\n",
      "     20        1.0360        1.1809  0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [03:32<00:39,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m2991.8597\u001b[0m        \u001b[32m7.7814\u001b[0m  0.1195\n",
      "      2      \u001b[36m303.3153\u001b[0m        \u001b[32m5.9203\u001b[0m  0.1102\n",
      "      3      \u001b[36m232.3933\u001b[0m        \u001b[32m4.1650\u001b[0m  0.1149\n",
      "      4       \u001b[36m11.4941\u001b[0m        \u001b[32m2.9626\u001b[0m  0.1020\n",
      "      5      143.3196        \u001b[32m2.8234\u001b[0m  0.1104\n",
      "      6      199.4231        \u001b[32m2.3777\u001b[0m  0.1098\n",
      "      7      115.6185        \u001b[32m2.3028\u001b[0m  0.1030\n",
      "      8      114.4914        \u001b[32m2.1770\u001b[0m  0.1215\n",
      "      9        \u001b[36m5.9493\u001b[0m        \u001b[32m2.0964\u001b[0m  0.1156\n",
      "     10       99.4573        2.1789  0.1026\n",
      "     11      176.6881        \u001b[32m1.9524\u001b[0m  0.1985\n",
      "     12      163.9359        2.1032  0.1391\n",
      "     13      171.8972        \u001b[32m1.9327\u001b[0m  0.1141\n",
      "     14      126.4229        2.0058  0.1061\n",
      "     15       39.4482        \u001b[32m1.9041\u001b[0m  0.1207\n",
      "     16       14.6562        1.9860  0.1954\n",
      "     17       23.5782        \u001b[32m1.8951\u001b[0m  0.1149\n",
      "     18       62.7639        1.9642  0.1174\n",
      "     19      125.5745        1.8968  0.1110\n",
      "     20       20.1449        1.9922  0.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [03:34<00:37,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m152556.1480\u001b[0m        \u001b[32m3.0844\u001b[0m  0.1330\n",
      "      2    \u001b[36m97496.9302\u001b[0m        \u001b[32m2.0108\u001b[0m  0.1230\n",
      "      3    \u001b[36m65143.7768\u001b[0m        \u001b[32m1.6024\u001b[0m  0.1141\n",
      "      4    \u001b[36m29747.7533\u001b[0m        \u001b[32m1.5544\u001b[0m  0.1175\n",
      "      5    \u001b[36m11770.6847\u001b[0m        \u001b[32m1.5169\u001b[0m  0.1140\n",
      "      6     \u001b[36m6030.4280\u001b[0m        \u001b[32m1.4540\u001b[0m  0.1130\n",
      "      7     \u001b[36m1805.3532\u001b[0m        \u001b[32m1.4096\u001b[0m  0.1108\n",
      "      8      \u001b[36m412.6673\u001b[0m        \u001b[32m1.3649\u001b[0m  0.1100\n",
      "      9       \u001b[36m92.4746\u001b[0m        \u001b[32m1.3472\u001b[0m  0.2013\n",
      "     10        \u001b[36m1.2945\u001b[0m        \u001b[32m1.3304\u001b[0m  0.1355\n",
      "     11        1.3102        \u001b[32m1.3078\u001b[0m  0.1171\n",
      "     12        \u001b[36m1.2892\u001b[0m        \u001b[32m1.2911\u001b[0m  0.1198\n",
      "     13        \u001b[36m1.0847\u001b[0m        \u001b[32m1.2902\u001b[0m  0.1192\n",
      "     14        \u001b[36m1.0136\u001b[0m        \u001b[32m1.2798\u001b[0m  0.1190\n",
      "     15        \u001b[36m0.9886\u001b[0m        \u001b[32m1.2732\u001b[0m  0.1199\n",
      "     16        \u001b[36m0.9734\u001b[0m        1.2749  0.1219\n",
      "     17        \u001b[36m0.9651\u001b[0m        \u001b[32m1.2534\u001b[0m  0.1180\n",
      "     18        7.3901        \u001b[32m1.2335\u001b[0m  0.1096\n",
      "     19        1.2746        1.2439  0.1104\n",
      "     20       25.8043        1.2358  0.1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [03:37<00:34,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m36.1541\u001b[0m        \u001b[32m9.8705\u001b[0m  0.1100\n",
      "      2        \u001b[36m8.7428\u001b[0m        \u001b[32m3.1318\u001b[0m  0.1215\n",
      "      3        \u001b[36m5.1665\u001b[0m        \u001b[32m2.0240\u001b[0m  0.1108\n",
      "      4        \u001b[36m3.6900\u001b[0m        \u001b[32m1.8142\u001b[0m  0.1110\n",
      "      5        \u001b[36m3.0368\u001b[0m        \u001b[32m1.6891\u001b[0m  0.1076\n",
      "      6        \u001b[36m2.6873\u001b[0m        \u001b[32m1.5852\u001b[0m  0.1061\n",
      "      7        \u001b[36m2.2116\u001b[0m        \u001b[32m1.5137\u001b[0m  0.1131\n",
      "      8        \u001b[36m1.9050\u001b[0m        \u001b[32m1.4707\u001b[0m  0.1665\n",
      "      9        \u001b[36m1.7865\u001b[0m        \u001b[32m1.4296\u001b[0m  0.1301\n",
      "     10        \u001b[36m1.5425\u001b[0m        \u001b[32m1.3804\u001b[0m  0.1094\n",
      "     11        \u001b[36m1.3840\u001b[0m        \u001b[32m1.3683\u001b[0m  0.1069\n",
      "     12        \u001b[36m1.2610\u001b[0m        \u001b[32m1.3189\u001b[0m  0.1162\n",
      "     13        \u001b[36m1.1767\u001b[0m        \u001b[32m1.2835\u001b[0m  0.1106\n",
      "     14        \u001b[36m1.1039\u001b[0m        \u001b[32m1.2586\u001b[0m  0.1079\n",
      "     15        \u001b[36m1.0600\u001b[0m        \u001b[32m1.2425\u001b[0m  0.1083\n",
      "     16        \u001b[36m1.0182\u001b[0m        \u001b[32m1.2173\u001b[0m  0.1097\n",
      "     17        \u001b[36m0.9985\u001b[0m        1.2193  0.1100\n",
      "     18        \u001b[36m0.9744\u001b[0m        \u001b[32m1.2093\u001b[0m  0.1100\n",
      "     19        \u001b[36m0.9606\u001b[0m        \u001b[32m1.2019\u001b[0m  0.1046\n",
      "     20        \u001b[36m0.9496\u001b[0m        1.2115  0.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [03:39<00:31,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m8491.0248\u001b[0m        \u001b[32m1.5726\u001b[0m  0.1134\n",
      "      2     \u001b[36m2244.6339\u001b[0m        \u001b[32m1.4827\u001b[0m  0.1141\n",
      "      3        \u001b[36m1.7731\u001b[0m        \u001b[32m1.1664\u001b[0m  0.1036\n",
      "      4       45.8524        1.1882  0.1032\n",
      "      5       11.3343        \u001b[32m1.1320\u001b[0m  0.1056\n",
      "      6        \u001b[36m1.6217\u001b[0m        1.1583  0.1096\n",
      "      7        \u001b[36m1.5202\u001b[0m        1.1587  0.1489\n",
      "      8        \u001b[36m1.1013\u001b[0m        \u001b[32m1.0978\u001b[0m  0.1506\n",
      "      9        \u001b[36m1.0744\u001b[0m        \u001b[32m1.0933\u001b[0m  0.1098\n",
      "     10        \u001b[36m1.0513\u001b[0m        \u001b[32m1.0878\u001b[0m  0.1157\n",
      "     11        \u001b[36m1.0124\u001b[0m        1.1584  0.1122\n",
      "     12        \u001b[36m0.9979\u001b[0m        \u001b[32m1.0708\u001b[0m  0.1141\n",
      "     13        \u001b[36m0.9961\u001b[0m        1.0908  0.1309\n",
      "     14        \u001b[36m0.9757\u001b[0m        1.0935  0.1140\n",
      "     15        0.9867        \u001b[32m1.0638\u001b[0m  0.1067\n",
      "     16        \u001b[36m0.9653\u001b[0m        1.0916  0.1190\n",
      "     17        1.0088        \u001b[32m1.0638\u001b[0m  0.1088\n",
      "     18        0.9939        1.0734  0.1104\n",
      "     19        1.0057        1.2705  0.1080\n",
      "     20        0.9724        1.1038  0.1083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [03:41<00:28,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m11.4381\u001b[0m        \u001b[32m5.9633\u001b[0m  0.1112\n",
      "      2        \u001b[36m5.4399\u001b[0m        \u001b[32m3.4724\u001b[0m  0.1338\n",
      "      3        \u001b[36m3.2634\u001b[0m        \u001b[32m2.5915\u001b[0m  0.1234\n",
      "      4        \u001b[36m2.1737\u001b[0m        \u001b[32m2.2910\u001b[0m  0.1183\n",
      "      5        \u001b[36m1.7140\u001b[0m        \u001b[32m2.1327\u001b[0m  0.1316\n",
      "      6        \u001b[36m1.5098\u001b[0m        \u001b[32m1.8643\u001b[0m  0.1888\n",
      "      7        \u001b[36m1.3853\u001b[0m        \u001b[32m1.7552\u001b[0m  0.1175\n",
      "      8        \u001b[36m1.3163\u001b[0m        \u001b[32m1.6843\u001b[0m  0.1116\n",
      "      9        \u001b[36m1.2626\u001b[0m        \u001b[32m1.6576\u001b[0m  0.1097\n",
      "     10        \u001b[36m1.2188\u001b[0m        \u001b[32m1.6095\u001b[0m  0.1184\n",
      "     11        \u001b[36m1.1821\u001b[0m        \u001b[32m1.6032\u001b[0m  0.1259\n",
      "     12        \u001b[36m1.1553\u001b[0m        \u001b[32m1.5597\u001b[0m  0.1108\n",
      "     13        \u001b[36m1.1327\u001b[0m        \u001b[32m1.5566\u001b[0m  0.1112\n",
      "     14        \u001b[36m1.1106\u001b[0m        \u001b[32m1.5313\u001b[0m  0.1119\n",
      "     15        \u001b[36m1.0852\u001b[0m        1.5393  0.1113\n",
      "     16        \u001b[36m1.0654\u001b[0m        \u001b[32m1.4941\u001b[0m  0.1083\n",
      "     17        \u001b[36m1.0467\u001b[0m        \u001b[32m1.4851\u001b[0m  0.1150\n",
      "     18        \u001b[36m1.0219\u001b[0m        1.4946  0.1090\n",
      "     19        \u001b[36m0.9986\u001b[0m        \u001b[32m1.4587\u001b[0m  0.1232\n",
      "     20        \u001b[36m0.9757\u001b[0m        \u001b[32m1.4208\u001b[0m  0.1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [03:44<00:26,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m29.3951\u001b[0m        \u001b[32m8.0358\u001b[0m  0.1264\n",
      "      2        \u001b[36m3.6111\u001b[0m        \u001b[32m2.0052\u001b[0m  0.1227\n",
      "      3        \u001b[36m1.9473\u001b[0m        2.1062  0.1087\n",
      "      4        \u001b[36m1.8420\u001b[0m        \u001b[32m1.7649\u001b[0m  0.1777\n",
      "      5        \u001b[36m1.6462\u001b[0m        \u001b[32m1.6117\u001b[0m  0.1491\n",
      "      6        \u001b[36m1.5553\u001b[0m        \u001b[32m1.5525\u001b[0m  0.1096\n",
      "      7        \u001b[36m1.5051\u001b[0m        \u001b[32m1.5006\u001b[0m  0.1223\n",
      "      8        \u001b[36m1.4738\u001b[0m        \u001b[32m1.4558\u001b[0m  0.1138\n",
      "      9        \u001b[36m1.4107\u001b[0m        \u001b[32m1.4250\u001b[0m  0.1159\n",
      "     10        \u001b[36m1.3526\u001b[0m        \u001b[32m1.3853\u001b[0m  0.1115\n",
      "     11        \u001b[36m1.3172\u001b[0m        \u001b[32m1.3675\u001b[0m  0.1089\n",
      "     12        \u001b[36m1.2838\u001b[0m        \u001b[32m1.3390\u001b[0m  0.1110\n",
      "     13        \u001b[36m1.2597\u001b[0m        \u001b[32m1.3244\u001b[0m  0.1115\n",
      "     14        \u001b[36m1.2344\u001b[0m        \u001b[32m1.3228\u001b[0m  0.1062\n",
      "     15        \u001b[36m1.2162\u001b[0m        \u001b[32m1.2885\u001b[0m  0.1160\n",
      "     16        \u001b[36m1.1912\u001b[0m        \u001b[32m1.2848\u001b[0m  0.1258\n",
      "     17        \u001b[36m1.1753\u001b[0m        \u001b[32m1.2666\u001b[0m  0.1127\n",
      "     18        \u001b[36m1.1609\u001b[0m        1.2775  0.1125\n",
      "     19        \u001b[36m1.1473\u001b[0m        \u001b[32m1.2583\u001b[0m  0.1114\n",
      "     20        \u001b[36m1.1416\u001b[0m        \u001b[32m1.2409\u001b[0m  0.1123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [03:46<00:24,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.4420\u001b[0m        \u001b[32m2.9427\u001b[0m  0.1288\n",
      "      2        \u001b[36m1.4237\u001b[0m        \u001b[32m2.2653\u001b[0m  0.1379\n",
      "      3        \u001b[36m1.2269\u001b[0m        \u001b[32m2.1004\u001b[0m  0.2149\n",
      "      4        \u001b[36m1.1817\u001b[0m        \u001b[32m2.0112\u001b[0m  0.1206\n",
      "      5        \u001b[36m1.1521\u001b[0m        \u001b[32m1.8652\u001b[0m  0.1216\n",
      "      6        \u001b[36m1.1341\u001b[0m        2.0115  0.1078\n",
      "      7        \u001b[36m1.0975\u001b[0m        1.8837  0.1036\n",
      "      8        \u001b[36m1.0611\u001b[0m        \u001b[32m1.7768\u001b[0m  0.1055\n",
      "      9        \u001b[36m1.0345\u001b[0m        2.0186  0.1048\n",
      "     10        1.0372        \u001b[32m1.5941\u001b[0m  0.1012\n",
      "     11        \u001b[36m1.0254\u001b[0m        \u001b[32m1.5663\u001b[0m  0.1100\n",
      "     12        \u001b[36m0.9986\u001b[0m        \u001b[32m1.5309\u001b[0m  0.1153\n",
      "     13        \u001b[36m0.9625\u001b[0m        \u001b[32m1.5221\u001b[0m  0.1074\n",
      "     14        \u001b[36m0.9440\u001b[0m        1.6666  0.1051\n",
      "     15        0.9802        1.7486  0.1065\n",
      "     16        0.9570        \u001b[32m1.4910\u001b[0m  0.1182\n",
      "     17        \u001b[36m0.9296\u001b[0m        \u001b[32m1.4524\u001b[0m  0.1103\n",
      "     18        0.9377        1.5623  0.1042\n",
      "     19        0.9308        1.5961  0.1051\n",
      "     20        \u001b[36m0.9204\u001b[0m        \u001b[32m1.4391\u001b[0m  0.1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [03:49<00:21,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1  \u001b[36m1736501.8755\u001b[0m      \u001b[32m465.3196\u001b[0m  0.1417\n",
      "      2  \u001b[36m1138263.1212\u001b[0m      \u001b[32m394.1424\u001b[0m  0.3110\n",
      "      3   \u001b[36m823927.5646\u001b[0m      \u001b[32m362.1286\u001b[0m  0.1456\n",
      "      4   \u001b[36m531452.5571\u001b[0m      \u001b[32m326.5433\u001b[0m  0.1196\n",
      "      5   \u001b[36m359826.4141\u001b[0m      \u001b[32m300.2156\u001b[0m  0.1225\n",
      "      6   \u001b[36m239289.8681\u001b[0m      \u001b[32m261.2562\u001b[0m  0.1237\n",
      "      7   \u001b[36m124100.4398\u001b[0m      \u001b[32m214.5160\u001b[0m  0.1212\n",
      "      8    \u001b[36m80699.7676\u001b[0m      \u001b[32m196.8282\u001b[0m  0.1318\n",
      "      9    \u001b[36m51227.1906\u001b[0m      \u001b[32m177.0067\u001b[0m  0.1072\n",
      "     10    \u001b[36m21967.3645\u001b[0m      \u001b[32m147.6949\u001b[0m  0.1185\n",
      "     11    \u001b[36m14765.0486\u001b[0m      \u001b[32m125.1101\u001b[0m  0.1312\n",
      "     12     \u001b[36m5500.2475\u001b[0m      \u001b[32m103.3027\u001b[0m  0.1172\n",
      "     13     \u001b[36m2546.6393\u001b[0m       \u001b[32m84.3286\u001b[0m  0.1125\n",
      "     14     \u001b[36m1587.0736\u001b[0m       \u001b[32m71.4045\u001b[0m  0.1125\n",
      "     15      \u001b[36m647.6351\u001b[0m       \u001b[32m60.1546\u001b[0m  0.1320\n",
      "     16      \u001b[36m179.8002\u001b[0m       \u001b[32m50.3820\u001b[0m  0.1069\n",
      "     17      \u001b[36m110.7265\u001b[0m       \u001b[32m42.5948\u001b[0m  0.1132\n",
      "     18       \u001b[36m52.1012\u001b[0m       \u001b[32m36.1671\u001b[0m  0.1167\n",
      "     19       \u001b[36m28.8366\u001b[0m       \u001b[32m31.0583\u001b[0m  0.1539\n",
      "     20       \u001b[36m20.2956\u001b[0m       \u001b[32m26.9374\u001b[0m  0.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [03:51<00:20,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m184031.1973\u001b[0m      \u001b[32m218.3359\u001b[0m  0.1504\n",
      "      2   \u001b[36m110321.2376\u001b[0m       \u001b[32m96.1941\u001b[0m  0.1505\n",
      "      3    \u001b[36m77375.5433\u001b[0m       \u001b[32m41.4161\u001b[0m  0.1379\n",
      "      4    \u001b[36m52052.2945\u001b[0m       \u001b[32m15.6307\u001b[0m  0.1270\n",
      "      5    \u001b[36m28781.3957\u001b[0m        \u001b[32m5.4339\u001b[0m  0.1327\n",
      "      6    \u001b[36m16349.8565\u001b[0m        \u001b[32m2.6261\u001b[0m  0.1236\n",
      "      7    \u001b[36m10699.8243\u001b[0m        \u001b[32m2.4117\u001b[0m  0.1172\n",
      "      8     \u001b[36m5826.0799\u001b[0m        \u001b[32m2.3452\u001b[0m  0.1140\n",
      "      9     \u001b[36m3469.7716\u001b[0m        2.4159  0.1113\n",
      "     10     \u001b[36m1293.7134\u001b[0m        \u001b[32m2.3108\u001b[0m  0.1119\n",
      "     11      \u001b[36m802.4360\u001b[0m        \u001b[32m2.2647\u001b[0m  0.1110\n",
      "     12      \u001b[36m229.7878\u001b[0m        \u001b[32m2.2097\u001b[0m  0.1102\n",
      "     13      \u001b[36m126.2132\u001b[0m        \u001b[32m2.1705\u001b[0m  0.1180\n",
      "     14       \u001b[36m31.1022\u001b[0m        \u001b[32m2.0932\u001b[0m  0.1119\n",
      "     15       \u001b[36m14.8104\u001b[0m        \u001b[32m2.0368\u001b[0m  0.1094\n",
      "     16        \u001b[36m4.3550\u001b[0m        \u001b[32m1.9947\u001b[0m  0.1103\n",
      "     17        \u001b[36m2.8650\u001b[0m        \u001b[32m1.9255\u001b[0m  0.1502\n",
      "     18        \u001b[36m2.1142\u001b[0m        \u001b[32m1.8790\u001b[0m  0.1613\n",
      "     19        \u001b[36m1.8761\u001b[0m        \u001b[32m1.8154\u001b[0m  0.1223\n",
      "     20        \u001b[36m1.7916\u001b[0m        \u001b[32m1.7618\u001b[0m  0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [03:54<00:17,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1      \u001b[36m984.5977\u001b[0m       \u001b[32m39.5641\u001b[0m  0.1159\n",
      "      2      \u001b[36m338.6922\u001b[0m       \u001b[32m16.4603\u001b[0m  0.1278\n",
      "      3     1871.6315        \u001b[32m8.0613\u001b[0m  0.1085\n",
      "      4      800.5161        \u001b[32m5.5275\u001b[0m  0.1254\n",
      "      5      \u001b[36m117.9442\u001b[0m        \u001b[32m3.5445\u001b[0m  0.1038\n",
      "      6       \u001b[36m72.5308\u001b[0m        \u001b[32m2.6687\u001b[0m  0.1130\n",
      "      7       \u001b[36m43.9247\u001b[0m        \u001b[32m2.4106\u001b[0m  0.1160\n",
      "      8       \u001b[36m25.0591\u001b[0m        \u001b[32m2.3216\u001b[0m  0.1098\n",
      "      9       \u001b[36m19.3637\u001b[0m        \u001b[32m2.2665\u001b[0m  0.1073\n",
      "     10       \u001b[36m11.1750\u001b[0m        \u001b[32m2.2094\u001b[0m  0.1051\n",
      "     11        \u001b[36m7.5788\u001b[0m        \u001b[32m2.1646\u001b[0m  0.1124\n",
      "     12        \u001b[36m5.9703\u001b[0m        \u001b[32m2.1281\u001b[0m  0.1100\n",
      "     13        \u001b[36m4.3486\u001b[0m        \u001b[32m2.0893\u001b[0m  0.1187\n",
      "     14        \u001b[36m3.5142\u001b[0m        \u001b[32m2.0561\u001b[0m  0.1156\n",
      "     15        \u001b[36m2.9485\u001b[0m        \u001b[32m2.0224\u001b[0m  0.1202\n",
      "     16        \u001b[36m2.7564\u001b[0m        \u001b[32m1.9957\u001b[0m  0.1997\n",
      "     17        \u001b[36m2.3015\u001b[0m        \u001b[32m1.9549\u001b[0m  0.1251\n",
      "     18        \u001b[36m2.1088\u001b[0m        \u001b[32m1.9393\u001b[0m  0.1107\n",
      "     19        \u001b[36m1.9532\u001b[0m        \u001b[32m1.9018\u001b[0m  0.1114\n",
      "     20        \u001b[36m1.8008\u001b[0m        \u001b[32m1.8642\u001b[0m  0.1187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [03:56<00:15,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m17.4206\u001b[0m        \u001b[32m4.4106\u001b[0m  0.1225\n",
      "      2        \u001b[36m3.5814\u001b[0m        \u001b[32m2.2778\u001b[0m  0.1174\n",
      "      3        \u001b[36m2.5760\u001b[0m        \u001b[32m2.2535\u001b[0m  0.1308\n",
      "      4        \u001b[36m2.2996\u001b[0m        \u001b[32m1.9359\u001b[0m  0.1284\n",
      "      5        \u001b[36m2.0281\u001b[0m        \u001b[32m1.7713\u001b[0m  0.1320\n",
      "      6        \u001b[36m1.8468\u001b[0m        \u001b[32m1.5889\u001b[0m  0.1263\n",
      "      7        \u001b[36m1.6790\u001b[0m        \u001b[32m1.5708\u001b[0m  0.1204\n",
      "      8        \u001b[36m1.5491\u001b[0m        2.0216  0.1175\n",
      "      9        \u001b[36m1.4519\u001b[0m        3.0600  0.1044\n",
      "     10        \u001b[36m1.3591\u001b[0m        4.7350  0.1040\n",
      "     11        \u001b[36m1.3034\u001b[0m        6.4194  0.1133\n",
      "     12        \u001b[36m1.2362\u001b[0m        8.5533  0.1153\n",
      "     13        \u001b[36m1.1948\u001b[0m       10.5989  0.1097\n",
      "     14        \u001b[36m1.1455\u001b[0m       12.3130  0.1691\n",
      "     15        \u001b[36m1.1184\u001b[0m       13.5632  0.2200\n",
      "     16        \u001b[36m1.0969\u001b[0m       14.9134  0.1112\n",
      "     17        \u001b[36m1.0702\u001b[0m       15.6979  0.1130\n",
      "     18        \u001b[36m1.0526\u001b[0m       16.0729  0.1173\n",
      "     19        \u001b[36m1.0397\u001b[0m       15.9364  0.1178\n",
      "     20        \u001b[36m1.0339\u001b[0m       15.8316  0.1086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [03:59<00:12,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m36925.1126\u001b[0m        \u001b[32m2.8736\u001b[0m  0.1194\n",
      "      2    \u001b[36m15793.6000\u001b[0m        \u001b[32m2.1094\u001b[0m  0.1215\n",
      "      3     \u001b[36m9408.4821\u001b[0m        \u001b[32m1.7436\u001b[0m  0.1082\n",
      "      4     \u001b[36m2858.6047\u001b[0m        \u001b[32m1.5469\u001b[0m  0.1108\n",
      "      5      \u001b[36m276.2999\u001b[0m        \u001b[32m1.4296\u001b[0m  0.1084\n",
      "      6       \u001b[36m43.1632\u001b[0m        \u001b[32m1.3130\u001b[0m  0.1104\n",
      "      7        \u001b[36m6.6210\u001b[0m        \u001b[32m1.2270\u001b[0m  0.1196\n",
      "      8        \u001b[36m1.4851\u001b[0m        \u001b[32m1.1664\u001b[0m  0.1204\n",
      "      9        1.7050        \u001b[32m1.1452\u001b[0m  0.1100\n",
      "     10        \u001b[36m1.3554\u001b[0m        \u001b[32m1.1079\u001b[0m  0.1118\n",
      "     11        1.4757        \u001b[32m1.1016\u001b[0m  0.1105\n",
      "     12        5.8309        1.1271  0.1256\n",
      "     13        2.2138        \u001b[32m1.0565\u001b[0m  0.1816\n",
      "     14        2.1972        1.0579  0.1141\n",
      "     15        \u001b[36m1.0802\u001b[0m        \u001b[32m1.0522\u001b[0m  0.1130\n",
      "     16        \u001b[36m1.0470\u001b[0m        \u001b[32m1.0472\u001b[0m  0.1097\n",
      "     17        \u001b[36m1.0396\u001b[0m        1.0514  0.1246\n",
      "     18        4.2263        \u001b[32m1.0365\u001b[0m  0.1148\n",
      "     19        1.3084        \u001b[32m1.0138\u001b[0m  0.1338\n",
      "     20        2.6751        1.0417  0.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [04:01<00:09,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m23.8360\u001b[0m    \u001b[32m99321.6870\u001b[0m  0.1328\n",
      "      2        \u001b[36m6.3220\u001b[0m    \u001b[32m40047.8380\u001b[0m  0.1466\n",
      "      3        \u001b[36m2.9925\u001b[0m    \u001b[32m23624.6503\u001b[0m  0.1206\n",
      "      4        \u001b[36m2.2458\u001b[0m    \u001b[32m21048.1073\u001b[0m  0.1236\n",
      "      5        \u001b[36m1.7653\u001b[0m    \u001b[32m18264.4222\u001b[0m  0.1171\n",
      "      6        \u001b[36m1.5724\u001b[0m    \u001b[32m15162.4841\u001b[0m  0.1377\n",
      "      7        \u001b[36m1.4603\u001b[0m    \u001b[32m12133.3071\u001b[0m  0.1310\n",
      "      8        \u001b[36m1.3873\u001b[0m     \u001b[32m9705.0104\u001b[0m  0.1580\n",
      "      9        \u001b[36m1.3329\u001b[0m     \u001b[32m7672.5253\u001b[0m  0.1601\n",
      "     10        \u001b[36m1.2878\u001b[0m     \u001b[32m6001.5633\u001b[0m  0.1781\n",
      "     11        \u001b[36m1.2514\u001b[0m     \u001b[32m4639.2231\u001b[0m  0.1167\n",
      "     12        \u001b[36m1.2180\u001b[0m     \u001b[32m3286.0334\u001b[0m  0.1137\n",
      "     13        \u001b[36m1.1870\u001b[0m     \u001b[32m2002.0206\u001b[0m  0.1190\n",
      "     14        \u001b[36m1.1653\u001b[0m     \u001b[32m1284.2911\u001b[0m  0.1440\n",
      "     15        \u001b[36m1.1428\u001b[0m      \u001b[32m686.3219\u001b[0m  0.1402\n",
      "     16        \u001b[36m1.1224\u001b[0m      \u001b[32m297.6770\u001b[0m  0.1103\n",
      "     17        \u001b[36m1.1049\u001b[0m       \u001b[32m78.8477\u001b[0m  0.1206\n",
      "     18        \u001b[36m1.0878\u001b[0m        \u001b[32m5.5822\u001b[0m  0.1187\n",
      "     19        \u001b[36m1.0693\u001b[0m      112.1778  0.1199\n",
      "     20        \u001b[36m1.0657\u001b[0m      336.7008  0.1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [04:04<00:07,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1  \u001b[36m1233652.4743\u001b[0m       \u001b[32m38.4570\u001b[0m  0.1222\n",
      "      2  \u001b[36m1057822.5598\u001b[0m        \u001b[32m7.7272\u001b[0m  0.1181\n",
      "      3   \u001b[36m611498.6910\u001b[0m        \u001b[32m5.8672\u001b[0m  0.1075\n",
      "      4   \u001b[36m407162.0578\u001b[0m        \u001b[32m4.0167\u001b[0m  0.1126\n",
      "      5   \u001b[36m278071.4332\u001b[0m        \u001b[32m3.0261\u001b[0m  0.1089\n",
      "      6   \u001b[36m175911.2773\u001b[0m        \u001b[32m2.6075\u001b[0m  0.1201\n",
      "      7   \u001b[36m114100.9831\u001b[0m        \u001b[32m2.3598\u001b[0m  0.1283\n",
      "      8    \u001b[36m76587.2820\u001b[0m        \u001b[32m2.1824\u001b[0m  0.1710\n",
      "      9    \u001b[36m40834.3503\u001b[0m        \u001b[32m2.0315\u001b[0m  0.1230\n",
      "     10    \u001b[36m31674.6828\u001b[0m        \u001b[32m1.9279\u001b[0m  0.1109\n",
      "     11    \u001b[36m12743.9083\u001b[0m        \u001b[32m1.8525\u001b[0m  0.1100\n",
      "     12     \u001b[36m7083.8570\u001b[0m        \u001b[32m1.8092\u001b[0m  0.1099\n",
      "     13     \u001b[36m3340.0610\u001b[0m        \u001b[32m1.7697\u001b[0m  0.1146\n",
      "     14     \u001b[36m2793.4733\u001b[0m        \u001b[32m1.7344\u001b[0m  0.1120\n",
      "     15      \u001b[36m872.6655\u001b[0m        \u001b[32m1.6884\u001b[0m  0.1224\n",
      "     16      \u001b[36m426.9853\u001b[0m        \u001b[32m1.6664\u001b[0m  0.1072\n",
      "     17      \u001b[36m179.6260\u001b[0m        \u001b[32m1.6444\u001b[0m  0.1104\n",
      "     18       \u001b[36m57.6820\u001b[0m        \u001b[32m1.6019\u001b[0m  0.1126\n",
      "     19       \u001b[36m30.9536\u001b[0m        \u001b[32m1.5740\u001b[0m  0.1064\n",
      "     20       \u001b[36m20.1151\u001b[0m        \u001b[32m1.5613\u001b[0m  0.1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [04:06<00:04,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m285256.5536\u001b[0m       \u001b[32m31.8416\u001b[0m  0.1229\n",
      "      2   \u001b[36m180663.5659\u001b[0m        \u001b[32m9.6671\u001b[0m  0.1247\n",
      "      3    \u001b[36m66822.0625\u001b[0m        \u001b[32m3.3083\u001b[0m  0.1114\n",
      "      4    \u001b[36m23679.8166\u001b[0m        \u001b[32m1.6373\u001b[0m  0.1109\n",
      "      5     \u001b[36m9143.6655\u001b[0m        1.7679  0.1162\n",
      "      6     \u001b[36m2169.7490\u001b[0m        \u001b[32m1.5001\u001b[0m  0.1499\n",
      "      7      \u001b[36m270.7945\u001b[0m        \u001b[32m1.4542\u001b[0m  0.1621\n",
      "      8        \u001b[36m1.8223\u001b[0m        \u001b[32m1.3757\u001b[0m  0.1178\n",
      "      9       33.3992        \u001b[32m1.3158\u001b[0m  0.1194\n",
      "     10       16.1061        \u001b[32m1.2760\u001b[0m  0.1423\n",
      "     11        \u001b[36m1.2498\u001b[0m        \u001b[32m1.2418\u001b[0m  0.1385\n",
      "     12        \u001b[36m1.1017\u001b[0m        \u001b[32m1.2315\u001b[0m  0.1445\n",
      "     13        1.1531        \u001b[32m1.1976\u001b[0m  0.1354\n",
      "     14        \u001b[36m1.0658\u001b[0m        \u001b[32m1.1924\u001b[0m  0.1158\n",
      "     15        \u001b[36m1.0327\u001b[0m        \u001b[32m1.1778\u001b[0m  0.1178\n",
      "     16        \u001b[36m1.0217\u001b[0m        1.1799  0.1159\n",
      "     17        6.5780        \u001b[32m1.1613\u001b[0m  0.1027\n",
      "     18        3.0275        \u001b[32m1.1606\u001b[0m  0.1206\n",
      "     19        1.8486        \u001b[32m1.1586\u001b[0m  0.1055\n",
      "     20        1.3241        1.1598  0.1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [04:09<00:02,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m104375.2826\u001b[0m        \u001b[32m4.3735\u001b[0m  0.1233\n",
      "      2    \u001b[36m87385.9497\u001b[0m        \u001b[32m1.7148\u001b[0m  0.1233\n",
      "      3    \u001b[36m60973.2134\u001b[0m        \u001b[32m1.2808\u001b[0m  0.1119\n",
      "      4    \u001b[36m47769.4119\u001b[0m        \u001b[32m1.1295\u001b[0m  0.1941\n",
      "      5    \u001b[36m37996.8954\u001b[0m        \u001b[32m1.0531\u001b[0m  0.1360\n",
      "      6    \u001b[36m27220.5174\u001b[0m        \u001b[32m0.9914\u001b[0m  0.1236\n",
      "      7    \u001b[36m20729.9626\u001b[0m        \u001b[32m0.9760\u001b[0m  0.1229\n",
      "      8    \u001b[36m15826.7340\u001b[0m        \u001b[32m0.9599\u001b[0m  0.1153\n",
      "      9    \u001b[36m13099.4398\u001b[0m        0.9741  0.1193\n",
      "     10     \u001b[36m9615.8791\u001b[0m        0.9657  0.1256\n",
      "     11     \u001b[36m6829.9641\u001b[0m        0.9670  0.1277\n",
      "     12     \u001b[36m5046.9315\u001b[0m        0.9705  0.1120\n",
      "     13     \u001b[36m4607.8433\u001b[0m        0.9843  0.1642\n",
      "     14     \u001b[36m2916.5785\u001b[0m        0.9750  0.1259\n",
      "     15     \u001b[36m1928.3420\u001b[0m        0.9763  0.1173\n",
      "     16     \u001b[36m1616.5068\u001b[0m        0.9893  0.1116\n",
      "     17     \u001b[36m1001.3905\u001b[0m        0.9845  0.1142\n",
      "     18      \u001b[36m801.0990\u001b[0m        0.9865  0.1069\n",
      "     19      \u001b[36m541.2753\u001b[0m        0.9931  0.1144\n",
      "     20      \u001b[36m352.9087\u001b[0m        1.0019  0.1057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:12<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "df = powerkit.run_selected_condition('pytorch', rngs, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(f'{file_save_path}{exp_id}_pytorch_control_dynamic.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029710571722528556"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model_performance'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rng</th>\n",
       "      <th>model_performance</th>\n",
       "      <th>p_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.75</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rng  model_performance  p_vals\n",
       "count  100.00             100.00  100.00\n",
       "mean    49.50               0.03    0.51\n",
       "std     29.01               0.13    0.31\n",
       "min      0.00              -0.34    0.00\n",
       "25%     24.75              -0.03    0.24\n",
       "50%     49.50               0.02    0.51\n",
       "75%     74.25               0.10    0.81\n",
       "max     99.00               0.39    1.00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe df with significant figure of 2 \n",
    "df.describe().round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamic-marker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

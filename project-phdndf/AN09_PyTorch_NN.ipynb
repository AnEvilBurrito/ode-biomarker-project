{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch # type: ignore\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(torch.__version__)\n",
    "    # Setup device agnostic code\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0708, -0.0851,  0.0290,  ...,  0.0032, -0.0527,  0.0193],\n",
      "        [ 0.0232, -0.0486,  0.0378,  ..., -0.0408,  0.0732, -0.0149],\n",
      "        [ 0.0373,  0.0352, -0.0231,  ...,  0.0403, -0.0399, -0.0527],\n",
      "        ...,\n",
      "        [ 0.0759,  0.0617, -0.0757,  ..., -0.0038,  0.0693, -0.0414],\n",
      "        [-0.0157,  0.0224,  0.0283,  ...,  0.0580, -0.0439,  0.0638],\n",
      "        [ 0.0731, -0.0434,  0.0294,  ...,  0.0854,  0.0757, -0.0095]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0284,  0.0284, -0.0258, -0.0305,  0.0641, -0.0005,  0.0453,  0.0070,\n",
      "         0.0833, -0.0531,  0.0888, -0.0586,  0.0956, -0.0037, -0.0676, -0.0806,\n",
      "        -0.0609,  0.0648,  0.0021,  0.0681,  0.0767, -0.0044, -0.0067,  0.0731,\n",
      "         0.0454,  0.0395, -0.0641, -0.0912,  0.0140, -0.0568, -0.0939, -0.0051,\n",
      "         0.0756,  0.0050, -0.0717,  0.0632,  0.0177,  0.0138, -0.0406,  0.0170,\n",
      "        -0.0959, -0.0203, -0.0078,  0.0365, -0.0981, -0.0395,  0.0467, -0.0873,\n",
      "        -0.0342, -0.0776, -0.0355, -0.0841,  0.0061, -0.0282,  0.0018, -0.0472,\n",
      "        -0.0763,  0.0441,  0.0852,  0.0774,  0.0094, -0.0123,  0.0631, -0.0658,\n",
      "        -0.0384,  0.0006, -0.0887,  0.0152,  0.0934,  0.0272,  0.0419,  0.0009,\n",
      "        -0.0907, -0.0319, -0.0144, -0.0005,  0.0460,  0.0455, -0.0112,  0.0319,\n",
      "        -0.0009,  0.0643, -0.0656, -0.0890, -0.0704, -0.0590, -0.0295, -0.0071,\n",
      "        -0.0105, -0.0552,  0.0350,  0.0106, -0.0320, -0.0064, -0.0524, -0.0217,\n",
      "        -0.0645, -0.0522,  0.0976, -0.0039, -0.0869, -0.0851, -0.0652, -0.0698,\n",
      "         0.0653,  0.0457,  0.0802, -0.0095,  0.0579, -0.0125,  0.0063,  0.0386,\n",
      "         0.0497, -0.0058,  0.0897,  0.0348, -0.0947, -0.0038,  0.0013,  0.0470,\n",
      "         0.0084, -0.0504, -0.0748,  0.0535,  0.0177, -0.0971,  0.0726, -0.0070,\n",
      "        -0.0394, -0.0832,  0.0039, -0.0690, -0.0998,  0.0650,  0.0278,  0.0267,\n",
      "         0.0512, -0.0406,  0.0506, -0.0710,  0.0896, -0.0404,  0.0069, -0.0571,\n",
      "        -0.0271, -0.0411, -0.0832, -0.0431,  0.0977, -0.0766,  0.0167, -0.0643,\n",
      "        -0.0868, -0.0759,  0.0104,  0.0252, -0.0801, -0.0982,  0.0414, -0.0051,\n",
      "         0.0555,  0.0296, -0.0245, -0.0316,  0.0045, -0.0518,  0.0463,  0.0751,\n",
      "         0.0282,  0.0047, -0.0828, -0.0366, -0.0879,  0.0096,  0.0378, -0.0365,\n",
      "        -0.0599,  0.0669,  0.0383,  0.0807,  0.0102,  0.0479,  0.0413, -0.0261,\n",
      "         0.0133,  0.0100,  0.0145,  0.0266,  0.0228,  0.0326, -0.0780,  0.0930,\n",
      "         0.0932,  0.0865,  0.0549,  0.0771,  0.0433,  0.0300, -0.0436,  0.0841],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0098,  0.0603,  0.0274,  ...,  0.0313, -0.0629,  0.0301],\n",
      "        [-0.0565, -0.0422, -0.0081,  ..., -0.0318, -0.0574,  0.0583],\n",
      "        [ 0.0701,  0.0536, -0.0513,  ..., -0.0036,  0.0112, -0.0681],\n",
      "        ...,\n",
      "        [ 0.0375,  0.0088, -0.0568,  ...,  0.0168,  0.0314,  0.0253],\n",
      "        [-0.0630,  0.0016, -0.0097,  ...,  0.0146,  0.0198,  0.0534],\n",
      "        [-0.0331, -0.0421,  0.0513,  ..., -0.0404, -0.0050,  0.0576]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0356,  0.0365,  0.0318, -0.0482,  0.0087,  0.0496, -0.0403,  0.0545,\n",
      "        -0.0642, -0.0372], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0098,  0.0603,  0.0274,  ...,  0.0313, -0.0629,  0.0301],\n",
      "        [-0.0565, -0.0422, -0.0081,  ..., -0.0318, -0.0574,  0.0583],\n",
      "        [ 0.0701,  0.0536, -0.0513,  ..., -0.0036,  0.0112, -0.0681],\n",
      "        ...,\n",
      "        [ 0.0375,  0.0088, -0.0568,  ...,  0.0168,  0.0314,  0.0253],\n",
      "        [-0.0630,  0.0016, -0.0097,  ...,  0.0146,  0.0198,  0.0534],\n",
      "        [-0.0331, -0.0421,  0.0513,  ..., -0.0404, -0.0050,  0.0576]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0356,  0.0365,  0.0318, -0.0482,  0.0087,  0.0496, -0.0403,  0.0545,\n",
      "        -0.0642, -0.0372], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn  # type: ignore\n",
    "import torch.nn.functional as F # type: ignore\n",
    "\n",
    "\n",
    "class MySmallModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MySmallModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.network1 = MySmallModel()\n",
    "        self.network2 = MySmallModel()\n",
    "        self.network3 = MySmallModel()\n",
    "\n",
    "        self.fc1 = nn.Linear(3, 2)\n",
    "        self.fc_out = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        x1 = F.relu(self.network1(x1))\n",
    "        x2 = F.relu(self.network2(x2))\n",
    "        x3 = F.relu(self.network3(x3))\n",
    "\n",
    "        x = torch.cat((x1, x2, x3), 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "N = 10\n",
    "x1, x2, x3 = torch.randn(N, 5), torch.randn(N, 5), torch.randn(N, 5)\n",
    "\n",
    "output = model(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Model Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterisation of Feature Size and Group Feature Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2135],\n",
      "        [-0.1285],\n",
      "        [-0.2141],\n",
      "        [-0.1349],\n",
      "        [-0.0851],\n",
      "        [-0.0523],\n",
      "        [-0.2534],\n",
      "        [-0.2638],\n",
      "        [-0.0889],\n",
      "        [-0.2055]], grad_fn=<AddmmBackward0>)\n",
      "TorchModel(\n",
      "  (group_layers): ModuleList(\n",
      "    (0-25): 26 x GroupLayer(\n",
      "      (fc1): Linear(in_features=10, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=26, out_features=13, bias=True)\n",
      "  (fc_out): Linear(in_features=13, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GroupLayer(nn.Module):\n",
    "    def __init__(self, group_feat_size: int):\n",
    "        super(GroupLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(group_feat_size, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x \n",
    "\n",
    "class TorchModel(nn.Module):\n",
    "    def __init__(self, group_feat_size: int, total_feat_size: int):\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.group_feat_size = group_feat_size\n",
    "        self.total_feat_size = total_feat_size\n",
    "        num_groups = self.total_feat_size // self.group_feat_size\n",
    "        # if num_groups not an integer, throw error\n",
    "        if num_groups != self.total_feat_size / self.group_feat_size:\n",
    "            raise ValueError(\"Total feature size must be divisible by group feature size\")\n",
    "        \n",
    "        self.num_groups = num_groups\n",
    "        self.group_layers = nn.ModuleList()\n",
    "        i = 0 \n",
    "        while i < num_groups:\n",
    "            self.group_layers.append(GroupLayer(group_feat_size))\n",
    "            i += 1\n",
    "            \n",
    "        self.layer_2_size = int(num_groups / 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_groups, self.layer_2_size)\n",
    "        self.fc_out = nn.Linear(self.layer_2_size, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # print(input_data.shape)\n",
    "        xs = []\n",
    "        i = 0\n",
    "        while i < self.total_feat_size:\n",
    "            xs.append(input_data[:, i:i+self.group_feat_size])\n",
    "            i += group_feat_size\n",
    "        \n",
    "        outs = []\n",
    "        for i,x in enumerate(xs):\n",
    "            # print(i+1, x.shape)\n",
    "            outs.append(self.group_layers[i](x))\n",
    "\n",
    "        x = torch.cat(outs, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "group_feat_size = 10\n",
    "total_feat_size = 260\n",
    "\n",
    "model = TorchModel(group_feat_size, total_feat_size)\n",
    "N = 10\n",
    "x = torch.randn(N, total_feat_size)\n",
    "output = model(x)\n",
    "print(output)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimisation Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn to generate some regression data\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=10000, n_features=260, noise=0.1)\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train_dl = DataLoader(list(zip(X_train, y_train)), batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(list(zip(X_test, y_test)), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "model = TorchModel(group_feat_size, total_feat_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "\n",
    "# def train(model, train_dl, optimizer, criterion, epochs=10):\n",
    "#     running_loss = 0.0\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f\"### Epoch {epoch}\")\n",
    "#         for i, (x, y) in enumerate(train_dl):\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(x)\n",
    "#             loss = criterion(output, y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item()\n",
    "#             print(f\"Batch {i} loss: {loss.item()}\")\n",
    "            \n",
    "#     return running_loss / len(train_dl)\n",
    "                            \n",
    "\n",
    "# train(model, train_dl, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the output against the target\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# plt.scatter(y_test, output.detach().numpy())\n",
    "# plt.xlabel('True Value')\n",
    "# plt.ylabel('Predicted Value')\n",
    "# plt.title('Predicted vs True Value')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "from torch import nn  # type: ignore\n",
    "import torch.nn.functional as F  # type: ignore\n",
    "\n",
    "class GroupLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, group_feat_size: int):\n",
    "        super(GroupLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(group_feat_size, 1).double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class TorchModel(nn.Module):\n",
    "\n",
    "    def __init__(self, group_feat_size: int, total_feat_size: int):\n",
    "\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.group_feat_size = group_feat_size\n",
    "        self.total_feat_size = total_feat_size\n",
    "\n",
    "        num_groups = self.total_feat_size // self.group_feat_size\n",
    "\n",
    "        # if num_groups not an integer, throw error\n",
    "        if num_groups != self.total_feat_size / self.group_feat_size:\n",
    "            raise ValueError(\"Total feature size must be divisible by group feature size\")\n",
    "\n",
    "        self.num_groups = num_groups\n",
    "        self.group_layers = nn.ModuleList()\n",
    "        i = 0\n",
    "        while i < num_groups:\n",
    "            self.group_layers.append(GroupLayer(group_feat_size))\n",
    "            i += 1\n",
    "        self.layer_2_size = int(num_groups / 2)\n",
    "        self.fc1 = nn.Linear(num_groups, self.layer_2_size).double()\n",
    "        self.fc_out = nn.Linear(self.layer_2_size, 1).double()\n",
    "\n",
    "\n",
    "    def forward(self, input_data):\n",
    "\n",
    "        # print(input_data.shape)\n",
    "\n",
    "        xs = []\n",
    "        i = 0\n",
    "        while i < self.total_feat_size:\n",
    "            xs.append(input_data[:, i:i+self.group_feat_size])\n",
    "            i += group_feat_size\n",
    "\n",
    "\n",
    "        outs = []\n",
    "        for i, x in enumerate(xs):\n",
    "            # print(i+1, x.shape)\n",
    "            outs.append(self.group_layers[i](x))\n",
    "\n",
    "\n",
    "        x = torch.cat(outs, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "group_feat_size = 10\n",
    "total_feat_size = 260\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    TorchModel,\n",
    "    module__group_feat_size=group_feat_size,\n",
    "    module__total_feat_size=total_feat_size,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=torch.nn.MSELoss,\n",
    "    max_epochs=20,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=2000, n_features=260, noise=0.01)\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m36538.5951\u001b[0m    \u001b[32m30354.4184\u001b[0m  0.2810\n",
      "      2    \u001b[36m36533.6516\u001b[0m    \u001b[32m30353.1917\u001b[0m  0.2420\n",
      "      3    \u001b[36m36528.3852\u001b[0m    \u001b[32m30350.3127\u001b[0m  0.2340\n",
      "      4    \u001b[36m36519.5394\u001b[0m    \u001b[32m30346.8352\u001b[0m  0.2270\n",
      "      5    \u001b[36m36506.7564\u001b[0m    \u001b[32m30339.8095\u001b[0m  0.2300\n",
      "      6    \u001b[36m36483.1964\u001b[0m    \u001b[32m30326.1093\u001b[0m  0.2260\n",
      "      7    \u001b[36m36442.3965\u001b[0m    \u001b[32m30300.9058\u001b[0m  0.2287\n",
      "      8    \u001b[36m36373.7734\u001b[0m    \u001b[32m30250.7520\u001b[0m  0.2210\n",
      "      9    \u001b[36m36253.8789\u001b[0m    \u001b[32m30159.9985\u001b[0m  0.2340\n",
      "     10    \u001b[36m36048.8307\u001b[0m    \u001b[32m30005.9318\u001b[0m  0.2310\n",
      "     11    \u001b[36m35733.6286\u001b[0m    \u001b[32m29758.5801\u001b[0m  0.2420\n",
      "     12    \u001b[36m35277.7611\u001b[0m    \u001b[32m29411.6200\u001b[0m  0.2330\n",
      "     13    \u001b[36m34664.7881\u001b[0m    \u001b[32m28955.0099\u001b[0m  0.2320\n",
      "     14    \u001b[36m33879.7537\u001b[0m    \u001b[32m28352.6917\u001b[0m  0.2270\n",
      "     15    \u001b[36m32897.6194\u001b[0m    \u001b[32m27620.7411\u001b[0m  0.2228\n",
      "     16    \u001b[36m31736.0332\u001b[0m    \u001b[32m26750.7767\u001b[0m  0.2350\n",
      "     17    \u001b[36m30372.7937\u001b[0m    \u001b[32m25785.9721\u001b[0m  0.2270\n",
      "     18    \u001b[36m28853.6752\u001b[0m    \u001b[32m24630.6073\u001b[0m  0.2240\n",
      "     19    \u001b[36m27153.0052\u001b[0m    \u001b[32m23415.5359\u001b[0m  0.2270\n",
      "     20    \u001b[36m25371.6254\u001b[0m    \u001b[32m22117.3457\u001b[0m  0.2370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=TorchModel(\n",
       "    (group_layers): ModuleList(\n",
       "      (0-25): 26 x GroupLayer(\n",
       "        (fc1): Linear(in_features=10, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (fc1): Linear(in_features=26, out_features=13, bias=True)\n",
       "    (fc_out): Linear(in_features=13, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make prediction \n",
    "\n",
    "y_pred = net.predict(X_test)\n",
    "\n",
    "# plot the output against the target\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.title('Predicted vs True Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.7669682676823475\n"
     ]
    }
   ],
   "source": [
    "# test pearson correlation \n",
    "\n",
    "# calculate pearson correlation\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr, _ = pearsonr(y_test.flatten(), y_pred.flatten())\n",
    "\n",
    "print(f'Pearsons correlation: {corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n",
    "# Bring in CCLE data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader\n",
    "from DataLink import DataLink\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "data_link = DataLink(path_loader, 'data_codes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in original ccle data\n",
    "loading_code = 'generic-gdsc-1-FGFR_0939-LN_IC50-fgfr4_ccle_dynamic_features_v2-true-Unnamed: 0'\n",
    "# generic-gdsc-{number}-{drug_name}-{target_label}-{dataset_name}-{replace_index}-{row_index}\n",
    "feature_data, label_data = data_link.get_data_using_code(loading_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pIGFR_auc</th>\n",
       "      <th>pIGFR_median</th>\n",
       "      <th>pIGFR_tfc</th>\n",
       "      <th>pIGFR_tmax</th>\n",
       "      <th>pIGFR_max</th>\n",
       "      <th>pIGFR_tmin</th>\n",
       "      <th>pIGFR_min</th>\n",
       "      <th>pIGFR_ttsv</th>\n",
       "      <th>pIGFR_tsv</th>\n",
       "      <th>pIGFR_init</th>\n",
       "      <th>...</th>\n",
       "      <th>amTORC2_auc</th>\n",
       "      <th>amTORC2_median</th>\n",
       "      <th>amTORC2_tfc</th>\n",
       "      <th>amTORC2_tmax</th>\n",
       "      <th>amTORC2_max</th>\n",
       "      <th>amTORC2_tmin</th>\n",
       "      <th>amTORC2_min</th>\n",
       "      <th>amTORC2_ttsv</th>\n",
       "      <th>amTORC2_tsv</th>\n",
       "      <th>amTORC2_init</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SIDM01085</th>\n",
       "      <td>0.019410</td>\n",
       "      <td>0.021032</td>\n",
       "      <td>4.682872</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.032885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>5.486629</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00949</th>\n",
       "      <td>0.077292</td>\n",
       "      <td>0.084704</td>\n",
       "      <td>9.089875</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.140803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218305</td>\n",
       "      <td>0.226915</td>\n",
       "      <td>0.364546</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.264206</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.193622</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.193622</td>\n",
       "      <td>0.193622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00494</th>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>3.560627</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.015136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>0.020458</td>\n",
       "      <td>0.403167</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.024825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>0.017692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00377</th>\n",
       "      <td>0.036978</td>\n",
       "      <td>0.039602</td>\n",
       "      <td>5.138051</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.065341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>1.189183</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00988</th>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.030932</td>\n",
       "      <td>8.449997</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.039991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.465354</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.008079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00697</th>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>9.576674</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.024837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.539425</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM01188</th>\n",
       "      <td>0.032034</td>\n",
       "      <td>0.036092</td>\n",
       "      <td>11.164995</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140425</td>\n",
       "      <td>0.146074</td>\n",
       "      <td>0.332654</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.167943</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.126022</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.126022</td>\n",
       "      <td>0.126022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00999</th>\n",
       "      <td>0.015288</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>5.579325</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>4.879114</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00149</th>\n",
       "      <td>0.078582</td>\n",
       "      <td>0.089001</td>\n",
       "      <td>14.430451</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.135102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142652</td>\n",
       "      <td>0.147998</td>\n",
       "      <td>0.297572</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.170342</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.131277</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.131277</td>\n",
       "      <td>0.131277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00848</th>\n",
       "      <td>0.031927</td>\n",
       "      <td>0.037403</td>\n",
       "      <td>11.575419</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.053087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463970</td>\n",
       "      <td>0.483035</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.544116</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.424736</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.424736</td>\n",
       "      <td>0.424736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows  260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pIGFR_auc  pIGFR_median  pIGFR_tfc  pIGFR_tmax  pIGFR_max  \\\n",
       "SIDM01085   0.019410      0.021032   4.682872        0.96   0.032885   \n",
       "SIDM00949   0.077292      0.084704   9.089875        0.96   0.140803   \n",
       "SIDM00494   0.010086      0.011210   3.560627        0.96   0.015136   \n",
       "SIDM00377   0.036978      0.039602   5.138051        0.96   0.065341   \n",
       "SIDM00988   0.027368      0.030932   8.449997        0.96   0.039991   \n",
       "...              ...           ...        ...         ...        ...   \n",
       "SIDM00697   0.013521      0.014763   9.576674        0.96   0.024837   \n",
       "SIDM01188   0.032034      0.036092  11.164995        0.96   0.056863   \n",
       "SIDM00999   0.015288      0.016662   5.579325        0.96   0.026040   \n",
       "SIDM00149   0.078582      0.089001  14.430451        0.96   0.135102   \n",
       "SIDM00848   0.031927      0.037403  11.575419        0.96   0.053087   \n",
       "\n",
       "           pIGFR_tmin  pIGFR_min  pIGFR_ttsv  pIGFR_tsv  pIGFR_init  ...  \\\n",
       "SIDM01085         0.0   0.005787        0.04   0.005787    0.005787  ...   \n",
       "SIDM00949         0.0   0.013955        0.04   0.013955    0.013955  ...   \n",
       "SIDM00494         0.0   0.003319        0.04   0.003319    0.003319  ...   \n",
       "SIDM00377         0.0   0.010645        0.04   0.010645    0.010645  ...   \n",
       "SIDM00988         0.0   0.004232        0.04   0.004232    0.004232  ...   \n",
       "...               ...        ...         ...        ...         ...  ...   \n",
       "SIDM00697         0.0   0.002348        0.04   0.002348    0.002348  ...   \n",
       "SIDM01188         0.0   0.004674        0.04   0.004674    0.004674  ...   \n",
       "SIDM00999         0.0   0.003958        0.04   0.003958    0.003958  ...   \n",
       "SIDM00149         0.0   0.008756        0.04   0.008756    0.008756  ...   \n",
       "SIDM00848         0.0   0.004222        0.04   0.004222    0.004222  ...   \n",
       "\n",
       "           amTORC2_auc  amTORC2_median  amTORC2_tfc  amTORC2_tmax  \\\n",
       "SIDM01085     0.001717        0.001599     5.486629          0.96   \n",
       "SIDM00949     0.218305        0.226915     0.364546          0.96   \n",
       "SIDM00494     0.019850        0.020458     0.403167          0.96   \n",
       "SIDM00377     0.000361        0.000332     1.189183          0.96   \n",
       "SIDM00988     0.008990        0.009058     0.465354          0.96   \n",
       "...                ...             ...          ...           ...   \n",
       "SIDM00697     0.000116        0.000116     0.539425          0.96   \n",
       "SIDM01188     0.140425        0.146074     0.332654          0.96   \n",
       "SIDM00999     0.002991        0.002788     4.879114          0.96   \n",
       "SIDM00149     0.142652        0.147998     0.297572          0.96   \n",
       "SIDM00848     0.463970        0.483035     0.281069          0.96   \n",
       "\n",
       "           amTORC2_max  amTORC2_tmin  amTORC2_min  amTORC2_ttsv  amTORC2_tsv  \\\n",
       "SIDM01085     0.003834          0.00     0.000591          0.04     0.000591   \n",
       "SIDM00949     0.264206          0.00     0.193622          0.04     0.193622   \n",
       "SIDM00494     0.024825          0.00     0.017692          0.04     0.017692   \n",
       "SIDM00377     0.000639          0.00     0.000292          0.04     0.000292   \n",
       "SIDM00988     0.011839          0.08     0.008078          0.04     0.008079   \n",
       "...                ...           ...          ...           ...          ...   \n",
       "SIDM00697     0.000160          0.00     0.000104          0.04     0.000104   \n",
       "SIDM01188     0.167943          0.00     0.126022          0.04     0.126022   \n",
       "SIDM00999     0.006578          0.00     0.001119          0.04     0.001119   \n",
       "SIDM00149     0.170342          0.00     0.131277          0.04     0.131277   \n",
       "SIDM00848     0.544116          0.00     0.424736          0.04     0.424736   \n",
       "\n",
       "           amTORC2_init  \n",
       "SIDM01085      0.000591  \n",
       "SIDM00949      0.193622  \n",
       "SIDM00494      0.017692  \n",
       "SIDM00377      0.000292  \n",
       "SIDM00988      0.008079  \n",
       "...                 ...  \n",
       "SIDM00697      0.000104  \n",
       "SIDM01188      0.126022  \n",
       "SIDM00999      0.001119  \n",
       "SIDM00149      0.131277  \n",
       "SIDM00848      0.424736  \n",
       "\n",
       "[665 rows x 260 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "feature_data_numpy = feature_data.to_numpy()\n",
    "label_data_numpy = label_data.to_numpy()\n",
    "label_data_numpy = label_data_numpy.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 260)\n",
      "(665, 1)\n"
     ]
    }
   ],
   "source": [
    "print(feature_data_numpy.shape)\n",
    "print(label_data_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on all data test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_feat_size = 10\n",
    "total_feat_size = 260\n",
    "torch.manual_seed(0)\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    TorchModel,\n",
    "    module__group_feat_size=group_feat_size,\n",
    "    module__total_feat_size=total_feat_size,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=torch.nn.MSELoss,\n",
    "    max_epochs=100,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m33053.9213\u001b[0m       \u001b[32m19.8250\u001b[0m  0.1010\n",
      "      2    \u001b[36m16931.7875\u001b[0m        \u001b[32m9.9286\u001b[0m  0.1000\n",
      "      3     \u001b[36m8757.3404\u001b[0m        \u001b[32m5.8922\u001b[0m  0.0980\n",
      "      4     \u001b[36m5343.7950\u001b[0m        \u001b[32m4.2848\u001b[0m  0.0980\n",
      "      5      \u001b[36m685.8830\u001b[0m        \u001b[32m3.6916\u001b[0m  0.1010\n",
      "      6      \u001b[36m269.8084\u001b[0m        \u001b[32m3.2345\u001b[0m  0.1100\n",
      "      7       \u001b[36m24.1567\u001b[0m        \u001b[32m3.0239\u001b[0m  0.1010\n",
      "      8        \u001b[36m2.6646\u001b[0m        \u001b[32m2.9014\u001b[0m  0.0960\n",
      "      9        \u001b[36m2.0168\u001b[0m        \u001b[32m2.7221\u001b[0m  0.1140\n",
      "     10        \u001b[36m1.8903\u001b[0m        \u001b[32m2.6328\u001b[0m  0.1020\n",
      "     11        \u001b[36m1.7704\u001b[0m        \u001b[32m2.4555\u001b[0m  0.0990\n",
      "     12        \u001b[36m1.7113\u001b[0m        \u001b[32m2.3370\u001b[0m  0.1000\n",
      "     13        \u001b[36m1.5975\u001b[0m        \u001b[32m2.2330\u001b[0m  0.0990\n",
      "     14        \u001b[36m1.5232\u001b[0m        \u001b[32m2.1889\u001b[0m  0.1090\n",
      "     15        \u001b[36m1.4965\u001b[0m        \u001b[32m2.0825\u001b[0m  0.1030\n",
      "     16        \u001b[36m1.4336\u001b[0m        \u001b[32m2.0098\u001b[0m  0.0980\n",
      "     17        \u001b[36m1.3903\u001b[0m        \u001b[32m2.0085\u001b[0m  0.1050\n",
      "     18        1.4326        \u001b[32m1.9168\u001b[0m  0.0980\n",
      "     19        1.4419        1.9309  0.0970\n",
      "     20        \u001b[36m1.3153\u001b[0m        \u001b[32m1.8412\u001b[0m  0.1010\n",
      "     21        \u001b[36m1.2874\u001b[0m        \u001b[32m1.8407\u001b[0m  0.0990\n",
      "     22        \u001b[36m1.2645\u001b[0m        \u001b[32m1.7923\u001b[0m  0.1400\n",
      "     23        \u001b[36m1.2476\u001b[0m        \u001b[32m1.7500\u001b[0m  0.1020\n",
      "     24        \u001b[36m1.2284\u001b[0m        \u001b[32m1.7234\u001b[0m  0.1000\n",
      "     25        1.2312        \u001b[32m1.6913\u001b[0m  0.1000\n",
      "     26        \u001b[36m1.1901\u001b[0m        \u001b[32m1.6828\u001b[0m  0.1000\n",
      "     27        \u001b[36m1.1713\u001b[0m        \u001b[32m1.6663\u001b[0m  0.0997\n",
      "     28        1.1721        \u001b[32m1.6426\u001b[0m  0.1000\n",
      "     29        \u001b[36m1.1477\u001b[0m        \u001b[32m1.6293\u001b[0m  0.0980\n",
      "     30        \u001b[36m1.1440\u001b[0m        \u001b[32m1.5870\u001b[0m  0.0980\n",
      "     31        \u001b[36m1.1008\u001b[0m        \u001b[32m1.5781\u001b[0m  0.0980\n",
      "     32        \u001b[36m1.0989\u001b[0m        \u001b[32m1.5682\u001b[0m  0.0980\n",
      "     33        \u001b[36m1.0874\u001b[0m        \u001b[32m1.5472\u001b[0m  0.0980\n",
      "     34        \u001b[36m1.0772\u001b[0m        \u001b[32m1.5346\u001b[0m  0.1130\n",
      "     35        \u001b[36m1.0644\u001b[0m        \u001b[32m1.5210\u001b[0m  0.1060\n",
      "     36        \u001b[36m1.0497\u001b[0m        \u001b[32m1.5069\u001b[0m  0.0990\n",
      "     37        1.0545        \u001b[32m1.4997\u001b[0m  0.0970\n",
      "     38        1.0593        \u001b[32m1.4841\u001b[0m  0.0980\n",
      "     39        \u001b[36m1.0259\u001b[0m        1.4907  0.0980\n",
      "     40        \u001b[36m1.0214\u001b[0m        \u001b[32m1.4644\u001b[0m  0.0990\n",
      "     41        \u001b[36m1.0183\u001b[0m        \u001b[32m1.4487\u001b[0m  0.0980\n",
      "     42        \u001b[36m1.0138\u001b[0m        1.5026  0.0980\n",
      "     43        1.0493        \u001b[32m1.4363\u001b[0m  0.1000\n",
      "     44        \u001b[36m0.9912\u001b[0m        \u001b[32m1.4228\u001b[0m  0.0980\n",
      "     45        1.0032        \u001b[32m1.4201\u001b[0m  0.0980\n",
      "     46        \u001b[36m0.9894\u001b[0m        \u001b[32m1.4162\u001b[0m  0.0980\n",
      "     47        0.9919        \u001b[32m1.4113\u001b[0m  0.0980\n",
      "     48        \u001b[36m0.9714\u001b[0m        \u001b[32m1.4106\u001b[0m  0.1010\n",
      "     49        \u001b[36m0.9643\u001b[0m        \u001b[32m1.3989\u001b[0m  0.0980\n",
      "     50        \u001b[36m0.9572\u001b[0m        \u001b[32m1.3981\u001b[0m  0.0960\n",
      "     51        0.9620        \u001b[32m1.3962\u001b[0m  0.0960\n",
      "     52        \u001b[36m0.9509\u001b[0m        \u001b[32m1.3853\u001b[0m  0.0980\n",
      "     53        0.9562        1.4149  0.0990\n",
      "     54        0.9679        1.3887  0.0980\n",
      "     55        \u001b[36m0.9445\u001b[0m        \u001b[32m1.3720\u001b[0m  0.1090\n",
      "     56        \u001b[36m0.9428\u001b[0m        1.3757  0.1000\n",
      "     57        0.9449        1.3819  0.0980\n",
      "     58        \u001b[36m0.9404\u001b[0m        \u001b[32m1.3586\u001b[0m  0.0990\n",
      "     59        \u001b[36m0.9239\u001b[0m        1.3695  0.0990\n",
      "     60        \u001b[36m0.9237\u001b[0m        \u001b[32m1.3549\u001b[0m  0.0980\n",
      "     61        \u001b[36m0.9226\u001b[0m        1.3658  0.0990\n",
      "     62        \u001b[36m0.9162\u001b[0m        1.3583  0.0990\n",
      "     63        0.9165        \u001b[32m1.3516\u001b[0m  0.0990\n",
      "     64        0.9291        1.3719  0.0990\n",
      "     65        0.9375        \u001b[32m1.3515\u001b[0m  0.0990\n",
      "     66        0.9184        \u001b[32m1.3510\u001b[0m  0.0980\n",
      "     67        0.9204        \u001b[32m1.3481\u001b[0m  0.0992\n",
      "     68        \u001b[36m0.9041\u001b[0m        1.3530  0.1100\n",
      "     69        0.9090        \u001b[32m1.3331\u001b[0m  0.0980\n",
      "     70        0.9057        \u001b[32m1.3257\u001b[0m  0.0980\n",
      "     71        \u001b[36m0.8998\u001b[0m        1.3391  0.0990\n",
      "     72        0.9036        \u001b[32m1.3253\u001b[0m  0.0980\n",
      "     73        0.9221        \u001b[32m1.3243\u001b[0m  0.0980\n",
      "     74        0.9076        \u001b[32m1.3233\u001b[0m  0.0980\n",
      "     75        0.9076        \u001b[32m1.3176\u001b[0m  0.1020\n",
      "     76        \u001b[36m0.8939\u001b[0m        \u001b[32m1.3157\u001b[0m  0.1050\n",
      "     77        0.8999        1.3160  0.0980\n",
      "     78        0.9100        \u001b[32m1.3046\u001b[0m  0.0980\n",
      "     79        \u001b[36m0.8866\u001b[0m        \u001b[32m1.3028\u001b[0m  0.0980\n",
      "     80        0.8893        \u001b[32m1.3019\u001b[0m  0.0970\n",
      "     81        0.8932        1.3042  0.1000\n",
      "     82        0.8916        1.3368  0.0980\n",
      "     83        0.9021        \u001b[32m1.2965\u001b[0m  0.1000\n",
      "     84        \u001b[36m0.8834\u001b[0m        \u001b[32m1.2963\u001b[0m  0.1010\n",
      "     85        \u001b[36m0.8793\u001b[0m        1.3062  0.0990\n",
      "     86        0.8826        \u001b[32m1.2905\u001b[0m  0.0990\n",
      "     87        0.8848        \u001b[32m1.2902\u001b[0m  0.0980\n",
      "     88        0.8858        1.2928  0.1020\n",
      "     89        \u001b[36m0.8729\u001b[0m        1.2966  0.0990\n",
      "     90        0.8824        \u001b[32m1.2847\u001b[0m  0.1000\n",
      "     91        0.8802        \u001b[32m1.2843\u001b[0m  0.0980\n",
      "     92        0.8794        1.2885  0.1010\n",
      "     93        \u001b[36m0.8726\u001b[0m        \u001b[32m1.2797\u001b[0m  0.0990\n",
      "     94        0.8808        1.3130  0.1000\n",
      "     95        0.8796        1.2909  0.0980\n",
      "     96        0.8776        1.2999  0.1040\n",
      "     97        0.9148        1.2827  0.1370\n",
      "     98        0.9471        1.2920  0.0980\n",
      "     99        0.9979        \u001b[32m1.2735\u001b[0m  0.0980\n",
      "    100        1.1239        1.2902  0.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=TorchModel(\n",
       "    (group_layers): ModuleList(\n",
       "      (0-25): 26 x GroupLayer(\n",
       "        (fc1): Linear(in_features=10, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (fc1): Linear(in_features=26, out_features=13, bias=True)\n",
       "    (fc_out): Linear(in_features=13, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(feature_data_numpy, label_data_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make prediction \n",
    "\n",
    "y_pred = net.predict(feature_data_numpy)\n",
    "\n",
    "# plot the output against the target\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(label_data_numpy, y_pred)\n",
    "plt.xlabel('True Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.title('Predicted vs True Value')\n",
    "# plt.xlim(-2, 4)\n",
    "# plt.ylim(0, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.14310619537858338\n"
     ]
    }
   ],
   "source": [
    "# calculate pearson correlation\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr, _ = pearsonr(label_data_numpy.flatten(), y_pred.flatten())\n",
    "\n",
    "print(f'Pearsons correlation: {corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with Powerkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "from toolkit import *   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerkit = Powerkit(feature_data, label_data)\n",
    "rngs = list(range(10))\n",
    "\n",
    "def pipeline_func(X_train, y_train, rng, **kwargs):\n",
    "    group_feat_size = 10\n",
    "    total_feat_size = 260\n",
    "\n",
    "    net = NeuralNetRegressor(\n",
    "        TorchModel,\n",
    "        module__group_feat_size=group_feat_size,\n",
    "        module__total_feat_size=total_feat_size,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        criterion=torch.nn.MSELoss,\n",
    "        max_epochs=20,\n",
    "        lr=0.001,\n",
    "        batch_size=32,\n",
    "        iterator_train__shuffle=True\n",
    "    )\n",
    "    \n",
    "    x_train_numpy = X_train.to_numpy()\n",
    "    y_train_numpy = y_train.to_numpy()\n",
    "    y_train_numpy = y_train_numpy.reshape(-1, 1)\n",
    "    net.fit(x_train_numpy, y_train_numpy)\n",
    "    return {'model': net}\n",
    "\n",
    "\n",
    "def eval_func(X_test, y_test, pipeline_components=None, **kwargs):\n",
    "    \n",
    "    # preprocess x and y \n",
    "    x_test_numpy = X_test.to_numpy()\n",
    "    y_test_numpy = y_test.to_numpy()\n",
    "    y_test_numpy = y_test_numpy.reshape(-1, 1)\n",
    "    \n",
    "    net = pipeline_components['model']\n",
    "    y_pred = net.predict(x_test_numpy)\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test_numpy.flatten(), y_pred.flatten())\n",
    "    return {'model_performance': corr, 'p_vals': p_vals, 'feature_importance': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerkit.add_condition('pytorch', False, pipeline_func, {}, eval_func, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.3686\u001b[0m        \u001b[32m2.2308\u001b[0m  0.0910\n",
      "      2        \u001b[36m1.5989\u001b[0m        \u001b[32m1.7191\u001b[0m  0.0900\n",
      "      3        \u001b[36m1.4232\u001b[0m        \u001b[32m1.5617\u001b[0m  0.0910\n",
      "      4        \u001b[36m1.3473\u001b[0m        \u001b[32m1.4113\u001b[0m  0.1030\n",
      "      5        \u001b[36m1.3119\u001b[0m        1.4172  0.0880\n",
      "      6        \u001b[36m1.2437\u001b[0m        \u001b[32m1.2961\u001b[0m  0.0860\n",
      "      7        \u001b[36m1.2114\u001b[0m        1.3042  0.0870\n",
      "      8        \u001b[36m1.2028\u001b[0m        1.2970  0.0860\n",
      "      9        \u001b[36m1.1733\u001b[0m        \u001b[32m1.2545\u001b[0m  0.0860\n",
      "     10        \u001b[36m1.1470\u001b[0m        \u001b[32m1.2088\u001b[0m  0.0850\n",
      "     11        \u001b[36m1.1240\u001b[0m        \u001b[32m1.1575\u001b[0m  0.0850\n",
      "     12        \u001b[36m1.1193\u001b[0m        1.1860  0.0860\n",
      "     13        \u001b[36m1.0905\u001b[0m        1.1783  0.0860\n",
      "     14        \u001b[36m1.0845\u001b[0m        1.2427  0.0850\n",
      "     15        \u001b[36m1.0617\u001b[0m        \u001b[32m1.1540\u001b[0m  0.0900\n",
      "     16        1.0637        1.1673  0.0900\n",
      "     17        \u001b[36m1.0508\u001b[0m        \u001b[32m1.1278\u001b[0m  0.0850\n",
      "     18        \u001b[36m1.0319\u001b[0m        \u001b[32m1.1048\u001b[0m  0.0930\n",
      "     19        1.0383        \u001b[32m1.0852\u001b[0m  0.1030\n",
      "     20        \u001b[36m1.0312\u001b[0m        1.1162  0.0870\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.0141\u001b[0m    \u001b[32m18537.4686\u001b[0m  0.0860\n",
      "      2        \u001b[36m1.1756\u001b[0m    27752.3260  0.0850\n",
      "      3        \u001b[36m1.0465\u001b[0m    38360.1385  0.0861\n",
      "      4        \u001b[36m0.9980\u001b[0m    52910.8635  0.0910\n",
      "      5        \u001b[36m0.9713\u001b[0m    59423.8319  0.0870\n",
      "      6        \u001b[36m0.9330\u001b[0m    69731.3569  0.0860\n",
      "      7        \u001b[36m0.9157\u001b[0m    80187.2458  0.0890\n",
      "      8        \u001b[36m0.9033\u001b[0m    97719.0642  0.0861\n",
      "      9        \u001b[36m0.8986\u001b[0m   108407.3083  0.0900\n",
      "     10        \u001b[36m0.8925\u001b[0m   121423.8940  0.0870\n",
      "     11        \u001b[36m0.8910\u001b[0m   119747.1013  0.0860\n",
      "     12        \u001b[36m0.8898\u001b[0m   152225.1545  0.0850\n",
      "     13        \u001b[36m0.8587\u001b[0m   141509.4843  0.0850\n",
      "     14        0.8637   179619.8622  0.0850\n",
      "     15        0.8696   169970.6137  0.0850\n",
      "     16        0.8659   187406.2025  0.0860\n",
      "     17        \u001b[36m0.8560\u001b[0m   203734.0999  0.0874\n",
      "     18        \u001b[36m0.8523\u001b[0m   195110.3326  0.0850\n",
      "     19        \u001b[36m0.8488\u001b[0m   217992.8153  0.0870\n",
      "     20        \u001b[36m0.8476\u001b[0m   208774.4219  0.0860\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m481074.6551\u001b[0m        \u001b[32m2.4627\u001b[0m  0.0900\n",
      "      2   \u001b[36m264896.1295\u001b[0m        \u001b[32m1.6142\u001b[0m  0.0976\n",
      "      3   \u001b[36m237969.5449\u001b[0m        2.1124  0.0890\n",
      "      4    \u001b[36m84515.4263\u001b[0m        1.7591  0.0860\n",
      "      5    \u001b[36m45766.9928\u001b[0m        1.6227  0.0850\n",
      "      6    \u001b[36m33541.4781\u001b[0m        2.1668  0.0850\n",
      "      7     \u001b[36m9198.2262\u001b[0m        1.9204  0.0850\n",
      "      8     \u001b[36m4521.4696\u001b[0m        1.8837  0.0860\n",
      "      9     \u001b[36m3132.6572\u001b[0m        2.0202  0.0840\n",
      "     10      \u001b[36m769.9030\u001b[0m        1.9561  0.0860\n",
      "     11      \u001b[36m175.5136\u001b[0m        1.8716  0.0920\n",
      "     12       \u001b[36m68.4363\u001b[0m        1.8107  0.0910\n",
      "     13       \u001b[36m17.6679\u001b[0m        1.7517  0.0870\n",
      "     14        \u001b[36m6.0828\u001b[0m        1.7007  0.0890\n",
      "     15        \u001b[36m3.1903\u001b[0m        1.6515  0.0860\n",
      "     16        \u001b[36m1.6997\u001b[0m        \u001b[32m1.6059\u001b[0m  0.0870\n",
      "     17        \u001b[36m1.5446\u001b[0m        \u001b[32m1.5611\u001b[0m  0.0870\n",
      "     18        \u001b[36m1.5048\u001b[0m        \u001b[32m1.5226\u001b[0m  0.0860\n",
      "     19        \u001b[36m1.4729\u001b[0m        \u001b[32m1.4855\u001b[0m  0.0920\n",
      "     20        \u001b[36m1.4356\u001b[0m        \u001b[32m1.4548\u001b[0m  0.0890\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m28933.6550\u001b[0m        \u001b[32m4.7411\u001b[0m  0.0860\n",
      "      2     \u001b[36m7901.6355\u001b[0m        \u001b[32m2.3167\u001b[0m  0.0880\n",
      "      3     \u001b[36m3108.2513\u001b[0m        \u001b[32m1.5741\u001b[0m  0.0900\n",
      "      4      \u001b[36m106.4910\u001b[0m        \u001b[32m1.2930\u001b[0m  0.0890\n",
      "      5      204.8479        \u001b[32m1.1680\u001b[0m  0.0900\n",
      "      6       \u001b[36m80.8207\u001b[0m        \u001b[32m1.0395\u001b[0m  0.0990\n",
      "      7       \u001b[36m23.8535\u001b[0m        \u001b[32m0.9391\u001b[0m  0.0890\n",
      "      8        \u001b[36m4.7398\u001b[0m        \u001b[32m0.8869\u001b[0m  0.1140\n",
      "      9        \u001b[36m2.9659\u001b[0m        \u001b[32m0.8205\u001b[0m  0.0970\n",
      "     10        \u001b[36m1.5380\u001b[0m        \u001b[32m0.8092\u001b[0m  0.0930\n",
      "     11        \u001b[36m1.4526\u001b[0m        0.8358  0.0900\n",
      "     12        \u001b[36m1.4051\u001b[0m        \u001b[32m0.8074\u001b[0m  0.0910\n",
      "     13        \u001b[36m1.3595\u001b[0m        0.8199  0.0910\n",
      "     14        \u001b[36m1.3039\u001b[0m        0.8151  0.0920\n",
      "     15        \u001b[36m1.2680\u001b[0m        0.8290  0.0910\n",
      "     16        \u001b[36m1.2528\u001b[0m        0.8138  0.0900\n",
      "     17        \u001b[36m1.2138\u001b[0m        0.8245  0.0910\n",
      "     18        \u001b[36m1.2045\u001b[0m        0.8093  0.0900\n",
      "     19        \u001b[36m1.1671\u001b[0m        0.8096  0.0890\n",
      "     20        \u001b[36m1.1593\u001b[0m        0.8170  0.0880\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1  \u001b[36m1230555.3709\u001b[0m       \u001b[32m41.2419\u001b[0m  0.0850\n",
      "      2  \u001b[36m1042140.0321\u001b[0m       \u001b[32m27.6489\u001b[0m  0.0890\n",
      "      3   \u001b[36m893122.3270\u001b[0m       \u001b[32m11.3356\u001b[0m  0.0890\n",
      "      4   \u001b[36m747375.3517\u001b[0m        \u001b[32m3.3529\u001b[0m  0.0920\n",
      "      5   \u001b[36m636202.9667\u001b[0m        \u001b[32m2.5904\u001b[0m  0.0910\n",
      "      6   \u001b[36m513743.0637\u001b[0m        \u001b[32m2.1608\u001b[0m  0.0880\n",
      "      7   \u001b[36m407159.7159\u001b[0m        \u001b[32m1.6902\u001b[0m  0.0890\n",
      "      8   \u001b[36m338325.0190\u001b[0m        \u001b[32m1.6397\u001b[0m  0.0980\n",
      "      9   \u001b[36m263246.2236\u001b[0m        \u001b[32m1.5180\u001b[0m  0.0870\n",
      "     10   \u001b[36m233303.6264\u001b[0m        1.8877  0.0870\n",
      "     11   \u001b[36m172819.5716\u001b[0m        1.8543  0.0870\n",
      "     12   \u001b[36m126078.8089\u001b[0m        1.7457  0.0880\n",
      "     13    \u001b[36m95471.6550\u001b[0m        1.8499  0.0870\n",
      "     14    \u001b[36m77994.7910\u001b[0m        2.5536  0.0900\n",
      "     15    \u001b[36m59563.8723\u001b[0m        2.6373  0.0880\n",
      "     16    \u001b[36m36657.2514\u001b[0m        2.0974  0.0910\n",
      "     17    \u001b[36m28244.5314\u001b[0m        2.0610  0.0880\n",
      "     18    \u001b[36m19056.4252\u001b[0m        2.0284  0.0930\n",
      "     19    \u001b[36m11093.5230\u001b[0m        1.7906  0.0890\n",
      "     20     \u001b[36m8861.4060\u001b[0m        1.9810  0.0870\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m11.9274\u001b[0m        \u001b[32m4.2760\u001b[0m  0.0870\n",
      "      2        \u001b[36m3.5666\u001b[0m        \u001b[32m2.4768\u001b[0m  0.0900\n",
      "      3        \u001b[36m2.3583\u001b[0m        \u001b[32m1.7455\u001b[0m  0.0870\n",
      "      4        \u001b[36m1.8609\u001b[0m        \u001b[32m1.4388\u001b[0m  0.0840\n",
      "      5        \u001b[36m1.6477\u001b[0m        \u001b[32m1.3587\u001b[0m  0.0870\n",
      "      6        \u001b[36m1.5520\u001b[0m        \u001b[32m1.3115\u001b[0m  0.0870\n",
      "      7        \u001b[36m1.4965\u001b[0m        \u001b[32m1.2779\u001b[0m  0.0880\n",
      "      8        \u001b[36m1.4561\u001b[0m        \u001b[32m1.2557\u001b[0m  0.0870\n",
      "      9        \u001b[36m1.4116\u001b[0m        \u001b[32m1.2163\u001b[0m  0.0880\n",
      "     10        \u001b[36m1.3770\u001b[0m        \u001b[32m1.1968\u001b[0m  0.0870\n",
      "     11        \u001b[36m1.3405\u001b[0m        \u001b[32m1.1766\u001b[0m  0.0930\n",
      "     12        \u001b[36m1.3134\u001b[0m        \u001b[32m1.1647\u001b[0m  0.0940\n",
      "     13        \u001b[36m1.2897\u001b[0m        \u001b[32m1.1550\u001b[0m  0.0870\n",
      "     14        \u001b[36m1.2626\u001b[0m        \u001b[32m1.1486\u001b[0m  0.0870\n",
      "     15        \u001b[36m1.2439\u001b[0m        \u001b[32m1.1177\u001b[0m  0.0870\n",
      "     16        \u001b[36m1.2317\u001b[0m        \u001b[32m1.1098\u001b[0m  0.0870\n",
      "     17        \u001b[36m1.2065\u001b[0m        \u001b[32m1.0968\u001b[0m  0.0880\n",
      "     18        \u001b[36m1.2039\u001b[0m        \u001b[32m1.0901\u001b[0m  0.0900\n",
      "     19        \u001b[36m1.1854\u001b[0m        \u001b[32m1.0673\u001b[0m  0.0860\n",
      "     20        \u001b[36m1.1733\u001b[0m        \u001b[32m1.0637\u001b[0m  0.0860\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1   \u001b[36m166412.4028\u001b[0m      \u001b[32m362.8886\u001b[0m  0.0910\n",
      "      2    \u001b[36m86855.2252\u001b[0m       \u001b[32m99.2759\u001b[0m  0.1140\n",
      "      3    \u001b[36m36903.9011\u001b[0m       \u001b[32m23.2252\u001b[0m  0.0870\n",
      "      4    \u001b[36m29506.7860\u001b[0m        \u001b[32m8.5447\u001b[0m  0.0870\n",
      "      5     \u001b[36m6061.9611\u001b[0m        \u001b[32m6.6006\u001b[0m  0.0880\n",
      "      6     \u001b[36m2785.0400\u001b[0m        \u001b[32m5.6275\u001b[0m  0.0880\n",
      "      7      \u001b[36m641.0234\u001b[0m        \u001b[32m5.1715\u001b[0m  0.0900\n",
      "      8       \u001b[36m72.0031\u001b[0m        \u001b[32m4.4336\u001b[0m  0.0850\n",
      "      9       \u001b[36m31.5414\u001b[0m        \u001b[32m3.9986\u001b[0m  0.0870\n",
      "     10        \u001b[36m6.7144\u001b[0m        \u001b[32m3.7273\u001b[0m  0.0880\n",
      "     11        6.7464        \u001b[32m3.5141\u001b[0m  0.0860\n",
      "     12        \u001b[36m5.1573\u001b[0m        \u001b[32m3.3325\u001b[0m  0.0870\n",
      "     13        \u001b[36m4.4927\u001b[0m        \u001b[32m3.1908\u001b[0m  0.0890\n",
      "     14        \u001b[36m3.9551\u001b[0m        \u001b[32m3.0698\u001b[0m  0.0910\n",
      "     15        \u001b[36m3.6863\u001b[0m        \u001b[32m2.9502\u001b[0m  0.0980\n",
      "     16        \u001b[36m3.4607\u001b[0m        \u001b[32m2.8491\u001b[0m  0.0850\n",
      "     17        \u001b[36m3.2714\u001b[0m        \u001b[32m2.7593\u001b[0m  0.0850\n",
      "     18        \u001b[36m3.0856\u001b[0m        \u001b[32m2.6678\u001b[0m  0.0870\n",
      "     19        \u001b[36m2.9036\u001b[0m        \u001b[32m2.5945\u001b[0m  0.0910\n",
      "     20        \u001b[36m2.7504\u001b[0m        \u001b[32m2.5259\u001b[0m  0.0880\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m23.6801\u001b[0m       \u001b[32m10.9453\u001b[0m  0.0880\n",
      "      2        \u001b[36m8.8261\u001b[0m        \u001b[32m4.7624\u001b[0m  0.0870\n",
      "      3        \u001b[36m4.2939\u001b[0m        \u001b[32m3.1832\u001b[0m  0.0870\n",
      "      4        \u001b[36m2.9841\u001b[0m        \u001b[32m2.3963\u001b[0m  0.0880\n",
      "      5        \u001b[36m2.2663\u001b[0m        \u001b[32m1.7863\u001b[0m  0.0850\n",
      "      6        \u001b[36m1.8667\u001b[0m        \u001b[32m1.5748\u001b[0m  0.0870\n",
      "      7        \u001b[36m1.6134\u001b[0m        \u001b[32m1.4481\u001b[0m  0.0850\n",
      "      8        \u001b[36m1.4487\u001b[0m        \u001b[32m1.3588\u001b[0m  0.0870\n",
      "      9        \u001b[36m1.3345\u001b[0m        \u001b[32m1.2310\u001b[0m  0.0850\n",
      "     10        \u001b[36m1.2122\u001b[0m        1.3272  0.0870\n",
      "     11        \u001b[36m1.1591\u001b[0m        \u001b[32m1.1692\u001b[0m  0.0890\n",
      "     12        \u001b[36m1.1097\u001b[0m        \u001b[32m1.1280\u001b[0m  0.0870\n",
      "     13        \u001b[36m1.0746\u001b[0m        1.1573  0.0880\n",
      "     14        \u001b[36m1.0375\u001b[0m        1.1937  0.0870\n",
      "     15        \u001b[36m0.9916\u001b[0m        \u001b[32m1.1085\u001b[0m  0.0870\n",
      "     16        \u001b[36m0.9605\u001b[0m        1.1464  0.0870\n",
      "     17        0.9892        1.1684  0.0870\n",
      "     18        \u001b[36m0.9536\u001b[0m        1.1388  0.1090\n",
      "     19        \u001b[36m0.9378\u001b[0m        \u001b[32m1.1003\u001b[0m  0.0870\n",
      "     20        \u001b[36m0.9285\u001b[0m        1.1052  0.0900\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1    \u001b[36m29496.4390\u001b[0m       \u001b[32m11.9322\u001b[0m  0.0850\n",
      "      2    \u001b[36m23292.3529\u001b[0m        \u001b[32m4.2844\u001b[0m  0.0890\n",
      "      3    \u001b[36m12293.3924\u001b[0m        \u001b[32m3.5019\u001b[0m  0.0880\n",
      "      4     \u001b[36m5783.5395\u001b[0m        \u001b[32m2.6268\u001b[0m  0.0880\n",
      "      5     \u001b[36m3632.1363\u001b[0m        \u001b[32m2.2863\u001b[0m  0.0870\n",
      "      6     \u001b[36m1686.0419\u001b[0m        \u001b[32m2.0623\u001b[0m  0.0880\n",
      "      7     \u001b[36m1060.9155\u001b[0m        \u001b[32m1.9609\u001b[0m  0.0880\n",
      "      8      \u001b[36m264.4200\u001b[0m        \u001b[32m1.8212\u001b[0m  0.0920\n",
      "      9      \u001b[36m104.6012\u001b[0m        \u001b[32m1.7169\u001b[0m  0.0880\n",
      "     10       \u001b[36m67.6143\u001b[0m        \u001b[32m1.6422\u001b[0m  0.0870\n",
      "     11       \u001b[36m15.3004\u001b[0m        \u001b[32m1.5784\u001b[0m  0.0870\n",
      "     12        \u001b[36m2.5622\u001b[0m        \u001b[32m1.5299\u001b[0m  0.0880\n",
      "     13        \u001b[36m1.9431\u001b[0m        \u001b[32m1.4929\u001b[0m  0.0890\n",
      "     14        \u001b[36m1.6979\u001b[0m        \u001b[32m1.4572\u001b[0m  0.0870\n",
      "     15        \u001b[36m1.6225\u001b[0m        \u001b[32m1.4431\u001b[0m  0.0880\n",
      "     16        \u001b[36m1.5889\u001b[0m        \u001b[32m1.4078\u001b[0m  0.0870\n",
      "     17        \u001b[36m1.5778\u001b[0m        \u001b[32m1.3868\u001b[0m  0.0880\n",
      "     18        \u001b[36m1.5375\u001b[0m        1.3901  0.0860\n",
      "     19        \u001b[36m1.5179\u001b[0m        \u001b[32m1.3565\u001b[0m  0.0910\n",
      "     20        \u001b[36m1.5012\u001b[0m        \u001b[32m1.3455\u001b[0m  0.0870\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m76.8498\u001b[0m        \u001b[32m5.2313\u001b[0m  0.1100\n",
      "      2      502.3118        \u001b[32m1.9824\u001b[0m  0.0890\n",
      "      3      263.0741        \u001b[32m1.6576\u001b[0m  0.0870\n",
      "      4        \u001b[36m1.7774\u001b[0m        \u001b[32m1.3097\u001b[0m  0.0880\n",
      "      5      177.9623        \u001b[32m1.2621\u001b[0m  0.0880\n",
      "      6        2.1837        \u001b[32m1.2569\u001b[0m  0.0870\n",
      "      7       61.0522        \u001b[32m1.1845\u001b[0m  0.0850\n",
      "      8       31.3266        \u001b[32m1.1678\u001b[0m  0.0920\n",
      "      9       18.8419        \u001b[32m1.1594\u001b[0m  0.0890\n",
      "     10        5.1921        \u001b[32m1.1440\u001b[0m  0.0900\n",
      "     11       61.2779        1.1641  0.1000\n",
      "     12       18.9757        1.1545  0.0930\n",
      "     13        \u001b[36m1.6241\u001b[0m        1.1650  0.0930\n",
      "     14        4.4977        1.1567  0.0910\n",
      "     15        2.3973        1.1915  0.0890\n",
      "     16        \u001b[36m1.0005\u001b[0m        1.1921  0.0860\n",
      "     17        1.9434        1.2013  0.0890\n",
      "     18        5.4468        1.2261  0.0910\n",
      "     19        7.7604        1.2391  0.0870\n",
      "     20       12.3261        1.2292  0.1100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rng</th>\n",
       "      <th>condition</th>\n",
       "      <th>model_performance</th>\n",
       "      <th>p_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.141459</td>\n",
       "      <td>0.253515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.015951</td>\n",
       "      <td>0.898061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.077332</td>\n",
       "      <td>0.533935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.133526</td>\n",
       "      <td>0.281383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.842729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.972786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.999064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>0.924571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>-0.023552</td>\n",
       "      <td>0.849952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>0.987965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rng condition  model_performance    p_vals\n",
       "0    0   pytorch           0.141459  0.253515\n",
       "1    1   pytorch           0.015951  0.898061\n",
       "2    2   pytorch           0.077332  0.533935\n",
       "3    3   pytorch           0.133526  0.281383\n",
       "4    4   pytorch           0.024700  0.842729\n",
       "5    5   pytorch           0.004248  0.972786\n",
       "6    6   pytorch           0.000146  0.999064\n",
       "7    7   pytorch           0.011788  0.924571\n",
       "8    8   pytorch          -0.023552  0.849952\n",
       "9    9   pytorch          -0.001878  0.987965"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerkit.run_selected_condition('pytorch', rngs, n_jobs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamic-marker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

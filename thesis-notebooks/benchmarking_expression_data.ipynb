{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276c041c",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689a5cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6567aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcb3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLink import DataLink\n",
    "data_link = DataLink(path_loader, 'data_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1510e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"ThesisResult3-BenchmarkingExpressionData\"\n",
    "exp_id = \"v1\"\n",
    "\n",
    "if not os.path.exists(f'{path_loader.get_data_path()}data/results/{folder_name}'):\n",
    "    os.makedirs(f'{path_loader.get_data_path()}data/results/{folder_name}')\n",
    "\n",
    "file_save_path = f'{path_loader.get_data_path()}data/results/{folder_name}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f647ce6",
   "metadata": {},
   "source": [
    "### Load in Palbociclib datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b606ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteomic feature data shape: (737, 6692) Proteomic label data shape: (737,)\n",
      "CCLE feature data shape: (584, 19221) CCLE label data shape: (584,)\n"
     ]
    }
   ],
   "source": [
    "# create a joint dataframe of cdk4 expression and drug response for palbociclib\n",
    "# load in original ccle data\n",
    "loading_code = \"goncalves-gdsc-2-Palbociclib-LN_IC50-sin\"\n",
    "# generic-gdsc-{number}-{drug_name}-{target_label}-{dataset_name}-{replace_index}-{row_index}\n",
    "proteomic_feature_data, proteomic_label_data = data_link.get_data_using_code(loading_code)\n",
    "\n",
    "print(f'Proteomic feature data shape: {proteomic_feature_data.shape}', f'Proteomic label data shape: {proteomic_label_data.shape}')\n",
    "\n",
    "loading_code = \"ccle-gdsc-2-Palbociclib-LN_IC50\"\n",
    "ccle_feature_data, ccle_label_data = data_link.get_data_using_code(loading_code)\n",
    "\n",
    "print(f'CCLE feature data shape: {ccle_feature_data.shape}', f'CCLE label data shape: {ccle_label_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a8c33",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da00b2",
   "metadata": {},
   "source": [
    "### Random Forest F-Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "862fbbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from toolkit import Powerkit, FirstQuantileImputer, select_stat_features\n",
    "\n",
    "\n",
    "def pipeline_rf_freg(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    rng: int,\n",
    "    k: int = 50,\n",
    "    rf_kwargs: dict | None = None,\n",
    "):\n",
    "    # 1) Fit transformer(s) on X_train only\n",
    "    imputer = FirstQuantileImputer().fit(X_train)\n",
    "    X_train_imp = imputer.transform(X_train, return_df=True)\n",
    "\n",
    "    # 2) Select features on X_train only\n",
    "    selected_features, sel_train = select_stat_features(\n",
    "        X_train_imp, y_train, selection_size=k\n",
    "    )\n",
    "\n",
    "    # 3) Train model\n",
    "    rf_kwargs = rf_kwargs or {}\n",
    "    model = RandomForestRegressor(random_state=rng, **rf_kwargs)\n",
    "    model.fit(sel_train, y_train)\n",
    "\n",
    "    # 4) Return components needed by eval\n",
    "    return {\n",
    "        \"imputer\": imputer,\n",
    "        \"selected_features\": list(selected_features),\n",
    "        \"model\": model,\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_regression(\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    *,\n",
    "    pipeline_components: dict,\n",
    "    metric: str = \"r2\",\n",
    "):\n",
    "    # Unpack\n",
    "    imputer = pipeline_components[\"imputer\"]\n",
    "    selected = pipeline_components[\"selected_features\"]\n",
    "    model = pipeline_components[\"model\"]\n",
    "\n",
    "    # Transform test\n",
    "    X_test_imp = imputer.transform(X_test, return_df=True)\n",
    "    X_test_sel = X_test_imp[selected]\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_sel)\n",
    "\n",
    "    # Metric\n",
    "    if metric == \"r2\":\n",
    "        perf = r2_score(y_test, y_pred)\n",
    "    else:\n",
    "        # Extend as needed (pearson, mse, etc.)\n",
    "        from scipy.stats import pearsonr\n",
    "\n",
    "        perf = pearsonr(y_test, y_pred)[0]\n",
    "\n",
    "    # Feature importance tuple: (feature_names, scores)\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        fi = (np.array(selected), model.feature_importances_)\n",
    "    else:\n",
    "        # Fallback if model has no built-in importances\n",
    "        fi = (np.array(selected), np.zeros(len(selected)))\n",
    "\n",
    "    return {\n",
    "        \"feature_importance\": fi,\n",
    "        \"model_performance\": perf,\n",
    "        # Optional: include other artifacts if desired\n",
    "        \"y_pred\": y_pred,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274c290",
   "metadata": {},
   "source": [
    "### Expression Data Benchmarking Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36caccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Literal\n",
    "import numpy as np # noqa: F811\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import r2_score # noqa: F811\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from toolkit import FirstQuantileImputer, f_regression_select, get_model_from_string  # noqa: F811\n",
    "\n",
    "\n",
    "def _drop_correlated_columns(X: pd.DataFrame, threshold: float = 0.95) -> List[str]:\n",
    "    corr = X.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    to_drop = set()\n",
    "    for col in sorted(upper.columns):\n",
    "        if col in to_drop:\n",
    "            continue\n",
    "        high_corr = upper.index[upper[col] > threshold].tolist()\n",
    "        to_drop.update(high_corr)\n",
    "    return [c for c in X.columns if c not in to_drop]\n",
    "\n",
    "def _drop_correlated_columns_memory_efficient_optimized(X: pd.DataFrame, threshold: float = 0.95) -> List[str]:\n",
    "    n_features = X.shape[1]\n",
    "    to_drop = set()\n",
    "    kept_columns = set()  # Track columns we're keeping\n",
    "    \n",
    "    batch_size = 1000\n",
    "    \n",
    "    for i in range(0, n_features, batch_size):\n",
    "        end_idx = min(i + batch_size, n_features)\n",
    "        batch_cols = X.columns[i:end_idx]\n",
    "        \n",
    "        # Calculate correlation for current batch against ALL kept columns\n",
    "        if kept_columns:\n",
    "            corr_batch = X[batch_cols].corrwith(X[list(kept_columns)], axis=0).abs()\n",
    "        else:\n",
    "            corr_batch = pd.DataFrame(index=batch_cols, columns=[])\n",
    "        \n",
    "        for j, col in enumerate(batch_cols):\n",
    "            if col in to_drop:\n",
    "                continue\n",
    "            \n",
    "            # Check if correlated with any kept columns\n",
    "            should_drop = False\n",
    "            if kept_columns:\n",
    "                max_corr = corr_batch.loc[col].max() if col in corr_batch.index else 0\n",
    "                if max_corr > threshold:\n",
    "                    should_drop = True\n",
    "            \n",
    "            if should_drop:\n",
    "                to_drop.add(col)\n",
    "            else:\n",
    "                kept_columns.add(col)\n",
    "    \n",
    "    return list(kept_columns)\n",
    "\n",
    "def adaptive_drop_correlated(X, threshold=0.95):\n",
    "    if X.shape[1] < 5000:\n",
    "        return _drop_correlated_columns(X, threshold)  # Original\n",
    "    else:\n",
    "        return _drop_correlated_columns_memory_efficient_optimized(X, threshold)\n",
    "\n",
    "\n",
    "def baseline_pipeline(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    rng: int,\n",
    "    *,\n",
    "    k: int = 500,\n",
    "    var_threshold: float = 0.0,\n",
    "    corr_threshold: float = 0.95,\n",
    "    model_name: Literal[\n",
    "        \"LinearRegression\",\n",
    "        \"RandomForestRegressor\",\n",
    "        \"SVR\",\n",
    "        \"KNeighborsRegressor\",\n",
    "        \"XGBRegressor\",\n",
    "    ] = \"LinearRegression\",\n",
    ") -> Dict:\n",
    "    # 0) Sanitize inputs\n",
    "    X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "    y_train = pd.Series(y_train).replace([np.inf, -np.inf], np.nan)\n",
    "    mask = ~y_train.isna()\n",
    "    X_train, y_train = X_train.loc[mask], y_train.loc[mask]\n",
    "\n",
    "    # 1) Impute on train (ensure no residual NaNs)\n",
    "    imputer = FirstQuantileImputer().fit(X_train)\n",
    "    Xtr = imputer.transform(X_train, return_df=True).astype(float)\n",
    "    Xtr = Xtr.fillna(0.0)\n",
    "\n",
    "    # 2) Variance filter\n",
    "    n_features_initial = Xtr.shape[1]\n",
    "    vt = VarianceThreshold(threshold=var_threshold).fit(Xtr)\n",
    "    vt_keep_cols = Xtr.columns[vt.get_support()].tolist()\n",
    "    Xtr = Xtr[vt_keep_cols]\n",
    "    n_features_post_variance = Xtr.shape[1]\n",
    "\n",
    "    # 3) Correlation filter\n",
    "    corr_keep_cols = adaptive_drop_correlated(Xtr, threshold=corr_threshold)\n",
    "    Xtr = Xtr[corr_keep_cols]\n",
    "    n_features_post_correlation = Xtr.shape[1]\n",
    "\n",
    "    # 4) Univariate ANOVA F-test (fixed top-k)\n",
    "    k_sel = min(k, Xtr.shape[1]) if Xtr.shape[1] > 0 else 0\n",
    "    if k_sel == 0:\n",
    "        selected_features, selector_scores = [], np.array([])\n",
    "        sel_train = Xtr.iloc[:, :0]\n",
    "        no_features = True\n",
    "    else:\n",
    "        selected_features, selector_scores = f_regression_select(Xtr, y_train, k=k_sel)\n",
    "        sel_train = Xtr[selected_features]\n",
    "        no_features = False\n",
    "\n",
    "    # 5) Fixed model; robust fallback if no features\n",
    "    if no_features:\n",
    "        model = DummyRegressor(strategy=\"mean\")\n",
    "        model.fit(np.zeros((len(y_train), 1)), y_train)\n",
    "        model_type = \"DummyRegressor(mean)\"\n",
    "        model_params = {\"strategy\": \"mean\"}\n",
    "    else:\n",
    "        if model_name == \"LinearRegression\":\n",
    "            model = get_model_from_string(\"LinearRegression\")\n",
    "        elif model_name == \"RandomForestRegressor\":\n",
    "            model = get_model_from_string(\n",
    "                \"RandomForestRegressor\", n_estimators=100, random_state=rng\n",
    "            )\n",
    "        elif model_name == \"SVR\":\n",
    "            model = get_model_from_string(\"SVR\", kernel=\"linear\", C=1.0)\n",
    "        elif model_name == \"KNeighborsRegressor\":\n",
    "            model = get_model_from_string(\n",
    "                \"KNeighborsRegressor\", n_neighbors=5, weights=\"distance\", p=2\n",
    "            )\n",
    "        elif model_name == \"XGBRegressor\":\n",
    "            model = get_model_from_string(\n",
    "                \"XGBRegressor\",\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                subsample=1.0,\n",
    "                colsample_bytree=1.0,\n",
    "                random_state=rng,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model_name for baseline benchmarking.\")\n",
    "        model.fit(sel_train, y_train)\n",
    "        model_type = model_name\n",
    "        try:\n",
    "            model_params = model.get_params(deep=False)\n",
    "        except Exception:\n",
    "            model_params = {}\n",
    "\n",
    "    return {\n",
    "        \"imputer\": imputer,\n",
    "        \"vt_keep_cols\": vt_keep_cols,\n",
    "        \"corr_keep_cols\": corr_keep_cols,\n",
    "        \"selected_features\": list(selected_features),\n",
    "        \"selector_scores\": np.array(selector_scores),\n",
    "        \"k_requested\": int(k),\n",
    "        \"k_effective\": int(len(selected_features)),\n",
    "        \"n_features_initial\": int(n_features_initial),\n",
    "        \"n_features_post_variance\": int(n_features_post_variance),\n",
    "        \"n_features_post_correlation\": int(n_features_post_correlation),\n",
    "        \"var_threshold\": float(var_threshold),\n",
    "        \"corr_threshold\": float(corr_threshold),\n",
    "        \"model\": model,\n",
    "        \"model_type\": model_type,\n",
    "        \"model_params\": model_params,\n",
    "        \"train_data\": sel_train,  # may be empty if no_features\n",
    "        \"rng\": int(rng),\n",
    "        \"no_features\": bool(no_features),\n",
    "        \"n_train_samples_used\": int(len(y_train)),\n",
    "    }\n",
    "\n",
    "\n",
    "def baseline_eval(\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    *,\n",
    "    pipeline_components: Dict,\n",
    "    metric_primary: Literal[\"r2\", \"pearson_r\", \"spearman_r\"] = \"r2\",\n",
    "    importance_from: Literal[\"selector\", \"model\"] = \"selector\",\n",
    ") -> Dict:\n",
    "    # Unpack\n",
    "    imputer = pipeline_components[\"imputer\"]\n",
    "    vt_keep = set(pipeline_components[\"vt_keep_cols\"])\n",
    "    corr_keep = set(pipeline_components[\"corr_keep_cols\"])\n",
    "    selected = list(pipeline_components[\"selected_features\"])\n",
    "    selector_scores = pipeline_components[\"selector_scores\"]\n",
    "    model = pipeline_components[\"model\"]\n",
    "    model_name = pipeline_components[\"model_type\"]\n",
    "    model_params = pipeline_components.get(\"model_params\", {})\n",
    "    rng = pipeline_components.get(\"rng\", None)\n",
    "    no_features = pipeline_components.get(\"no_features\", False)\n",
    "\n",
    "    k_requested = pipeline_components.get(\"k_requested\", len(selected))\n",
    "    k_effective = pipeline_components.get(\"k_effective\", len(selected))\n",
    "    n_features_initial = pipeline_components.get(\"n_features_initial\", None)\n",
    "    n_features_post_variance = pipeline_components.get(\"n_features_post_variance\", None)\n",
    "    n_features_post_correlation = pipeline_components.get(\n",
    "        \"n_features_post_correlation\", None\n",
    "    )\n",
    "    var_threshold = pipeline_components.get(\"var_threshold\", None)\n",
    "    corr_threshold = pipeline_components.get(\"corr_threshold\", None)\n",
    "\n",
    "    # 0) Sanitize test inputs\n",
    "    X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "    y_test = pd.Series(y_test).replace([np.inf, -np.inf], np.nan)\n",
    "    mask_y = ~y_test.isna()\n",
    "    X_test, y_test = X_test.loc[mask_y], y_test.loc[mask_y]\n",
    "\n",
    "    # Apply identical transforms\n",
    "    Xti = imputer.transform(X_test, return_df=True).astype(float).fillna(0.0)\n",
    "    cols_after_vt = [c for c in Xti.columns if c in vt_keep]\n",
    "    Xti = Xti[cols_after_vt]\n",
    "    cols_after_corr = [c for c in Xti.columns if c in corr_keep]\n",
    "    Xti = Xti[cols_after_corr]\n",
    "    Xsel = Xti[selected] if len(selected) > 0 else Xti.iloc[:, :0]\n",
    "\n",
    "    # Predict robustly\n",
    "    if no_features or Xsel.shape[1] == 0:\n",
    "        y_pred = np.full_like(\n",
    "            y_test.values, fill_value=float(y_test.mean()), dtype=float\n",
    "        )\n",
    "    else:\n",
    "        y_pred = np.asarray(model.predict(Xsel), dtype=float)\n",
    "\n",
    "    # Filter any non-finite values before metrics\n",
    "    mask_fin = np.isfinite(y_test.values) & np.isfinite(y_pred)\n",
    "    y_t = y_test.values[mask_fin]\n",
    "    y_p = y_pred[mask_fin]\n",
    "    n_test_used = int(y_t.shape[0])\n",
    "\n",
    "    if n_test_used < 2:\n",
    "        r2 = np.nan\n",
    "        pearson_r = pearson_p = np.nan\n",
    "        spearman_rho = spearman_p = np.nan\n",
    "    else:\n",
    "        r2 = r2_score(y_t, y_p)\n",
    "        pearson_r, pearson_p = pearsonr(y_t, y_p)\n",
    "        spearman_rho, spearman_p = spearmanr(y_t, y_p)\n",
    "\n",
    "    metrics = {\n",
    "        \"r2\": float(r2) if np.isfinite(r2) else np.nan,\n",
    "        \"pearson_r\": float(pearson_r) if np.isfinite(pearson_r) else np.nan,\n",
    "        \"pearson_p\": float(pearson_p) if np.isfinite(pearson_p) else np.nan,\n",
    "        \"spearman_rho\": float(spearman_rho) if np.isfinite(spearman_rho) else np.nan,\n",
    "        \"spearman_p\": float(spearman_p) if np.isfinite(spearman_p) else np.nan,\n",
    "        \"n_test_samples_used\": n_test_used,\n",
    "    }\n",
    "\n",
    "    # Importance\n",
    "    if importance_from == \"selector\":\n",
    "        fi = (np.array(selected), np.array(selector_scores))\n",
    "    else:\n",
    "        if hasattr(model, \"feature_importances_\") and len(selected) > 0:\n",
    "            fi = (np.array(selected), model.feature_importances_)\n",
    "        elif model_name in (\"LinearRegression\",) and len(selected) > 0:\n",
    "            coef = getattr(model, \"coef_\", np.zeros(len(selected)))\n",
    "            fi = (np.array(selected), np.abs(coef))\n",
    "        else:\n",
    "            fi = (np.array(selected), np.zeros(len(selected)))\n",
    "\n",
    "    primary = metrics.get(metric_primary, metrics[\"r2\"])\n",
    "\n",
    "    return {\n",
    "        \"feature_importance\": fi,\n",
    "        \"feature_importance_from\": importance_from,\n",
    "        \"model_performance\": float(primary) if primary is not None else np.nan,\n",
    "        \"metrics\": metrics,\n",
    "        \"k_requested\": int(k_requested),\n",
    "        \"k_effective\": int(k_effective),\n",
    "        \"n_features_initial\": int(n_features_initial)\n",
    "        if n_features_initial is not None\n",
    "        else None,\n",
    "        \"n_features_post_variance\": int(n_features_post_variance)\n",
    "        if n_features_post_variance is not None\n",
    "        else None,\n",
    "        \"n_features_post_correlation\": int(n_features_post_correlation)\n",
    "        if n_features_post_correlation is not None\n",
    "        else None,\n",
    "        \"var_threshold\": float(var_threshold) if var_threshold is not None else None,\n",
    "        \"corr_threshold\": float(corr_threshold) if corr_threshold is not None else None,\n",
    "        \"model_name\": model_name,\n",
    "        \"model_params\": model_params,\n",
    "        \"rng\": rng,\n",
    "        \"selected_features\": selected,\n",
    "        \"selector_scores\": np.array(selector_scores),\n",
    "        \"y_pred\": y_p,  # filtered to finite entries\n",
    "        \"y_true_index\": y_test.index[mask_fin],\n",
    "        \"n_train_samples_used\": pipeline_components.get(\"n_train_samples_used\", None),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8433723",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80255417",
   "metadata": {},
   "source": [
    "### Benchmarking Expression Datasets (k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # noqa: F811\n",
    "import pandas as pd\n",
    "from toolkit import Powerkit  # noqa: F811\n",
    "\n",
    "# 1) Align indices and order (critical for identical splits across modalities)\n",
    "common = sorted(\n",
    "    set(ccle_label_data.index)\n",
    "    & set(ccle_feature_data.index)\n",
    "    & set(proteomic_label_data.index)\n",
    "    & set(proteomic_feature_data.index)\n",
    ")\n",
    "ccle_feature_data = ccle_feature_data.loc[common]\n",
    "ccle_label_data = ccle_label_data.loc[common]\n",
    "proteomic_feature_data = proteomic_feature_data.loc[common]\n",
    "proteomic_label_data = proteomic_label_data.loc[common]\n",
    "\n",
    "# Optional: ensure numeric only\n",
    "ccle_feature_data = ccle_feature_data.select_dtypes(include=[np.number])\n",
    "proteomic_feature_data = proteomic_feature_data.select_dtypes(include=[np.number])\n",
    "\n",
    "fixed_args = {\"k\": 500, \"var_threshold\": 0.0, \"corr_threshold\": 0.95}\n",
    "models = [\n",
    "    \"LinearRegression\",\n",
    "    \"RandomForestRegressor\",\n",
    "    \"SVR\",\n",
    "]  # extend with \"KNeighborsRegressor\",\"XGBRegressor\"\n",
    "\n",
    "\n",
    "def add_baselines(pk: Powerkit, model_list):\n",
    "    for m in model_list:\n",
    "        cond = f\"baseline_{m.lower().replace('regressor', '')}\"\n",
    "        pk.add_condition(\n",
    "            condition=cond,\n",
    "            get_importance=False,  # 3.3.2 focuses on performance; set True if you need FI aggregation\n",
    "            pipeline_function=baseline_pipeline,\n",
    "            pipeline_args={**fixed_args, \"model_name\": m},\n",
    "            eval_function=baseline_eval,\n",
    "            eval_args={\"metric_primary\": \"r2\", \"importance_from\": \"selector\"},\n",
    "        )\n",
    "\n",
    "\n",
    "# 2) Build Powerkit instances and register conditions\n",
    "pk_rna = Powerkit(ccle_feature_data, ccle_label_data)\n",
    "add_baselines(pk_rna, models)\n",
    "\n",
    "pk_prot = Powerkit(proteomic_feature_data, proteomic_label_data)\n",
    "add_baselines(pk_prot, models)\n",
    "\n",
    "# 3) Identical RNGs for fair repeated holdouts\n",
    "rngs = np.random.RandomState(42).randint(0, 100000, size=50)\n",
    "\n",
    "df_rna = pk_rna.run_all_conditions(rng_list=rngs, n_jobs=-1, verbose=True)\n",
    "df_rna[\"modality\"] = \"RNASeq\"\n",
    "df_prot = pk_prot.run_all_conditions(rng_list=rngs, n_jobs=-1, verbose=True)\n",
    "df_prot[\"modality\"] = \"Proteomic\"\n",
    "# 5) Concatenate and summarize\n",
    "df_all = pd.concat([df_rna, df_prot], ignore_index=True)\n",
    "\n",
    "# model_performance is primary metric (R2); full metrics dict per row in 'metrics'\n",
    "summary = (\n",
    "    df_all.groupby([\"modality\", \"condition\"])[\"model_performance\"]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bfbf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored metrics (mean ± std) by modality and condition:\n",
      "                                    pearson_r     spearman_rho    \n",
      "                                         mean std         mean std\n",
      "modality  condition                                               \n",
      "Proteomic baseline_linearregression    0.0644 NaN       0.0487 NaN\n",
      "          baseline_randomforest        0.7172 NaN       0.6623 NaN\n",
      "          baseline_svr                 0.3184 NaN       0.3376 NaN\n",
      "RNASeq    baseline_linearregression    0.1578 NaN       0.1762 NaN\n",
      "          baseline_randomforest        0.7368 NaN       0.7110 NaN\n",
      "          baseline_svr                 0.2996 NaN       0.2886 NaN\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr  # noqa: F811\n",
    "\n",
    "# Expand stored 'metrics' dict (if present) and show pearson/spearman by modality+condition,\n",
    "# plus an optional recompute from y_true_index + y_pred for verification.\n",
    "\n",
    "# 1) If df_all contains a 'metrics' column with dicts, unpack it\n",
    "if \"metrics\" in df_all.columns and \"pearson_r\" not in df_all.columns:\n",
    "    metrics_df = pd.json_normalize(df_all[\"metrics\"])\n",
    "    for col in (\"r2\", \"pearson_r\", \"spearman_rho\"):\n",
    "        if col in metrics_df.columns:\n",
    "            df_all[col] = metrics_df[col]\n",
    "\n",
    "# 2) Quick grouped summary from stored metrics (if available)\n",
    "if {\"pearson_r\", \"spearman_rho\"}.issubset(df_all.columns):\n",
    "    print(\"Stored metrics (mean ± std) by modality and condition:\")\n",
    "    print(\n",
    "        df_all.groupby([\"modality\", \"condition\"])[[\"pearson_r\", \"spearman_rho\"]]\n",
    "        .agg([\"mean\", \"std\"])\n",
    "        .round(4)\n",
    "    )\n",
    "else:\n",
    "    print(\"Stored pearson/spearman not found in df_all; you can recompute them from y_true_index + y_pred (see step 3).\")\n",
    "\n",
    "# 3) Recompute metrics from y_true_index and y_pred to verify (uses ccle_label_data / proteomic_label_data)\n",
    "\n",
    "def recompute_metrics(row):\n",
    "    # pick correct label series based on modality\n",
    "    labels = ccle_label_data if row[\"modality\"] == \"RNASeq\" else proteomic_label_data\n",
    "    idx = row[\"y_true_index\"]\n",
    "    y_true = labels.loc[idx].values\n",
    "    y_pred = np.asarray(row[\"y_pred\"], dtype=float)\n",
    "\n",
    "    mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if mask.sum() < 2:\n",
    "        return pd.Series({\"r2_re\": np.nan, \"pearson_r_re\": np.nan, \"spearman_rho_re\": np.nan})\n",
    "\n",
    "    r2 = r2_score(y_true[mask], y_pred[mask])\n",
    "    pr = pearsonr(y_true[mask], y_pred[mask])[0]\n",
    "    sr = spearmanr(y_true[mask], y_pred[mask])[0]\n",
    "    return pd.Series({\"r2_re\": r2, \"pearson_r_re\": pr, \"spearman_rho_re\": sr})\n",
    "\n",
    "recomputed = df_all.apply(recompute_metrics, axis=1)\n",
    "df_all = pd.concat([df_all, recomputed], axis=1)\n",
    "\n",
    "# print(\"\\nRecomputed metrics (mean ± std) by modality and condition:\")\n",
    "# print(\n",
    "#     df_all.groupby([\"modality\", \"condition\"])[[\"pearson_r_re\", \"spearman_rho_re\"]]\n",
    "#     .agg([\"mean\", \"std\"])\n",
    "#     .round(4)\n",
    "# )\n",
    "\n",
    "# Optionally inspect row-level values\n",
    "display_cols = [\"modality\", \"condition\", \"pearson_r_re\", \"spearman_rho_re\", \"r2_re\"]\n",
    "# print(\"\\nPer-row recomputed metrics:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_pickle(f\"{file_save_path}benchmarking_results_{exp_id}.pkl\")\n",
    "\n",
    "# Also save the individual modality results\n",
    "df_rna.to_pickle(f\"{file_save_path}rna_results_{exp_id}.pkl\")\n",
    "df_prot.to_pickle(f\"{file_save_path}proteomic_results_{exp_id}.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da691ae",
   "metadata": {},
   "source": [
    "### Benchmarking Expression Datasets (three k values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a437bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # noqa: F811\n",
    "import pandas as pd\n",
    "from toolkit import Powerkit  # noqa: F811\n",
    "\n",
    "# 1) Align indices and order (critical for identical splits across modalities)\n",
    "common = sorted(\n",
    "    set(ccle_label_data.index)\n",
    "    & set(ccle_feature_data.index)\n",
    "    & set(proteomic_label_data.index)\n",
    "    & set(proteomic_feature_data.index)\n",
    ")\n",
    "ccle_feature_data = ccle_feature_data.loc[common]\n",
    "ccle_label_data = ccle_label_data.loc[common]\n",
    "proteomic_feature_data = proteomic_feature_data.loc[common]\n",
    "proteomic_label_data = proteomic_label_data.loc[common]\n",
    "\n",
    "# Optional: ensure numeric only\n",
    "ccle_feature_data = ccle_feature_data.select_dtypes(include=[np.number])\n",
    "proteomic_feature_data = proteomic_feature_data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Define k values to test\n",
    "k_values = [20, 100, 500]\n",
    "fixed_args_base = {\"var_threshold\": 0.0, \"corr_threshold\": 0.95}\n",
    "models = [\n",
    "    \"LinearRegression\",\n",
    "    \"RandomForestRegressor\",\n",
    "    \"SVR\",\n",
    "]  # extend with \"KNeighborsRegressor\",\"XGBRegressor\"\n",
    "\n",
    "def add_baselines(pk: Powerkit, model_list, k_values):\n",
    "    for m in model_list:\n",
    "        for k in k_values:\n",
    "            cond = f\"baseline_{m.lower().replace('regressor', '')}_k{k}\"\n",
    "            pk.add_condition(\n",
    "                condition=cond,\n",
    "                get_importance=False,  # 3.3.2 focuses on performance; set True if you need FI aggregation\n",
    "                pipeline_function=baseline_pipeline,\n",
    "                pipeline_args={**fixed_args_base, \"model_name\": m, \"k\": k},\n",
    "                eval_function=baseline_eval,\n",
    "                eval_args={\"metric_primary\": \"r2\", \"importance_from\": \"selector\"},\n",
    "            )\n",
    "\n",
    "# 2) Build Powerkit instances and register conditions\n",
    "pk_rna = Powerkit(ccle_feature_data, ccle_label_data)\n",
    "add_baselines(pk_rna, models, k_values)\n",
    "pk_prot = Powerkit(proteomic_feature_data, proteomic_label_data)\n",
    "add_baselines(pk_prot, models, k_values)\n",
    "\n",
    "# 3) Identical RNGs for fair repeated holdouts\n",
    "rngs = np.random.RandomState(42).randint(0, 100000, size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685438f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Run all conditions\n",
    "df_rna = pk_rna.run_all_conditions(rng_list=rngs, n_jobs=-1, verbose=True)\n",
    "df_rna[\"modality\"] = \"RNASeq\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_prot = pk_prot.run_all_conditions(rng_list=rngs, n_jobs=-1, verbose=True)\n",
    "df_prot[\"modality\"] = \"Proteomic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c96ee6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     modality                       condition  k_value        mean  std  count\n",
      "0   Proteomic  baseline_linearregression_k100      100    0.400253  NaN      1\n",
      "1   Proteomic   baseline_linearregression_k20       20    0.382698  NaN      1\n",
      "2   Proteomic  baseline_linearregression_k500      500 -200.721790  NaN      1\n",
      "3   Proteomic      baseline_randomforest_k100      100    0.434101  NaN      1\n",
      "4   Proteomic       baseline_randomforest_k20       20    0.272204  NaN      1\n",
      "5   Proteomic      baseline_randomforest_k500      500    0.453106  NaN      1\n",
      "6   Proteomic               baseline_svr_k100      100    0.279440  NaN      1\n",
      "7   Proteomic                baseline_svr_k20       20    0.397100  NaN      1\n",
      "8   Proteomic               baseline_svr_k500      500   -2.178528  NaN      1\n",
      "9      RNASeq  baseline_linearregression_k100      100    0.291513  NaN      1\n",
      "10     RNASeq   baseline_linearregression_k20       20    0.474755  NaN      1\n",
      "11     RNASeq  baseline_linearregression_k500      500  -32.261884  NaN      1\n",
      "12     RNASeq      baseline_randomforest_k100      100    0.493928  NaN      1\n",
      "13     RNASeq       baseline_randomforest_k20       20    0.546006  NaN      1\n",
      "14     RNASeq      baseline_randomforest_k500      500    0.521312  NaN      1\n",
      "15     RNASeq               baseline_svr_k100      100    0.235294  NaN      1\n",
      "16     RNASeq                baseline_svr_k20       20    0.464356  NaN      1\n",
      "17     RNASeq               baseline_svr_k500      500   -2.903587  NaN      1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5) Concatenate and summarize\n",
    "df_all = pd.concat([df_rna, df_prot], ignore_index=True)\n",
    "\n",
    "# 6) Extract k value from condition name for grouping\n",
    "df_all[\"k_value\"] = df_all[\"condition\"].str.extract(r'k(\\d+)').astype(int)\n",
    "\n",
    "# model_performance is primary metric (R2); full metrics dict per row in 'metrics'\n",
    "summary = (\n",
    "    df_all.groupby([\"modality\", \"condition\", \"k_value\"])[\"model_performance\"]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a98afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_pickle(f\"{file_save_path}benchmarking_results_{exp_id}.pkl\")\n",
    "\n",
    "# Also save the individual modality results\n",
    "df_rna.to_pickle(f\"{file_save_path}rna_results_{exp_id}.pkl\")\n",
    "df_prot.to_pickle(f\"{file_save_path}proteomic_results_{exp_id}.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59504fea",
   "metadata": {},
   "source": [
    "## Reading data \n",
    "\n",
    "This section can be ran to read in the data used for the analysis. The initialisation code block must be run first to load in the correct file paths."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ode-biomarker-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06bc1b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook in Jupytext format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbb055",
   "metadata": {},
   "source": [
    "## Feature Importance Export for All Methods\n",
    "\n",
    "This script exports feature importance data from the feature selection method comparison\n",
    "in the same format as feat_importance_analysis.py, ensuring consistency across all exports.\n",
    "\n",
    "**Export Format**: mean_importance, std_importance, occurrence_count\n",
    "**Methods Covered**: Network only (d3), MRMR only, MRMR + Network (d3)\n",
    "**Importance Methods**: SHAP and MDI for each method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab294532",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bff9f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find(\"project\")\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[: index_project + 7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f\"Project path set to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0245d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader #noqa: E402\n",
    "\n",
    "path_loader = PathLoader(\"data_config.env\", \"current_user.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f621656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLink import DataLink #noqa: E402\n",
    "\n",
    "data_link = DataLink(path_loader, \"data_codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74df2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the actual directory where results are stored\n",
    "folder_name = \"ThesisResult-FeatureImportanceConsensus\"\n",
    "exp_id = \"v1_rf_k500_3methods_split0.3_comparison\"\n",
    "\n",
    "# The results are already in the main folder, no need to create subfolders\n",
    "main_results_folder = f\"{path_loader.get_data_path()}data/results/{folder_name}/\"\n",
    "file_save_path = f\"{path_loader.get_data_path()}data/results/{folder_name}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee110c00",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create a new report file for capturing print statements\n",
    "print_report_path = f\"{file_save_path}feature_importance_export_report_{exp_id}.md\"\n",
    "print_report_file = open(print_report_path, 'w', encoding='utf-8')\n",
    "\n",
    "# Write header to the print report\n",
    "print_report_file.write(f\"# Feature Importance Export Report - {exp_id}\\n\\n\")\n",
    "print_report_file.write(f\"**Generated**: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "print_report_file.write(\"This report captures all feature importance exports from the feature selection method comparison analysis.\\n\\n\")\n",
    "\n",
    "def save_and_print(message, report_file=None, level=\"info\"):\n",
    "    \"\"\"\n",
    "    Print message to console and save to report file with proper formatting.\n",
    "    \"\"\"\n",
    "    # Print to console\n",
    "    print(message)\n",
    "    \n",
    "    # Save to report with proper formatting\n",
    "    if report_file:\n",
    "        if level == \"header\":\n",
    "            report_file.write(f\"# {message}\\n\\n\")\n",
    "        elif level == \"section\":\n",
    "            report_file.write(f\"## {message}\\n\\n\")\n",
    "        elif level == \"subsection\":\n",
    "            report_file.write(f\"### {message}\\n\\n\")\n",
    "        else:  # info level\n",
    "            report_file.write(f\"{message}\\n\\n\")\n",
    "    \n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00711495",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae2f9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Loading Feature Selection Comparison Data\n",
      "Loading data for 6 conditions:\n",
      "- Network only (distance 3): SHAP and MDI importance methods\n",
      "- MRMR only: SHAP and MDI importance methods\n",
      "- MRMR + Network (distance 3): SHAP and MDI importance methods\n"
     ]
    }
   ],
   "source": [
    "save_and_print(\"## Loading Feature Selection Comparison Data\", print_report_file, level=\"section\")\n",
    "\n",
    "# Define experiment parameters\n",
    "model_name = \"RandomForestRegressor\"\n",
    "k_value = 500\n",
    "split_size = 0.3\n",
    "network_distance = 3\n",
    "\n",
    "# Define the 3 feature selection methods\n",
    "methods = {\n",
    "    \"network_only_d3\": \"Network only (distance 3)\", \n",
    "    \"mrmr_only\": \"MRMR only\",\n",
    "    \"mrmr_network_d3\": \"MRMR + Network (distance 3)\"\n",
    "}\n",
    "\n",
    "# Define all conditions (3 methods × 2 importance methods)\n",
    "conditions = []\n",
    "for method_name, method_desc in methods.items():\n",
    "    conditions.append(f\"{model_name}_k{k_value}_{method_name}_split{split_size}_shap\")\n",
    "    conditions.append(f\"{model_name}_k{k_value}_{method_name}_split{split_size}_mdi\")\n",
    "\n",
    "save_and_print(f\"Loading data for {len(conditions)} conditions:\", print_report_file, level=\"info\")\n",
    "for method_name, method_desc in methods.items():\n",
    "    save_and_print(f\"- {method_desc}: SHAP and MDI importance methods\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad61a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Data Loading Progress\n",
      "✓ Loaded consensus_feature_importance_RandomForestRegressor_k500_network_only_d3_split0.3_shap.pkl\n",
      "✓ Loaded consensus_feature_importance_signed_RandomForestRegressor_k500_network_only_d3_split0.3_shap.pkl\n",
      "✓ Loaded consensus_feature_importance_RandomForestRegressor_k500_network_only_d3_split0.3_mdi.pkl\n",
      "✗ File not found: consensus_feature_importance_signed_RandomForestRegressor_k500_network_only_d3_split0.3_mdi.pkl\n",
      "✓ Loaded consensus_feature_importance_RandomForestRegressor_k500_mrmr_only_split0.3_shap.pkl\n",
      "✓ Loaded consensus_feature_importance_signed_RandomForestRegressor_k500_mrmr_only_split0.3_shap.pkl\n",
      "✓ Loaded consensus_feature_importance_RandomForestRegressor_k500_mrmr_only_split0.3_mdi.pkl\n",
      "✗ File not found: consensus_feature_importance_signed_RandomForestRegressor_k500_mrmr_only_split0.3_mdi.pkl\n",
      "✓ Loaded consensus_feature_importance_RandomForestRegressor_k500_mrmr_network_d3_split0.3_shap.pkl\n",
      "✓ Loaded consensus_feature_importance_signed_RandomForestRegressor_k500_mrmr_network_d3_split0.3_shap.pkl\n",
      "✓ Loaded consensus_feature_importance_RandomForestRegressor_k500_mrmr_network_d3_split0.3_mdi.pkl\n",
      "✗ File not found: consensus_feature_importance_signed_RandomForestRegressor_k500_mrmr_network_d3_split0.3_mdi.pkl\n",
      "### Available Data Summary\n",
      "**Method Data Availability:**\n",
      "- Network only (distance 3): SHAP=1, MDI=1, Total files=3\n",
      "- MRMR only: SHAP=1, MDI=1, Total files=3\n",
      "- MRMR + Network (distance 3): SHAP=1, MDI=1, Total files=3\n"
     ]
    }
   ],
   "source": [
    "# Load all available data files from the comparison results folder\n",
    "data_files = {}\n",
    "\n",
    "save_and_print(\"### Data Loading Progress\", print_report_file, level=\"subsection\")\n",
    "\n",
    "for condition in conditions:\n",
    "    condition_data = {}\n",
    "    \n",
    "    # Try to load consensus feature importance data\n",
    "    file_types = [\n",
    "        f\"consensus_feature_importance_{condition}.pkl\",\n",
    "        f\"consensus_feature_importance_signed_{condition}.pkl\"\n",
    "    ]\n",
    "    \n",
    "    for file_type in file_types:\n",
    "        file_path = f\"{main_results_folder}{file_type}\"\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                condition_data[file_type.replace(f\"_{condition}.pkl\", \"\")] = pd.read_pickle(file_path)\n",
    "                save_and_print(f\"✓ Loaded {file_type}\", print_report_file, level=\"info\")\n",
    "            except Exception as e:\n",
    "                save_and_print(f\"✗ Failed to load {file_type}: {e}\", print_report_file, level=\"info\")\n",
    "        else:\n",
    "            save_and_print(f\"✗ File not found: {file_type}\", print_report_file, level=\"info\")\n",
    "    \n",
    "    data_files[condition] = condition_data\n",
    "\n",
    "# Display available data summary\n",
    "save_and_print(\"### Available Data Summary\", print_report_file, level=\"subsection\")\n",
    "\n",
    "method_summary = {}\n",
    "for condition, files in data_files.items():\n",
    "    # Extract method name from condition\n",
    "    method_name = '_'.join(condition.split('_')[2:-2])\n",
    "    importance_method = condition.split('_')[-1]\n",
    "    \n",
    "    if method_name not in method_summary:\n",
    "        method_summary[method_name] = {'shap': 0, 'mdi': 0, 'total_files': 0}\n",
    "    \n",
    "    method_summary[method_name][importance_method] += 1\n",
    "    method_summary[method_name]['total_files'] += len([f for f in files.values() if f is not None])\n",
    "\n",
    "save_and_print(\"**Method Data Availability:**\", print_report_file, level=\"info\")\n",
    "for method_name, counts in method_summary.items():\n",
    "    save_and_print(f\"- {methods[method_name]}: SHAP={counts['shap']}, MDI={counts['mdi']}, Total files={counts['total_files']}\", \n",
    "                  print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac7ebb",
   "metadata": {},
   "source": [
    "## Feature Importance CSV Export (All Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575ea7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Feature Importance CSV Export (All Methods)\n",
      "### Exporting Feature Importance Data for All Methods\n",
      "Found 6 conditions with consensus data\n",
      "✓ Exported Network only (distance 3) (SHAP): 1280 features\n",
      "✓ Exported Network only (distance 3) (MDI): 1279 features\n",
      "✓ Exported MRMR only (SHAP): 1230 features\n",
      "✓ Exported MRMR only (MDI): 1262 features\n",
      "✓ Exported MRMR + Network (distance 3) (SHAP): 923 features\n",
      "✓ Exported MRMR + Network (distance 3) (MDI): 931 features\n",
      "### Creating Comprehensive Combined Export\n",
      "✓ Exported comprehensive file: 2408 features\n",
      "  File: I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/feature_importance_comprehensive_all_methods_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "### Creating Selected Features Export\n",
      "✓ Exported selected features: 2057 features\n",
      "  Threshold: 3.0 occurrences (50%)\n",
      "  File: I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/feature_importance_selected_all_methods_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "### Creating Method-Specific Combined Exports\n",
      "✓ Exported Network only (distance 3) combined: 1280 features\n",
      "  File: I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/feature_importance_network_only_d3_combined_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "✓ Exported MRMR only combined: 1446 features\n",
      "  File: I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/feature_importance_mrmr_only_combined_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "✓ Exported MRMR + Network (distance 3) combined: 990 features\n",
      "  File: I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/feature_importance_mrmr_network_d3_combined_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "### Export Summary Statistics\n",
      "**Total conditions exported:** 6\n",
      "**Total unique features across all methods:** 2408\n",
      "**Comprehensive export file:** I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/feature_importance_comprehensive_all_methods_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "**Features with occurrence data:** 2408\n",
      "**Average occurrences per feature:** 182.0\n",
      "**Method breakdown:**\n",
      "- Network only (distance 3) (SHAP): 1280 features\n",
      "- Network only (distance 3) (MDI): 1279 features\n",
      "- MRMR only (SHAP): 1230 features\n",
      "- MRMR only (MDI): 1262 features\n",
      "- MRMR + Network (distance 3) (SHAP): 923 features\n",
      "- MRMR + Network (distance 3) (MDI): 931 features\n"
     ]
    }
   ],
   "source": [
    "save_and_print(\"## Feature Importance CSV Export (All Methods)\", print_report_file, level=\"section\")\n",
    "\n",
    "def export_feature_importance_csv_all_methods(data_files, file_save_path, exp_id, top_n=50, min_occurrence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Export comprehensive feature importance data to CSV files for all feature selection methods\n",
    "    following the same format as feat_importance_analysis.py\n",
    "    \n",
    "    Args:\n",
    "        data_files: Dictionary containing the data files for all methods\n",
    "        file_save_path: Path to save CSV files\n",
    "        exp_id: Experiment identifier\n",
    "        top_n: Number of top features to consider for top-N analysis\n",
    "        min_occurrence_threshold: Minimum occurrence ratio threshold for feature selection (default: 0.5 = 50%)\n",
    "    \"\"\"\n",
    "    save_and_print(\"### Exporting Feature Importance Data for All Methods\", print_report_file, level=\"subsection\")\n",
    "    \n",
    "    # Check available conditions\n",
    "    available_conditions = []\n",
    "    for condition in conditions:\n",
    "        if condition in data_files and 'consensus_feature_importance' in data_files[condition]:\n",
    "            available_conditions.append(condition)\n",
    "    \n",
    "    if not available_conditions:\n",
    "        save_and_print(\"No consensus feature importance data available for export\", print_report_file, level=\"info\")\n",
    "        return None\n",
    "    \n",
    "    save_and_print(f\"Found {len(available_conditions)} conditions with consensus data\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Export each condition separately\n",
    "    exported_files = {}\n",
    "    \n",
    "    for condition in available_conditions:\n",
    "        if 'consensus_feature_importance' not in data_files[condition]:\n",
    "            continue\n",
    "            \n",
    "        consensus_df = data_files[condition]['consensus_feature_importance']\n",
    "        \n",
    "        # Extract method information\n",
    "        parts = condition.split('_')\n",
    "        method_name = '_'.join(parts[2:-2])\n",
    "        importance_method = parts[-1]\n",
    "        \n",
    "        # Create export dataframe with the same format as feat_importance_analysis.py\n",
    "        export_df = pd.DataFrame()\n",
    "        \n",
    "        for feature in consensus_df.index:\n",
    "            feature_data = consensus_df.loc[feature]\n",
    "            export_df.loc[feature, 'mean_importance'] = feature_data.get('mean_importance', np.nan)\n",
    "            export_df.loc[feature, 'std_importance'] = feature_data.get('std_importance', np.nan)\n",
    "            if 'occurrence_count' in feature_data:\n",
    "                export_df.loc[feature, 'occurrence_count'] = feature_data.get('occurrence_count', np.nan)\n",
    "            else:\n",
    "                export_df.loc[feature, 'occurrence_count'] = np.nan\n",
    "        \n",
    "        # Sort by mean importance (most important first)\n",
    "        export_df = export_df.sort_values('mean_importance', ascending=False)\n",
    "        \n",
    "        # Export individual condition file\n",
    "        condition_csv_path = f\"{file_save_path}feature_importance_{method_name}_{importance_method}_{exp_id}.csv\"\n",
    "        export_df.to_csv(condition_csv_path)\n",
    "        \n",
    "        exported_files[condition] = {\n",
    "            'path': condition_csv_path,\n",
    "            'method': method_name,\n",
    "            'importance_method': importance_method,\n",
    "            'n_features': len(export_df)\n",
    "        }\n",
    "        \n",
    "        save_and_print(f\"✓ Exported {methods[method_name]} ({importance_method.upper()}): {len(export_df)} features\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Create comprehensive combined export (all methods and importance types)\n",
    "    save_and_print(\"### Creating Comprehensive Combined Export\", print_report_file, level=\"subsection\")\n",
    "    \n",
    "    # Get all unique features across all conditions\n",
    "    all_features = set()\n",
    "    for condition in available_conditions:\n",
    "        if 'consensus_feature_importance' in data_files[condition]:\n",
    "            all_features.update(data_files[condition]['consensus_feature_importance'].index)\n",
    "    \n",
    "    # Create comprehensive dataframe\n",
    "    comprehensive_df = pd.DataFrame(index=list(all_features))\n",
    "    \n",
    "    # Add columns for each condition\n",
    "    for condition in available_conditions:\n",
    "        if 'consensus_feature_importance' not in data_files[condition]:\n",
    "            continue\n",
    "            \n",
    "        consensus_df = data_files[condition]['consensus_feature_importance']\n",
    "        parts = condition.split('_')\n",
    "        method_name = '_'.join(parts[2:-2])\n",
    "        importance_method = parts[-1]\n",
    "        \n",
    "        # Add mean and std importance columns\n",
    "        for feature in all_features:\n",
    "            if feature in consensus_df.index:\n",
    "                feature_data = consensus_df.loc[feature]\n",
    "                comprehensive_df.loc[feature, f'{method_name}_{importance_method}_mean'] = feature_data.get('mean_importance', np.nan)\n",
    "                comprehensive_df.loc[feature, f'{method_name}_{importance_method}_std'] = feature_data.get('std_importance', np.nan)\n",
    "                comprehensive_df.loc[feature, f'{method_name}_{importance_method}_occurrence'] = feature_data.get('occurrence_count', np.nan)\n",
    "            else:\n",
    "                comprehensive_df.loc[feature, f'{method_name}_{importance_method}_mean'] = np.nan\n",
    "                comprehensive_df.loc[feature, f'{method_name}_{importance_method}_std'] = np.nan\n",
    "                comprehensive_df.loc[feature, f'{method_name}_{importance_method}_occurrence'] = np.nan\n",
    "    \n",
    "    # Add summary statistics\n",
    "    mean_cols = [col for col in comprehensive_df.columns if col.endswith('_mean')]\n",
    "    comprehensive_df['mean_importance_all_methods'] = comprehensive_df[mean_cols].mean(axis=1)\n",
    "    comprehensive_df['std_importance_all_methods'] = comprehensive_df[[col for col in comprehensive_df.columns if col.endswith('_std')]].mean(axis=1)\n",
    "    comprehensive_df['total_occurrences'] = comprehensive_df[[col for col in comprehensive_df.columns if col.endswith('_occurrence')]].sum(axis=1)\n",
    "    \n",
    "    # Sort by overall importance\n",
    "    comprehensive_df = comprehensive_df.sort_values('mean_importance_all_methods', ascending=False)\n",
    "    \n",
    "    # Export comprehensive file\n",
    "    comprehensive_csv_path = f\"{file_save_path}feature_importance_comprehensive_all_methods_{exp_id}.csv\"\n",
    "    comprehensive_df.to_csv(comprehensive_csv_path)\n",
    "    \n",
    "    save_and_print(f\"✓ Exported comprehensive file: {len(comprehensive_df)} features\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"  File: {comprehensive_csv_path}\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Create selected features export using occurrence threshold\n",
    "    save_and_print(\"### Creating Selected Features Export\", print_report_file, level=\"subsection\")\n",
    "    \n",
    "    # Apply occurrence threshold (similar to feat_importance_analysis.py)\n",
    "    if 'total_occurrences' in comprehensive_df.columns:\n",
    "        # Calculate threshold based on total possible occurrences\n",
    "        max_possible_occurrences = len([c for c in available_conditions if 'consensus_feature_importance' in data_files.get(c, {})])\n",
    "        occurrence_threshold = max_possible_occurrences * min_occurrence_threshold\n",
    "        \n",
    "        selected_features_df = comprehensive_df[comprehensive_df['total_occurrences'] >= occurrence_threshold].copy()\n",
    "        \n",
    "        # Export selected features\n",
    "        selected_csv_path = f\"{file_save_path}feature_importance_selected_all_methods_{exp_id}.csv\"\n",
    "        selected_features_df.to_csv(selected_csv_path)\n",
    "        \n",
    "        save_and_print(f\"✓ Exported selected features: {len(selected_features_df)} features\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"  Threshold: {occurrence_threshold:.1f} occurrences ({min_occurrence_threshold*100:.0f}%)\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"  File: {selected_csv_path}\", print_report_file, level=\"info\")\n",
    "    else:\n",
    "        selected_features_df = pd.DataFrame()\n",
    "        save_and_print(\"✗ Could not create selected features export (no occurrence data)\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Create method-specific combined exports\n",
    "    save_and_print(\"### Creating Method-Specific Combined Exports\", print_report_file, level=\"subsection\")\n",
    "    \n",
    "    for method_name in methods.keys():\n",
    "        method_conditions = [c for c in available_conditions if method_name in c]\n",
    "        \n",
    "        if len(method_conditions) < 2:\n",
    "            save_and_print(f\"Skipping {method_name}: insufficient conditions\", print_report_file, level=\"info\")\n",
    "            continue\n",
    "        \n",
    "        # Create method-specific dataframe\n",
    "        method_df = pd.DataFrame()\n",
    "        \n",
    "        # Get features for this method\n",
    "        method_features = set()\n",
    "        for condition in method_conditions:\n",
    "            if 'consensus_feature_importance' in data_files[condition]:\n",
    "                method_features.update(data_files[condition]['consensus_feature_importance'].index)\n",
    "        \n",
    "        method_df = pd.DataFrame(index=list(method_features))\n",
    "        \n",
    "        # Add SHAP and MDI data for this method\n",
    "        for condition in method_conditions:\n",
    "            if 'consensus_feature_importance' not in data_files[condition]:\n",
    "                continue\n",
    "                \n",
    "            consensus_df = data_files[condition]['consensus_feature_importance']\n",
    "            importance_method = condition.split('_')[-1]\n",
    "            \n",
    "            for feature in method_features:\n",
    "                if feature in consensus_df.index:\n",
    "                    feature_data = consensus_df.loc[feature]\n",
    "                    method_df.loc[feature, f'{importance_method}_mean_importance'] = feature_data.get('mean_importance', np.nan)\n",
    "                    method_df.loc[feature, f'{importance_method}_std_importance'] = feature_data.get('std_importance', np.nan)\n",
    "                    method_df.loc[feature, f'{importance_method}_occurrence_count'] = feature_data.get('occurrence_count', np.nan)\n",
    "                else:\n",
    "                    method_df.loc[feature, f'{importance_method}_mean_importance'] = np.nan\n",
    "                    method_df.loc[feature, f'{importance_method}_std_importance'] = np.nan\n",
    "                    method_df.loc[feature, f'{importance_method}_occurrence_count'] = np.nan\n",
    "        \n",
    "        # Add method summary statistics\n",
    "        if 'shap_mean_importance' in method_df.columns and 'mdi_mean_importance' in method_df.columns:\n",
    "            method_df['mean_importance_avg'] = method_df[['shap_mean_importance', 'mdi_mean_importance']].mean(axis=1)\n",
    "            method_df['std_importance_avg'] = method_df[['shap_std_importance', 'mdi_std_importance']].mean(axis=1)\n",
    "            method_df['total_occurrence'] = method_df[['shap_occurrence_count', 'mdi_occurrence_count']].sum(axis=1)\n",
    "        elif 'shap_mean_importance' in method_df.columns:\n",
    "            method_df['mean_importance_avg'] = method_df['shap_mean_importance']\n",
    "            method_df['std_importance_avg'] = method_df['shap_std_importance']\n",
    "            method_df['total_occurrence'] = method_df['shap_occurrence_count']\n",
    "        elif 'mdi_mean_importance' in method_df.columns:\n",
    "            method_df['mean_importance_avg'] = method_df['mdi_mean_importance']\n",
    "            method_df['std_importance_avg'] = method_df['mdi_std_importance']\n",
    "            method_df['total_occurrence'] = method_df['mdi_occurrence_count']\n",
    "        \n",
    "        # Sort by average importance\n",
    "        method_df = method_df.sort_values('mean_importance_avg', ascending=False)\n",
    "        \n",
    "        # Export method-specific file\n",
    "        method_csv_path = f\"{file_save_path}feature_importance_{method_name}_combined_{exp_id}.csv\"\n",
    "        method_df.to_csv(method_csv_path)\n",
    "        \n",
    "        save_and_print(f\"✓ Exported {methods[method_name]} combined: {len(method_df)} features\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"  File: {method_csv_path}\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    save_and_print(\"### Export Summary Statistics\", print_report_file, level=\"subsection\")\n",
    "    save_and_print(f\"**Total conditions exported:** {len(exported_files)}\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"**Total unique features across all methods:** {len(all_features)}\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"**Comprehensive export file:** {comprehensive_csv_path}\", print_report_file, level=\"info\")\n",
    "    \n",
    "    if 'total_occurrences' in comprehensive_df.columns:\n",
    "        save_and_print(f\"**Features with occurrence data:** {comprehensive_df['total_occurrences'].notna().sum()}\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"**Average occurrences per feature:** {comprehensive_df['total_occurrences'].mean():.1f}\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Method breakdown\n",
    "    save_and_print(\"**Method breakdown:**\", print_report_file, level=\"info\")\n",
    "    for condition, info in exported_files.items():\n",
    "        save_and_print(f\"- {methods[info['method']]} ({info['importance_method'].upper()}): {info['n_features']} features\", print_report_file, level=\"info\")\n",
    "    \n",
    "    return {\n",
    "        'individual_exports': exported_files,\n",
    "        'comprehensive_export': comprehensive_csv_path,\n",
    "        'comprehensive_df': comprehensive_df,\n",
    "        'selected_export': selected_csv_path if len(selected_features_df) > 0 else None,\n",
    "        'selected_df': selected_features_df\n",
    "    }\n",
    "\n",
    "# Execute the export for all methods\n",
    "export_results = export_feature_importance_csv_all_methods(data_files, file_save_path, exp_id, min_occurrence_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592e22e",
   "metadata": {},
   "source": [
    "## SHAP Directional Effects Export (All Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "080425c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## SHAP Directional Effects Export (All Methods)\n",
      "### Exporting SHAP Directional Effects for All Methods\n",
      "✓ Network only (distance 3) SHAP effects exported:\n",
      "  - Positive effects: 580 features -> I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/shap_positive_effects_network_only_d3_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "  - Negative effects: 657 features -> I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/shap_negative_effects_network_only_d3_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "  - Total features: 1280\n",
      "✓ MRMR only SHAP effects exported:\n",
      "  - Positive effects: 580 features -> I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/shap_positive_effects_mrmr_only_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "  - Negative effects: 642 features -> I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/shap_negative_effects_mrmr_only_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "  - Total features: 1230\n",
      "✓ MRMR + Network (distance 3) SHAP effects exported:\n",
      "  - Positive effects: 437 features -> I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/shap_positive_effects_mrmr_network_d3_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "  - Negative effects: 474 features -> I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/shap_negative_effects_mrmr_network_d3_v1_rf_k500_3methods_split0.3_comparison.csv\n",
      "  - Total features: 923\n",
      "### SHAP Directional Effects Summary\n",
      "**Total SHAP features across all methods:** 3433\n",
      "**Total positive effects:** 1597\n",
      "**Total negative effects:** 1773\n",
      "**Overall positive ratio:** 46.5%\n",
      "**Method breakdown:**\n",
      "- Network only (distance 3): 580 positive, 657 negative (45.3% positive)\n",
      "- MRMR only: 580 positive, 642 negative (47.2% positive)\n",
      "- MRMR + Network (distance 3): 437 positive, 474 negative (47.3% positive)\n"
     ]
    }
   ],
   "source": [
    "save_and_print(\"## SHAP Directional Effects Export (All Methods)\", print_report_file, level=\"section\")\n",
    "\n",
    "def export_shap_directional_effects_all_methods(data_files, file_save_path, exp_id):\n",
    "    \"\"\"\n",
    "    Export SHAP directional effects (positive/negative) for all methods that have SHAP data\n",
    "    following the same format as feat_importance_analysis.py\n",
    "    \"\"\"\n",
    "    save_and_print(\"### Exporting SHAP Directional Effects for All Methods\", print_report_file, level=\"subsection\")\n",
    "    \n",
    "    shap_exports = {}\n",
    "    \n",
    "    # Find all SHAP conditions\n",
    "    shap_conditions = [condition for condition in conditions if 'shap' in condition]\n",
    "    \n",
    "    for condition in shap_conditions:\n",
    "        if condition not in data_files or 'consensus_feature_importance_signed' not in data_files[condition]:\n",
    "            save_and_print(f\"Skipping {condition}: No signed SHAP data available\", print_report_file, level=\"info\")\n",
    "            continue\n",
    "        \n",
    "        # Extract method information\n",
    "        parts = condition.split('_')\n",
    "        method_name = '_'.join(parts[2:-2])\n",
    "        \n",
    "        signed_consensus = data_files[condition]['consensus_feature_importance_signed']\n",
    "        \n",
    "        # Analyze directional effects\n",
    "        positive_effects = signed_consensus[signed_consensus['mean_importance_signed'] > 0]\n",
    "        negative_effects = signed_consensus[signed_consensus['mean_importance_signed'] < 0]\n",
    "        \n",
    "        # Create export dataframes with the same format as feat_importance_analysis.py\n",
    "        positive_export = positive_effects[['mean_importance_signed', 'std_importance_signed', 'occurrence_count']].copy()\n",
    "        negative_export = negative_effects[['mean_importance_signed', 'std_importance_signed', 'occurrence_count']].copy()\n",
    "        \n",
    "        # Rename columns to match existing format\n",
    "        positive_export = positive_export.rename(columns={\n",
    "            'mean_importance_signed': 'mean_importance',\n",
    "            'std_importance_signed': 'std_importance'\n",
    "        })\n",
    "        negative_export = negative_export.rename(columns={\n",
    "            'mean_importance_signed': 'mean_importance',\n",
    "            'std_importance_signed': 'std_importance'\n",
    "        })\n",
    "        \n",
    "        # Convert negative values to absolute values for negative effects export\n",
    "        negative_export['mean_importance'] = negative_export['mean_importance'].abs()\n",
    "        \n",
    "        # Sort by absolute value of mean_importance (most impactful first)\n",
    "        positive_export['abs_importance'] = positive_export['mean_importance'].abs()\n",
    "        negative_export['abs_importance'] = negative_export['mean_importance'].abs()\n",
    "        \n",
    "        positive_export = positive_export.sort_values('abs_importance', ascending=False)\n",
    "        negative_export = negative_export.sort_values('abs_importance', ascending=False)\n",
    "        \n",
    "        # Remove the temporary abs_importance column before export\n",
    "        positive_export = positive_export.drop('abs_importance', axis=1)\n",
    "        negative_export = negative_export.drop('abs_importance', axis=1)\n",
    "        \n",
    "        # Export positive effects\n",
    "        positive_csv_path = f\"{file_save_path}shap_positive_effects_{method_name}_{exp_id}.csv\"\n",
    "        positive_export.to_csv(positive_csv_path)\n",
    "        \n",
    "        # Export negative effects  \n",
    "        negative_csv_path = f\"{file_save_path}shap_negative_effects_{method_name}_{exp_id}.csv\"\n",
    "        negative_export.to_csv(negative_csv_path)\n",
    "        \n",
    "        shap_exports[method_name] = {\n",
    "            'positive_path': positive_csv_path,\n",
    "            'negative_path': negative_csv_path,\n",
    "            'positive_count': len(positive_export),\n",
    "            'negative_count': len(negative_export),\n",
    "            'total_count': len(signed_consensus)\n",
    "        }\n",
    "        \n",
    "        save_and_print(f\"✓ {methods[method_name]} SHAP effects exported:\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"  - Positive effects: {len(positive_export)} features -> {positive_csv_path}\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"  - Negative effects: {len(negative_export)} features -> {negative_csv_path}\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"  - Total features: {len(signed_consensus)}\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    if shap_exports:\n",
    "        save_and_print(\"### SHAP Directional Effects Summary\", print_report_file, level=\"subsection\")\n",
    "        total_positive = sum(info['positive_count'] for info in shap_exports.values())\n",
    "        total_negative = sum(info['negative_count'] for info in shap_exports.values())\n",
    "        total_features = sum(info['total_count'] for info in shap_exports.values())\n",
    "        \n",
    "        save_and_print(f\"**Total SHAP features across all methods:** {total_features}\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"**Total positive effects:** {total_positive}\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"**Total negative effects:** {total_negative}\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"**Overall positive ratio:** {total_positive/total_features:.1%}\", print_report_file, level=\"info\")\n",
    "        \n",
    "        save_and_print(\"**Method breakdown:**\", print_report_file, level=\"info\")\n",
    "        for method_name, info in shap_exports.items():\n",
    "            positive_ratio = info['positive_count'] / info['total_count']\n",
    "            save_and_print(f\"- {methods[method_name]}: {info['positive_count']} positive, {info['negative_count']} negative ({positive_ratio:.1%} positive)\", print_report_file, level=\"info\")\n",
    "    else:\n",
    "        save_and_print(\"No SHAP directional effects data available for export\", print_report_file, level=\"info\")\n",
    "    \n",
    "    return shap_exports\n",
    "\n",
    "# Execute SHAP directional effects export\n",
    "shap_export_results = export_shap_directional_effects_all_methods(data_files, file_save_path, exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798cb06",
   "metadata": {},
   "source": [
    "## Export Summary and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d632ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Export Summary and Validation\n",
      "### Export Validation\n",
      "**Feature Importance Exports:**\n",
      "✓ Comprehensive export: 291766 bytes\n",
      "  - Rows: 2408, Columns: 21\n",
      "✓ Selected features export: 268583 bytes\n",
      "✓ Individual exports: 6/6 files found\n",
      "**SHAP Directional Effects Exports:**\n",
      "✓ Network only (distance 3) positive effects: 22594 bytes\n",
      "✓ Network only (distance 3) negative effects: 25636 bytes\n",
      "✓ MRMR only positive effects: 21935 bytes\n",
      "✓ MRMR only negative effects: 24375 bytes\n",
      "✓ MRMR + Network (distance 3) positive effects: 17126 bytes\n",
      "✓ MRMR + Network (distance 3) negative effects: 18630 bytes\n",
      "✓ SHAP exports: 6/6 files found\n",
      "**Export Summary:**\n",
      "Total files exported: 14\n",
      "Total size: 974,056 bytes (0.93 MB)\n",
      "Export directory: I:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data/results/ThesisResult-FeatureImportanceConsensus/\n"
     ]
    }
   ],
   "source": [
    "save_and_print(\"## Export Summary and Validation\", print_report_file, level=\"section\")\n",
    "\n",
    "def validate_exports(export_results, shap_export_results, file_save_path, exp_id):\n",
    "    \"\"\"\n",
    "    Validate exported files and provide summary statistics\n",
    "    \"\"\"\n",
    "    save_and_print(\"### Export Validation\", print_report_file, level=\"subsection\")\n",
    "    \n",
    "    validation_results = {\n",
    "        'feature_importance_exports': {},\n",
    "        'shap_exports': {},\n",
    "        'file_sizes': {},\n",
    "        'data_integrity': {}\n",
    "    }\n",
    "    \n",
    "    # Validate feature importance exports\n",
    "    if export_results:\n",
    "        save_and_print(\"**Feature Importance Exports:**\", print_report_file, level=\"info\")\n",
    "        \n",
    "        # Check comprehensive export\n",
    "        if export_results.get('comprehensive_export'):\n",
    "            comp_path = export_results['comprehensive_export']\n",
    "            if os.path.exists(comp_path):\n",
    "                comp_size = os.path.getsize(comp_path)\n",
    "                validation_results['file_sizes']['comprehensive'] = comp_size\n",
    "                save_and_print(f\"✓ Comprehensive export: {comp_size} bytes\", print_report_file, level=\"info\")\n",
    "                \n",
    "                # Validate data integrity\n",
    "                try:\n",
    "                    comp_df = pd.read_csv(comp_path, index_col=0)\n",
    "                    validation_results['data_integrity']['comprehensive'] = {\n",
    "                        'rows': len(comp_df),\n",
    "                        'columns': len(comp_df.columns),\n",
    "                        'has_mean_importance': 'mean_importance_all_methods' in comp_df.columns,\n",
    "                        'has_std_importance': 'std_importance_all_methods' in comp_df.columns,\n",
    "                        'has_occurrences': 'total_occurrences' in comp_df.columns\n",
    "                    }\n",
    "                    save_and_print(f\"  - Rows: {len(comp_df)}, Columns: {len(comp_df.columns)}\", print_report_file, level=\"info\")\n",
    "                except Exception as e:\n",
    "                    save_and_print(f\"  ✗ Error reading comprehensive export: {e}\", print_report_file, level=\"info\")\n",
    "            else:\n",
    "                save_and_print(f\"✗ Comprehensive export file not found: {comp_path}\", print_report_file, level=\"info\")\n",
    "        \n",
    "        # Check selected export\n",
    "        if export_results.get('selected_export'):\n",
    "            sel_path = export_results['selected_export']\n",
    "            if os.path.exists(sel_path):\n",
    "                sel_size = os.path.getsize(sel_path)\n",
    "                validation_results['file_sizes']['selected'] = sel_size\n",
    "                save_and_print(f\"✓ Selected features export: {sel_size} bytes\", print_report_file, level=\"info\")\n",
    "            else:\n",
    "                save_and_print(f\"✗ Selected features export file not found: {sel_path}\", print_report_file, level=\"info\")\n",
    "        \n",
    "        # Check individual exports\n",
    "        individual_count = 0\n",
    "        for condition, info in export_results.get('individual_exports', {}).items():\n",
    "            if os.path.exists(info['path']):\n",
    "                individual_count += 1\n",
    "                size = os.path.getsize(info['path'])\n",
    "                validation_results['file_sizes'][f\"individual_{condition}\"] = size\n",
    "            else:\n",
    "                save_and_print(f\"✗ Individual export not found: {info['path']}\", print_report_file, level=\"info\")\n",
    "        \n",
    "        save_and_print(f\"✓ Individual exports: {individual_count}/{len(export_results.get('individual_exports', {}))} files found\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Validate SHAP exports\n",
    "    if shap_export_results:\n",
    "        save_and_print(\"**SHAP Directional Effects Exports:**\", print_report_file, level=\"info\")\n",
    "        \n",
    "        positive_count = 0\n",
    "        negative_count = 0\n",
    "        \n",
    "        for method_name, info in shap_export_results.items():\n",
    "            pos_path = info['positive_path']\n",
    "            neg_path = info['negative_path']\n",
    "            \n",
    "            if os.path.exists(pos_path):\n",
    "                positive_count += 1\n",
    "                pos_size = os.path.getsize(pos_path)\n",
    "                validation_results['file_sizes'][f\"shap_positive_{method_name}\"] = pos_size\n",
    "                save_and_print(f\"✓ {methods[method_name]} positive effects: {pos_size} bytes\", print_report_file, level=\"info\")\n",
    "            else:\n",
    "                save_and_print(f\"✗ {methods[method_name]} positive effects not found: {pos_path}\", print_report_file, level=\"info\")\n",
    "            \n",
    "            if os.path.exists(neg_path):\n",
    "                negative_count += 1\n",
    "                neg_size = os.path.getsize(neg_path)\n",
    "                validation_results['file_sizes'][f\"shap_negative_{method_name}\"] = neg_size\n",
    "                save_and_print(f\"✓ {methods[method_name]} negative effects: {neg_size} bytes\", print_report_file, level=\"info\")\n",
    "            else:\n",
    "                save_and_print(f\"✗ {methods[method_name]} negative effects not found: {neg_path}\", print_report_file, level=\"info\")\n",
    "        \n",
    "        save_and_print(f\"✓ SHAP exports: {positive_count + negative_count}/{len(shap_export_results) * 2} files found\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Summary\n",
    "    save_and_print(\"**Export Summary:**\", print_report_file, level=\"info\")\n",
    "    total_files = len(validation_results['file_sizes'])\n",
    "    total_size = sum(validation_results['file_sizes'].values())\n",
    "    save_and_print(f\"Total files exported: {total_files}\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"Total size: {total_size:,} bytes ({total_size/1024/1024:.2f} MB)\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"Export directory: {file_save_path}\", print_report_file, level=\"info\")\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "# Validate all exports\n",
    "validation_results = validate_exports(export_results, shap_export_results, file_save_path, exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c1bdc2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc8a63b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Feature Export Conclusion\n",
      "Feature importance data has been successfully exported for all feature selection methods using the same format as feat_importance_analysis.py:\n",
      "### Exported Files:\n",
      "1. **Individual condition exports** - Each method/importance combination\n",
      "2. **Comprehensive export** - All features across all methods combined\n",
      "3. **Selected features export** - Features meeting occurrence threshold\n",
      "4. **Method-specific exports** - Combined SHAP+MDI for each method\n",
      "5. **SHAP directional effects** - Positive and negative effects for each method\n",
      "### Export Format Consistency:\n",
      "- **Column structure**: mean_importance, std_importance, occurrence_count\n",
      "- **File naming**: Consistent with existing export patterns\n",
      "- **Threshold logic**: Same occurrence-based feature selection\n",
      "- **Data validation**: All exports verified for integrity\n",
      "The exported files are now ready for downstream analysis and maintain full compatibility with existing analysis pipelines.\n",
      "## Export Complete\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Close the report file\u001b[39;00m\n\u001b[0;32m     21\u001b[0m print_report_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m---> 23\u001b[0m \u001b[43msave_and_print\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m## Export Complete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_report_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m save_and_print(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll feature importance exports have been completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m, print_report_file, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m save_and_print(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReport saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprint_report_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, print_report_file, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m, in \u001b[0;36msave_and_print\u001b[1;34m(message, report_file, level)\u001b[0m\n\u001b[0;32m     27\u001b[0m     report_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m level \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mreport_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m## \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmessage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m level \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     31\u001b[0m     report_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "save_and_print(\"## Feature Export Conclusion\", print_report_file, level=\"section\")\n",
    "\n",
    "save_and_print(\"Feature importance data has been successfully exported for all feature selection methods using the same format as feat_importance_analysis.py:\", print_report_file, level=\"info\")\n",
    "\n",
    "save_and_print(\"### Exported Files:\", print_report_file, level=\"subsection\")\n",
    "save_and_print(\"1. **Individual condition exports** - Each method/importance combination\", print_report_file, level=\"info\")\n",
    "save_and_print(\"2. **Comprehensive export** - All features across all methods combined\", print_report_file, level=\"info\")\n",
    "save_and_print(\"3. **Selected features export** - Features meeting occurrence threshold\", print_report_file, level=\"info\")\n",
    "save_and_print(\"4. **Method-specific exports** - Combined SHAP+MDI for each method\", print_report_file, level=\"info\")\n",
    "save_and_print(\"5. **SHAP directional effects** - Positive and negative effects for each method\", print_report_file, level=\"info\")\n",
    "\n",
    "save_and_print(\"### Export Format Consistency:\", print_report_file, level=\"subsection\")\n",
    "save_and_print(\"- **Column structure**: mean_importance, std_importance, occurrence_count\", print_report_file, level=\"info\")\n",
    "save_and_print(\"- **File naming**: Consistent with existing export patterns\", print_report_file, level=\"info\")\n",
    "save_and_print(\"- **Threshold logic**: Same occurrence-based feature selection\", print_report_file, level=\"info\")\n",
    "save_and_print(\"- **Data validation**: All exports verified for integrity\", print_report_file, level=\"info\")\n",
    "\n",
    "save_and_print(\"The exported files are now ready for downstream analysis and maintain full compatibility with existing analysis pipelines.\", print_report_file, level=\"info\")\n",
    "\n",
    "# Close the report file\n",
    "print_report_file.close()\n",
    "\n",
    "save_and_print(\"## Export Complete\", print_report_file, level=\"section\")\n",
    "save_and_print(f\"All feature importance exports have been completed successfully!\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"Report saved to: {print_report_path}\", print_report_file, level=\"info\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "ode-biomarker-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

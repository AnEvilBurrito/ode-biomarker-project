{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76590876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook in Jupytext format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb88de",
   "metadata": {},
   "source": [
    "## CV Split Size Analysis for Random Forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find(\"project\")\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[: index_project + 7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f\"Project path set to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader #noqa: E402\n",
    "\n",
    "path_loader = PathLoader(\"data_config.env\", \"current_user.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b557b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLink import DataLink #noqa: E402\n",
    "\n",
    "data_link = DataLink(path_loader, \"data_codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"ThesisResult5-ModelSelectionBenchmark\"\n",
    "exp_id = \"v1_svr_hyperparameter_mrmr_d3\"\n",
    "\n",
    "# Create both the main folder and exp_id subfolder\n",
    "main_folder = f\"{path_loader.get_data_path()}data/results/{folder_name}\"\n",
    "exp_folder = f\"{main_folder}/{exp_id}\"\n",
    "\n",
    "if not os.path.exists(main_folder):\n",
    "    os.makedirs(main_folder)\n",
    "if not os.path.exists(exp_folder):\n",
    "    os.makedirs(exp_folder)\n",
    "\n",
    "file_save_path = f\"{exp_folder}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50db0b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load saved SVR hyperparameter benchmark data\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Create a new report file for capturing print statements\n",
    "print_report_path = f\"{file_save_path}svr_hyperparameter_visualisation_report_{exp_id}.md\"\n",
    "print_report_file = open(print_report_path, 'w', encoding='utf-8')\n",
    "\n",
    "# Write header to the print report\n",
    "print_report_file.write(f\"# SVR Hyperparameter Visualization Analysis Report - {exp_id}\\n\\n\")\n",
    "print_report_file.write(f\"**Generated**: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "print_report_file.write(\"This report captures all print statements from the SVR hyperparameter analysis with proper formatting.\\n\\n\")\n",
    "\n",
    "def save_and_print(message, report_file=None, level=\"info\"):\n",
    "    \"\"\"\n",
    "    Print message to console and save to report file with proper formatting.\n",
    "    \n",
    "    Args:\n",
    "        message: The message to print and save\n",
    "        report_file: File object to save to (optional)\n",
    "        level: Formatting level - \"header\", \"section\", \"subsection\", or \"info\"\n",
    "    \"\"\"\n",
    "    # Print to console\n",
    "    print(message)\n",
    "    \n",
    "    # Save to report with proper formatting\n",
    "    if report_file:\n",
    "        if level == \"header\":\n",
    "            report_file.write(f\"# {message}\\n\\n\")\n",
    "        elif level == \"section\":\n",
    "            report_file.write(f\"## {message}\\n\\n\")\n",
    "        elif level == \"subsection\":\n",
    "            report_file.write(f\"### {message}\\n\\n\")\n",
    "        else:  # info level\n",
    "            report_file.write(f\"{message}\\n\\n\")\n",
    "    \n",
    "    return message\n",
    "\n",
    "# Load the SVR hyperparameter benchmark data\n",
    "pkl_path = f\"{path_loader.get_data_path()}data/results/{folder_name}/svr_hyperparameter_benchmark_{exp_id}.pkl\"\n",
    "if not os.path.exists(pkl_path):\n",
    "    raise FileNotFoundError(f\"SVR hyperparameter benchmark pickle not found: {pkl_path}\")\n",
    "\n",
    "df_benchmark = pd.read_pickle(pkl_path)\n",
    "save_and_print(f\"Loaded SVR hyperparameter benchmark with shape: {df_benchmark.shape}\", print_report_file, level=\"section\")\n",
    "\n",
    "# Display first rows\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(df_benchmark.head())\n",
    "except Exception:\n",
    "    save_and_print(df_benchmark.head().to_string(), print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427c308",
   "metadata": {},
   "source": [
    "## SVR Data Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse condition column to extract SVR hyperparameters correctly\n",
    "def parse_svr_condition_column(df_benchmark):\n",
    "    \"\"\"Parse the condition column to extract SVR hyperparameters correctly\"\"\"\n",
    "    \n",
    "    save_and_print(\"## Parsing SVR Condition Column\", print_report_file, level=\"section\")\n",
    "    save_and_print(\"Parsing condition column to extract SVR kernel, C, gamma, degree, k-value, and method\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Create new columns based on condition parsing\n",
    "    parsed_data = []\n",
    "    \n",
    "    for idx, row in df_benchmark.iterrows():\n",
    "        condition = row['condition']\n",
    "        \n",
    "        # Parse the SVR condition format: SVR_{kernel}_C{value}_{gamma}_{degree}_k{value}_{method}\n",
    "        # Example: \"SVR_linear_C1_gammaScale_deg3_k100_mrmr_network_d3\"\n",
    "        parts = condition.split('_')\n",
    "        \n",
    "        # Extract SVR hyperparameters\n",
    "        if len(parts) >= 7:\n",
    "            svr_kernel = parts[1]\n",
    "            svr_C = float(parts[2].replace('C', ''))\n",
    "            svr_gamma = parts[3]\n",
    "            svr_degree = int(parts[4].replace('deg', '').replace('default', '3'))\n",
    "            k_value = int(parts[5].replace('k', ''))\n",
    "            method = '_'.join(parts[6:])\n",
    "        else:\n",
    "            # Fallback parsing for unexpected formats\n",
    "            save_and_print(f\"Warning: Unexpected condition format: {condition}\", print_report_file, level=\"info\")\n",
    "            svr_kernel = 'unknown'\n",
    "            svr_C = 1.0\n",
    "            svr_gamma = 'scale'\n",
    "            svr_degree = 3\n",
    "            k_value = 100\n",
    "            method = 'unknown'\n",
    "        \n",
    "        parsed_data.append({\n",
    "            'condition': condition,\n",
    "            'svr_kernel': svr_kernel,\n",
    "            'svr_C': svr_C,\n",
    "            'svr_gamma': svr_gamma,\n",
    "            'svr_degree': svr_degree,\n",
    "            'k_value': k_value,\n",
    "            'method': method\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame with parsed values\n",
    "    parsed_df = pd.DataFrame(parsed_data)\n",
    "    \n",
    "    # Update the dataframe with parsed values\n",
    "    df_benchmark['svr_kernel'] = parsed_df['svr_kernel']\n",
    "    df_benchmark['svr_C'] = parsed_df['svr_C']\n",
    "    df_benchmark['svr_gamma'] = parsed_df['svr_gamma']\n",
    "    df_benchmark['svr_degree'] = parsed_df['svr_degree']\n",
    "    df_benchmark['k_value'] = parsed_df['k_value']\n",
    "    df_benchmark['method'] = parsed_df['method']\n",
    "    \n",
    "    save_and_print(\"Dataframe columns updated with correctly parsed SVR hyperparameters\", print_report_file, level=\"info\")\n",
    "    \n",
    "    # Show unique values after parsing\n",
    "    save_and_print(\"### Unique SVR Hyperparameter Values After Parsing\", print_report_file, level=\"subsection\")\n",
    "    save_and_print(f\"Kernels: {df_benchmark['svr_kernel'].unique()}\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"C values: {sorted(df_benchmark['svr_C'].unique())}\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"Gamma values: {df_benchmark['svr_gamma'].unique()}\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"Degree values: {sorted(df_benchmark['svr_degree'].unique())}\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"K-values: {sorted(df_benchmark['k_value'].unique())}\", print_report_file, level=\"info\")\n",
    "    save_and_print(f\"Methods: {df_benchmark['method'].unique()}\", print_report_file, level=\"info\")\n",
    "    \n",
    "    return df_benchmark\n",
    "\n",
    "# Apply the parsing fix\n",
    "df_benchmark = parse_svr_condition_column(df_benchmark)\n",
    "\n",
    "# Display first rows after parsing\n",
    "try:\n",
    "    display(df_benchmark.head())\n",
    "except Exception:\n",
    "    save_and_print(df_benchmark.head().to_string(), print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f167cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically detect available SVR configurations\n",
    "kernels = df_benchmark['svr_kernel'].unique().tolist()\n",
    "c_values = sorted(df_benchmark['svr_C'].unique())\n",
    "gamma_values = df_benchmark['svr_gamma'].unique().tolist()\n",
    "degree_values = sorted(df_benchmark['svr_degree'].unique())\n",
    "k_values = sorted(df_benchmark['k_value'].unique())\n",
    "methods = df_benchmark['method'].unique().tolist()\n",
    "\n",
    "save_and_print(\"### SVR Configuration Summary\", print_report_file, level=\"subsection\")\n",
    "save_and_print(f\"Number of kernel types: {len(kernels)}\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"Kernels: {kernels}\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"C values: {c_values}\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"Gamma values: {gamma_values}\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"Degree values: {degree_values}\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"K-values: {k_values}\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"Methods: {methods}\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"Total SVR configurations: {len(df_benchmark)}\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define publication-quality font sizes with optimized spacing and layout\n",
    "publication_font_sizes = {\n",
    "    'title': 16, 'axis_label': 14, 'tick': 12, \n",
    "    'value': 10, 'legend': 10, 'annotation': 9\n",
    "}\n",
    "\n",
    "# Create SVR configuration labels for better readability\n",
    "kernel_labels = {\n",
    "    'linear': 'Linear',\n",
    "    'rbf': 'RBF',\n",
    "    'poly': 'Polynomial',\n",
    "    'sigmoid': 'Sigmoid'\n",
    "}\n",
    "\n",
    "# Create gamma labels\n",
    "gamma_labels = {\n",
    "    'scale': 'Scale',\n",
    "    'auto': 'Auto',\n",
    "    'gamma0.1': 'γ=0.1',\n",
    "    'gamma1': 'γ=1'\n",
    "}\n",
    "\n",
    "# Create method labels\n",
    "method_labels = {\n",
    "    'mrmr_network_d3': 'MRMR+Network (d3)'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8dea66",
   "metadata": {},
   "source": [
    "## SVR Hyperparameter Performance Comparison Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Centralized color and marker mapping system for consistent visualization\n",
    "def get_consistent_kernel_color_mapping(kernels):\n",
    "    \"\"\"Create consistent color mapping for kernel types across all plots\"\"\"\n",
    "    # Standard color palette for kernel types\n",
    "    kernel_colors = {\n",
    "        'linear': '#1f77b4',  # Blue\n",
    "        'rbf': '#ff7f0e',     # Orange\n",
    "        'poly': '#2ca02c',    # Green\n",
    "        'sigmoid': '#d62728'  # Red\n",
    "    }\n",
    "    \n",
    "    extended_palette = sns.color_palette(\"husl\", max(8, len(kernels)))\n",
    "    \n",
    "    color_mapping = {}\n",
    "    for i, kernel in enumerate(kernels):\n",
    "        if kernel in kernel_colors:\n",
    "            color_mapping[kernel] = kernel_colors[kernel]\n",
    "        else:\n",
    "            color_mapping[kernel] = extended_palette[i % len(extended_palette)]\n",
    "    \n",
    "    return color_mapping\n",
    "\n",
    "def get_consistent_kernel_marker_mapping(kernels):\n",
    "    \"\"\"Create consistent marker mapping for kernel types across all plots\"\"\"\n",
    "    base_markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'h', 'H', '+', 'x', 'd']\n",
    "    \n",
    "    marker_mapping = {}\n",
    "    for i, kernel in enumerate(kernels):\n",
    "        marker_mapping[kernel] = base_markers[i % len(base_markers)]\n",
    "    \n",
    "    return marker_mapping\n",
    "\n",
    "# Generate consistent color and marker mappings based on available kernels\n",
    "kernel_color_mapping = get_consistent_kernel_color_mapping(kernels)\n",
    "kernel_marker_mapping = get_consistent_kernel_marker_mapping(kernels)\n",
    "\n",
    "# Create palette list for seaborn in the correct order\n",
    "kernel_palette = [kernel_color_mapping[kernel] for kernel in kernels]\n",
    "\n",
    "# Define consistent R² range for all performance plots\n",
    "R2_RANGE = (-0.1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696bfc7",
   "metadata": {},
   "source": [
    "### Figure 1: SVR Kernel Type Performance Comparison (Box Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebecfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication-quality box plot comparing kernel types across all configurations\n",
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.rcParams['font.family'] = 'sans'\n",
    "plt.rcParams['font.size'] = publication_font_sizes['tick']\n",
    "plt.rcParams['axes.linewidth'] = 1.2\n",
    "\n",
    "sns.boxplot(data=df_benchmark, x='svr_kernel', y='model_performance', \n",
    "            order=kernels,\n",
    "            palette=kernel_palette, width=0.5, fliersize=2)\n",
    "plt.title('SVR Kernel Type Performance Comparison (All Configurations)', \n",
    "          fontsize=publication_font_sizes['title'], fontweight='bold', pad=15)\n",
    "plt.xlabel('SVR Kernel Type', fontsize=publication_font_sizes['axis_label'], fontweight='bold')\n",
    "plt.ylabel('R² Score', fontsize=publication_font_sizes['axis_label'], fontweight='bold')\n",
    "plt.xticks(ticks=range(len(kernels)), \n",
    "           labels=[kernel_labels[k] for k in kernels],\n",
    "           rotation=45, fontsize=publication_font_sizes['tick'])\n",
    "plt.yticks(fontsize=publication_font_sizes['tick'])\n",
    "plt.ylim(R2_RANGE)  # Set consistent R² range\n",
    "plt.grid(axis='y', alpha=0.2, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_save_path}svr_kernel_comparison_boxplot_{exp_id}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "save_and_print(\"Created SVR kernel type comparison box plot\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a63fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive statistical summary for kernel types\n",
    "kernel_summary_table = df_benchmark.groupby('svr_kernel')['model_performance'].agg([\n",
    "    ('count', 'count'),\n",
    "    ('mean', 'mean'),\n",
    "    ('std', 'std'),\n",
    "    ('min', 'min'),\n",
    "    ('25%', lambda x: x.quantile(0.25)),\n",
    "    ('median', 'median'),\n",
    "    ('75%', lambda x: x.quantile(0.75)),\n",
    "    ('max', 'max')\n",
    "]).round(4)\n",
    "\n",
    "save_and_print(\"Performance Statistics by SVR Kernel Type:\", print_report_file, level=\"section\")\n",
    "save_and_print(kernel_summary_table.to_string(), print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f348b",
   "metadata": {},
   "source": [
    "### Figure 3: C Parameter Sensitivity Analysis (Line Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a03597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean performance for each kernel at each C value\n",
    "c_performance_stats = df_benchmark.groupby(['svr_kernel', 'svr_C'])['model_performance'].agg(['mean', 'std', 'count']).reset_index()\n",
    "\n",
    "# Calculate 95% confidence intervals (assuming normal distribution)\n",
    "c_performance_stats['ci_lower'] = c_performance_stats['mean'] - 1.96 * c_performance_stats['std'] / np.sqrt(c_performance_stats['count'])\n",
    "c_performance_stats['ci_upper'] = c_performance_stats['mean'] + 1.96 * c_performance_stats['std'] / np.sqrt(c_performance_stats['count'])\n",
    "\n",
    "# Create C parameter sensitivity line plot\n",
    "plt.figure(figsize=(12, 8), dpi=300)\n",
    "plt.rcParams['font.family'] = 'sans'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.linewidth'] = 1.2\n",
    "\n",
    "# Plot each kernel's sensitivity to C parameter\n",
    "for kernel in kernels:\n",
    "    kernel_data = c_performance_stats[c_performance_stats['svr_kernel'] == kernel]\n",
    "    \n",
    "    if len(kernel_data) > 0:\n",
    "        # Sort by C value for proper line plotting\n",
    "        kernel_data = kernel_data.sort_values('svr_C')\n",
    "        \n",
    "        # Plot line with error bars (95% CI)\n",
    "        plt.plot(kernel_data['svr_C'], kernel_data['mean'], \n",
    "                marker=kernel_marker_mapping[kernel], \n",
    "                color=kernel_color_mapping[kernel],\n",
    "                linewidth=2, markersize=8, label=kernel_labels[kernel])\n",
    "        \n",
    "        # Add confidence interval shading\n",
    "        plt.fill_between(kernel_data['svr_C'], \n",
    "                        kernel_data['ci_lower'], kernel_data['ci_upper'],\n",
    "                        color=kernel_color_mapping[kernel], alpha=0.2)\n",
    "\n",
    "plt.title('SVR Performance Sensitivity to C Parameter (All Kernels)', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('C Parameter Value (log scale)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Mean R² Score ± 95% CI', fontsize=14, fontweight='bold')\n",
    "plt.xscale('log')  # Log scale for C parameter\n",
    "plt.xticks(c_values, [str(c) for c in c_values], fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(R2_RANGE)  # Set consistent R² range\n",
    "plt.legend(title='Kernel Type', fontsize=12, framealpha=0.9)\n",
    "plt.grid(True, alpha=0.2, linestyle='--')\n",
    "\n",
    "# Add annotations for optimal C values per kernel\n",
    "for kernel in kernels:\n",
    "    kernel_data = c_performance_stats[c_performance_stats['svr_kernel'] == kernel]\n",
    "    if len(kernel_data) > 0:\n",
    "        best_c_idx = kernel_data['mean'].idxmax()\n",
    "        best_c = kernel_data.loc[best_c_idx, 'svr_C']\n",
    "        best_perf = kernel_data.loc[best_c_idx, 'mean']\n",
    "        \n",
    "        plt.annotate(f'Optimal C={best_c}', \n",
    "                    xy=(best_c, best_perf), \n",
    "                    xytext=(10, 10), textcoords='offset points',\n",
    "                    fontsize=10, fontweight='bold',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\", alpha=0.8),\n",
    "                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_save_path}svr_c_parameter_sensitivity_{exp_id}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "save_and_print(\"Created C parameter sensitivity line plot\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c2742",
   "metadata": {},
   "source": [
    "### Figure 4: RBF Kernel Gamma vs C Parameter (Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ff300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for RBF kernel (where gamma is most relevant)\n",
    "rbf_data = df_benchmark[df_benchmark['svr_kernel'] == 'rbf']\n",
    "\n",
    "if len(rbf_data) > 0:\n",
    "    # Calculate gamma performance statistics\n",
    "    gamma_performance_stats = rbf_data.groupby(['svr_gamma', 'svr_C'])['model_performance'].agg(['mean', 'std', 'count']).reset_index()\n",
    "    \n",
    "    # Create heatmap for gamma vs C performance\n",
    "    plt.figure(figsize=(10, 6), dpi=300)\n",
    "    plt.rcParams['font.family'] = 'sans'\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['axes.linewidth'] = 1.2\n",
    "    \n",
    "    # Pivot data for heatmap\n",
    "    heatmap_data = gamma_performance_stats.pivot(index='svr_gamma', columns='svr_C', values='mean')\n",
    "    \n",
    "    # Create heatmap with proper R² scaling\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd', \n",
    "                vmin=R2_RANGE[0], vmax=R2_RANGE[1],  # Set consistent R² range\n",
    "                cbar_kws={'label': 'R² Score'}, linewidths=0.5)\n",
    "    \n",
    "    plt.title('RBF Kernel: Performance by Gamma and C Parameters', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('C Parameter Value', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Gamma Parameter', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{file_save_path}svr_gamma_c_heatmap_{exp_id}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    save_and_print(\"Created gamma vs C parameter heatmap for RBF kernel\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddafaf7",
   "metadata": {},
   "source": [
    "### Figure 5: Feature Set Size Impact (k=100 vs k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance statistics for each kernel at each k-value\n",
    "k_performance_stats = df_benchmark.groupby(['svr_kernel', 'k_value'])['model_performance'].agg(['mean', 'std', 'count']).reset_index()\n",
    "\n",
    "# Calculate 95% confidence intervals\n",
    "k_performance_stats['ci_lower'] = k_performance_stats['mean'] - 1.96 * k_performance_stats['std'] / np.sqrt(k_performance_stats['count'])\n",
    "k_performance_stats['ci_upper'] = k_performance_stats['mean'] + 1.96 * k_performance_stats['std'] / np.sqrt(k_performance_stats['count'])\n",
    "\n",
    "# Create grouped bar chart for k-value comparison\n",
    "plt.figure(figsize=(14, 8), dpi=300)\n",
    "plt.rcParams['font.family'] = 'sans'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.linewidth'] = 1.2\n",
    "\n",
    "bar_width = 0.35\n",
    "x_pos = np.arange(len(kernels))\n",
    "\n",
    "# Create bars for k=100 and k=500 with consistent colors\n",
    "for i, k_value in enumerate(k_values):\n",
    "    k_data = k_performance_stats[k_performance_stats['k_value'] == k_value]\n",
    "    \n",
    "    # Ensure the data is in the same order as kernels\n",
    "    k_means = []\n",
    "    k_cis = []\n",
    "    for kernel in kernels:\n",
    "        kernel_k_data = k_data[k_data['svr_kernel'] == kernel]\n",
    "        if len(kernel_k_data) > 0:\n",
    "            k_means.append(kernel_k_data['mean'].iloc[0])\n",
    "            k_cis.append((kernel_k_data['mean'].iloc[0] - kernel_k_data['ci_lower'].iloc[0], \n",
    "                         kernel_k_data['ci_upper'].iloc[0] - kernel_k_data['mean'].iloc[0]))\n",
    "        else:\n",
    "            k_means.append(0)\n",
    "            k_cis.append((0, 0))\n",
    "    \n",
    "    # Use consistent colors: blue for k=100, orange for k=500\n",
    "    color = '#1f77b4' if k_value == 100 else '#ff7f0e'\n",
    "    bars = plt.bar(x_pos + i * bar_width, k_means, bar_width,\n",
    "                   color=color, alpha=0.8, edgecolor='black', linewidth=1,\n",
    "                   label=f'k={k_value}')\n",
    "    \n",
    "    # Add 95% confidence intervals with subtle styling\n",
    "    plt.errorbar(x_pos + i * bar_width, k_means, \n",
    "                 yerr=np.array(k_cis).T, fmt='none', ecolor='gray', \n",
    "                 elinewidth=1, capsize=3, capthick=1, alpha=0.7)\n",
    "\n",
    "plt.title('SVR Performance: k=100 vs k=500 Features (by Kernel Type)', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('SVR Kernel Type', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Mean R² Score ± 95% CI', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x_pos + bar_width/2, [kernel_labels[k] for k in kernels], rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(R2_RANGE)  # Set consistent R² range\n",
    "plt.legend(title='Number of Features', fontsize=12, framealpha=0.9)\n",
    "plt.grid(axis='y', alpha=0.2, linestyle='--')\n",
    "\n",
    "# Add value labels with improved placement (only for positive values)\n",
    "for i, kernel in enumerate(kernels):\n",
    "    for j, k_value in enumerate(k_values):\n",
    "        k_data = k_performance_stats[k_performance_stats['k_value'] == k_value]\n",
    "        kernel_k_data = k_data[k_data['svr_kernel'] == kernel]\n",
    "        if len(kernel_k_data) > 0:\n",
    "            height = kernel_k_data['mean'].iloc[0]\n",
    "            if height >= 0:  # Only label positive values to reduce clutter\n",
    "                plt.text(x_pos[i] + j * bar_width, height + 0.01,\n",
    "                         f'{height:.2f}', ha='center', va='bottom', \n",
    "                         fontsize=9, fontweight='bold',\n",
    "                         bbox=dict(boxstyle=\"round,pad=0.1\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_save_path}svr_k_value_comparison_{exp_id}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "save_and_print(\"Created feature set size impact comparison\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f67e6",
   "metadata": {},
   "source": [
    "### Figure 6: Small Multiples for Individual Kernel Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED VERSION 6: Advanced Heatmap Matrix Visualization\n",
    "save_and_print(\"### ENHANCED VERSION 6: Advanced Heatmap Matrix Visualization\", print_report_file, level=\"subsection\")\n",
    "\n",
    "# Create heatmap for C vs k_value across all kernels\n",
    "plt.figure(figsize=(9, 5), dpi=300)\n",
    "plt.rcParams['font.family'] = 'sans'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.linewidth'] = 1.2\n",
    "\n",
    "# Calculate mean performance for each combination\n",
    "heatmap_data = df_benchmark.pivot_table(index='svr_C', \n",
    "                                       columns=['k_value', 'svr_kernel'], \n",
    "                                       values='model_performance', \n",
    "                                       aggfunc='mean')\n",
    "\n",
    "# Create the heatmap with proper R² color scaling\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".3f\", cmap=\"RdYlBu\", \n",
    "            center=0, vmin=-0.1, vmax=0.5,  # Proper R² scaling\n",
    "            cbar_kws={'label': 'R² Score', 'shrink': 0.8},\n",
    "            linewidths=0.5, annot_kws={'size': 8})\n",
    "\n",
    "plt.title('SVR Performance Matrix: C vs k_value across Kernels', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Kernel Type and Feature Set Size (k)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('C Parameter Value', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_save_path}svr_heatmap_matrix_{exp_id}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "save_and_print(\"Created advanced heatmap matrix visualization\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6807f80",
   "metadata": {},
   "source": [
    "## SVR Timing and Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze computational time metrics for SVR configurations\n",
    "save_and_print(\"## SVR Computational Time Analysis\", print_report_file, level=\"section\")\n",
    "\n",
    "# Calculate time statistics for each kernel type\n",
    "time_stats = df_benchmark.groupby('svr_kernel')[['feature_selection_time', 'model_training_time', 'prediction_time']].agg(['mean', 'std', 'count']).round(6)\n",
    "\n",
    "save_and_print(\"Time Statistics by SVR Kernel Type:\", print_report_file, level=\"subsection\")\n",
    "save_and_print(time_stats.to_string(), print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05fa01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time comparison visualization for SVR kernels\n",
    "plt.figure(figsize=(14, 8), dpi=300)\n",
    "plt.rcParams['font.family'] = 'sans'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.linewidth'] = 1.2\n",
    "\n",
    "# Calculate mean times for each kernel\n",
    "time_means = df_benchmark.groupby('svr_kernel')[['feature_selection_time', 'model_training_time', 'prediction_time']].mean()\n",
    "\n",
    "# Create stacked bar plot for time components\n",
    "bar_width = 0.6\n",
    "x_pos = np.arange(len(kernels))\n",
    "\n",
    "# Plot each time component\n",
    "feature_selection_times = [time_means.loc[kernel, 'feature_selection_time'] for kernel in kernels]\n",
    "training_times = [time_means.loc[kernel, 'model_training_time'] for kernel in kernels]\n",
    "prediction_times = [time_means.loc[kernel, 'prediction_time'] for kernel in kernels]\n",
    "\n",
    "# Create stacked bars\n",
    "plt.bar(x_pos, feature_selection_times, bar_width, label='Feature Selection', \n",
    "        color='lightblue', edgecolor='black', linewidth=1)\n",
    "plt.bar(x_pos, training_times, bar_width, bottom=feature_selection_times, \n",
    "        label='Model Training', color='lightgreen', edgecolor='black', linewidth=1)\n",
    "plt.bar(x_pos, prediction_times, bar_width, \n",
    "        bottom=[feature_selection_times[i] + training_times[i] for i in range(len(kernels))],\n",
    "        label='Prediction', color='lightcoral', edgecolor='black', linewidth=1)\n",
    "\n",
    "plt.title('SVR Computational Time Breakdown by Kernel Type', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('SVR Kernel Type', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Time (seconds)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x_pos, [kernel_labels[k] for k in kernels], rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(title='Time Component', fontsize=12, framealpha=0.9)\n",
    "plt.grid(axis='y', alpha=0.2, linestyle='--')\n",
    "\n",
    "# Add total time labels\n",
    "total_times = [feature_selection_times[i] + training_times[i] + prediction_times[i] for i in range(len(kernels))]\n",
    "for i, total_time in enumerate(total_times):\n",
    "    plt.text(x_pos[i], total_time + 0.01, f'{total_time:.3f}s', \n",
    "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_save_path}svr_time_breakdown_{exp_id}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "save_and_print(\"Created SVR computational time breakdown visualization\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc984cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create swarm plot for individual configuration visualization\n",
    "plt.figure(figsize=(12, 8), dpi=300)\n",
    "plt.rcParams['font.family'] = 'sans'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.linewidth'] = 1.2\n",
    "\n",
    "# Create swarm plot with proper R² scaling\n",
    "sns.swarmplot(data=df_benchmark, x='svr_kernel', y='model_performance', \n",
    "              order=kernels, palette=kernel_palette, size=4, alpha=0.7)\n",
    "\n",
    "plt.title('Individual SVR Configuration Performance (Swarm Plot)', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('SVR Kernel Type', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('R² Score', fontsize=14, fontweight='bold')\n",
    "plt.xticks(ticks=range(len(kernels)), \n",
    "           labels=[kernel_labels[k] for k in kernels],\n",
    "           rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Set proper R² scale\n",
    "plt.ylim(-0.1, \n",
    "         min(1, df_benchmark['model_performance'].max() + 0.1))\n",
    "\n",
    "plt.grid(axis='y', alpha=0.2, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_save_path}svr_swarm_plot_{exp_id}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "save_and_print(\"Created swarm plot visualization\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f196af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis and significance testing for SVR kernels\n",
    "save_and_print(\"## SVR Statistical Analysis and Significance Testing\", print_report_file, level=\"section\")\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Perform pairwise kernel comparisons\n",
    "kernel_comparisons = []\n",
    "for i, kernel1 in enumerate(kernels):\n",
    "    for j, kernel2 in enumerate(kernels):\n",
    "        if i < j:\n",
    "            kernel1_data = df_benchmark[df_benchmark['svr_kernel'] == kernel1]['model_performance']\n",
    "            kernel2_data = df_benchmark[df_benchmark['svr_kernel'] == kernel2]['model_performance']\n",
    "            \n",
    "            if len(kernel1_data) > 0 and len(kernel2_data) > 0:\n",
    "                t_stat, p_value = ttest_ind(kernel1_data, kernel2_data, equal_var=False)\n",
    "                mean_diff = kernel1_data.mean() - kernel2_data.mean()\n",
    "                \n",
    "                kernel_comparisons.append({\n",
    "                    'kernel1': kernel1,\n",
    "                    'kernel2': kernel2,\n",
    "                    'kernel1_label': kernel_labels[kernel1],\n",
    "                    'kernel2_label': kernel_labels[kernel2],\n",
    "                    'mean_difference': mean_diff,\n",
    "                    't_statistic': t_stat,\n",
    "                    'p_value': p_value,\n",
    "                    'significant': p_value < 0.05\n",
    "                })\n",
    "\n",
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame(kernel_comparisons)\n",
    "save_and_print(\"Pairwise SVR Kernel Comparisons (Performance):\", print_report_file, level=\"subsection\")\n",
    "save_and_print(comparison_df.round(4).to_string(index=False), print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85be5e0",
   "metadata": {},
   "source": [
    "## SVR Best Configuration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f92367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best performing SVR configuration for each k-value\n",
    "save_and_print(\"## Best Performing SVR Configurations by k-value\", print_report_file, level=\"section\")\n",
    "\n",
    "for k_value in k_values:\n",
    "    k_data = df_benchmark[df_benchmark['k_value'] == k_value]\n",
    "    if len(k_data) > 0:\n",
    "        best_config_row = k_data.loc[k_data['model_performance'].idxmax()]\n",
    "        best_kernel = best_config_row['svr_kernel']\n",
    "        best_c = best_config_row['svr_C']\n",
    "        best_gamma = best_config_row['svr_gamma']\n",
    "        best_degree = best_config_row['svr_degree']\n",
    "        best_performance = best_config_row['model_performance']\n",
    "        \n",
    "        save_and_print(f\"k={k_value}:\", print_report_file, level=\"subsection\")\n",
    "        save_and_print(f\"  Best configuration: {kernel_labels[best_kernel]} (C={best_c}, γ={best_gamma}, deg={best_degree})\", print_report_file, level=\"info\")\n",
    "        save_and_print(f\"  Best performance (R²): {best_performance:.4f}\", print_report_file, level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ad25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive SVR summary report\n",
    "save_and_print(\"## SVR Comprehensive Summary\", print_report_file, level=\"section\")\n",
    "\n",
    "# Overall best SVR configuration\n",
    "overall_best_row = df_benchmark.loc[df_benchmark['model_performance'].idxmax()]\n",
    "overall_best_kernel = overall_best_row['svr_kernel']\n",
    "overall_best_c = overall_best_row['svr_C']\n",
    "overall_best_gamma = overall_best_row['svr_gamma']\n",
    "overall_best_degree = overall_best_row['svr_degree']\n",
    "overall_best_performance = overall_best_row['model_performance']\n",
    "overall_best_k = overall_best_row['k_value']\n",
    "\n",
    "save_and_print(\"### Overall Best SVR Configuration\", print_report_file, level=\"subsection\")\n",
    "save_and_print(f\"Best overall configuration: {kernel_labels[overall_best_kernel]} (C={overall_best_c}, γ={overall_best_gamma}, deg={overall_best_degree})\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"Best overall performance (R²): {overall_best_performance:.4f}\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"At k-value: {overall_best_k}\", print_report_file, level=\"info\")\n",
    "\n",
    "# Performance range\n",
    "performance_range = df_benchmark['model_performance'].max() - df_benchmark['model_performance'].min()\n",
    "save_and_print(f\"Performance range across all SVR configurations: {performance_range:.4f}\", print_report_file, level=\"info\")\n",
    "\n",
    "# Time efficiency analysis\n",
    "fastest_kernel_time = df_benchmark.groupby('svr_kernel')['model_training_time'].mean().idxmin()\n",
    "fastest_time = df_benchmark.groupby('svr_kernel')['model_training_time'].mean().min()\n",
    "save_and_print(f\"Fastest training kernel: {kernel_labels[fastest_kernel_time]} ({fastest_time:.3f}s)\", print_report_file, level=\"info\")\n",
    "\n",
    "# Key findings summary\n",
    "save_and_print(\"### Key Findings Summary\", print_report_file, level=\"subsection\")\n",
    "save_and_print(\"1. Kernel type performance ranking (based on mean R²):\", print_report_file, level=\"info\")\n",
    "kernel_ranking = df_benchmark.groupby('svr_kernel')['model_performance'].mean().sort_values(ascending=False)\n",
    "for i, (kernel, perf) in enumerate(kernel_ranking.items(), 1):\n",
    "    save_and_print(f\"   {i}. {kernel_labels[kernel]}: {perf:.4f}\", print_report_file, level=\"info\")\n",
    "\n",
    "save_and_print(\"2. Optimal C parameter ranges by kernel:\", print_report_file, level=\"info\")\n",
    "for kernel in kernels:\n",
    "    kernel_c_data = c_performance_stats[c_performance_stats['svr_kernel'] == kernel]\n",
    "    if len(kernel_c_data) > 0:\n",
    "        best_c_idx = kernel_c_data['mean'].idxmax()\n",
    "        best_c = kernel_c_data.loc[best_c_idx, 'svr_C']\n",
    "        save_and_print(f\"   {kernel_labels[kernel]}: Optimal C ≈ {best_c}\", print_report_file, level=\"info\")\n",
    "\n",
    "save_and_print(\"3. Feature set size impact:\", print_report_file, level=\"info\")\n",
    "k_impact = df_benchmark.groupby('k_value')['model_performance'].mean()\n",
    "for k_val, perf in k_impact.items():\n",
    "    save_and_print(f\"   k={k_val}: Mean R² = {perf:.4f}\", print_report_file, level=\"info\")\n",
    "\n",
    "print(f\"Print report saved to: {print_report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate enhanced summary report with all new visualizations\n",
    "save_and_print(\"## Enhanced Visualization Summary\", print_report_file, level=\"section\")\n",
    "\n",
    "save_and_print(\"### New Enhanced Visualizations Created:\", print_report_file, level=\"subsection\")\n",
    "save_and_print(\"1. **Multi-dimensional Faceted Plots**: Shows kernel × C × k_value interactions with proper R² scaling\", print_report_file, level=\"info\")\n",
    "save_and_print(\"2. **Advanced Heatmap Matrix**: C vs k_value across all kernels with proper R² color scaling\", print_report_file, level=\"info\")\n",
    "save_and_print(\"3. **Configuration Ranking Visualization**: Ranks all SVR configurations by performance with kernel and C parameter visualization\", print_report_file, level=\"info\")\n",
    "save_and_print(\"4. **Enhanced Statistical Visualizations**: Violin plots and swarm plots for better distribution analysis\", print_report_file, level=\"info\")\n",
    "save_and_print(\"5. **Improved Small Multiples**: Individual kernel analysis with proper R² range handling\", print_report_file, level=\"info\")\n",
    "\n",
    "save_and_print(\"### Key Technical Improvements:\", print_report_file, level=\"subsection\")\n",
    "save_and_print(\"- **Proper R² Scaling**: All visualizations maintain 0-1 range while accommodating negative values\", print_report_file, level=\"info\")\n",
    "save_and_print(\"- **Consistent Color Mapping**: Kernel types use consistent colors across all plots\", print_report_file, level=\"info\")\n",
    "save_and_print(\"- **Publication Quality**: High-resolution (300 DPI) images with professional styling\", print_report_file, level=\"info\")\n",
    "save_and_print(\"- **Multi-dimensional Analysis**: Complex hyperparameter interactions visualized clearly\", print_report_file, level=\"info\")\n",
    "\n",
    "save_and_print(\"### Files Generated:\", print_report_file, level=\"subsection\")\n",
    "save_and_print(f\"- svr_faceted_interactions_{exp_id}.png: Multi-dimensional kernel × C × k_value interactions\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"- svr_heatmap_matrix_{exp_id}.png: Advanced heatmap matrix visualization\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"- svr_configuration_ranking_{exp_id}.png: Configuration performance ranking\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"- svr_violin_plot_{exp_id}.png: Enhanced distribution visualization\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"- svr_swarm_plot_{exp_id}.png: Individual configuration visualization\", print_report_file, level=\"info\")\n",
    "save_and_print(f\"- svr_hyperparameter_visualisation_report_{exp_id}.md: Comprehensive analysis report\", print_report_file, level=\"info\")\n",
    "\n",
    "print(f\"Print report saved to: {print_report_path}\")\n",
    "print(\"Enhanced SVR hyperparameter benchmarking visualization completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "ode-biomarker-project",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

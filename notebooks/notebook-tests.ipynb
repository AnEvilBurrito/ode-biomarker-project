{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader\n",
    "\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "\n",
    "### Load data\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# import GDSC2 drug response data using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/drug-response/GDSC2/cache_gdsc2.pkl', 'rb') as f:\n",
    "    gdsc2 = pickle.load(f)\n",
    "    gdsc2_info = pickle.load(f)\n",
    "    \n",
    "# import CCLE gene expression data using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/gene-expression/CCLE_Public_22Q2/ccle_expression.pkl', 'rb') as f:\n",
    "    gene_entrez = pickle.load(f)\n",
    "    ccle = pickle.load(f)\n",
    "\n",
    "# import CCLE sample info data using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/gene-expression/CCLE_Public_22Q2/ccle_sample_info.pkl', 'rb') as f:\n",
    "    ccle_sample_info = pickle.load(f)\n",
    "\n",
    "# import STRING database using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/protein-interaction/STRING/string_df.pkl', 'rb') as f:\n",
    "    string_df = pickle.load(f)\n",
    "    string_df_info = pickle.load(f)\n",
    "    string_df_alias = pickle.load(f)\n",
    "\n",
    "\n",
    "# import proteomic expression\n",
    "with open(f'{path_loader.get_data_path()}data/proteomic-expression/goncalves-2022-cell/goncalve_proteome_fillna_processed.pkl', 'rb') as f:\n",
    "    joined_full_protein_matrix = pickle.load(f)\n",
    "    joined_sin_peptile_exclusion_matrix = pickle.load(f)\n",
    "\n",
    "# import STRING database using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/protein-interaction/STRING/string_df.pkl', 'rb') as f:\n",
    "    string_df = pickle.load(f)\n",
    "    string_df_info = pickle.load(f)\n",
    "    string_df_alias = pickle.load(f)\n",
    "\n",
    "# open STRING to goncalves mapping file\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data\\protein-interaction\\STRING\\goncalve_to_string_id_df.pkl', 'rb') as f:\n",
    "    goncalve_to_string_id_df = pickle.load(f)\n",
    "\n",
    "# open the cache for neighbourhood calculations\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/protein-interaction/STRING/palbociclib_nth_degree_neighbours.pkl', 'rb') as f:\n",
    "    nth_degree_neighbours = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolkit Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# loading cell line proteomic expression data\n",
    "\n",
    "cancercell2022 = pd.read_csv('data\\preprocessed\\SY-Processed\\CancerCell2022_PRISM.csv')\n",
    "\n",
    "cancercell2022_dropnan = cancercell2022.dropna(subset=['AUC'])\n",
    "\n",
    "import DataFunctions as dfunc \n",
    "\n",
    "feature_data, label_data = dfunc.create_feature_and_label(cancercell2022_dropnan, label_name='AUC')\n",
    "\n",
    "feature_data_no_row = feature_data.drop(['Row'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import FeatureTransformer\n",
    "from toolkit import impute_by_zero, impute_by_first_quantile, get_network_stat_features, get_random_features\n",
    "\n",
    "F = FeatureTransformer()\n",
    "\n",
    "F.add_transform_function('impute_by_zero', impute_by_zero)\n",
    "F.add_selection_function('random_select', get_random_features, {\"selection_size\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, label_data, random_state=42)\n",
    "\n",
    "# Print the shapes of the new X objects\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n",
    "\n",
    "# Run Feature Transformer \n",
    "\n",
    "selected_features, sel_train, sel_test = F.run(X_train, y_train, X_test)\n",
    "\n",
    "print(selected_features, sel_train.shape, sel_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear variables in juptyer notebook\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create controlled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "\n",
    "# turn X and Y into dataframes\n",
    "X, y = make_regression(n_samples=500, n_features=1000, n_informative=10, random_state=1, shuffle=False)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "# turn columns into strings\n",
    "\n",
    "X.columns = [str(i) for i in range(X.shape[1])]\n",
    "\n",
    "print(f'Original informative columns: {X.columns[:10]}')\n",
    "\n",
    "# shuffle columns around for X\n",
    "\n",
    "X = X.sample(frac=1, axis=1, random_state=0)\n",
    "\n",
    "print(f'Newly shuffled columns: {X.columns[:10]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import mrmr_select_fcq\n",
    "\n",
    "features, scores = mrmr_select_fcq(X, y, K=10,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import enet_select\n",
    "\n",
    "features, scores = enet_select(X, y, 10, max_iter=10000, alpha=0.1, l1_ratio=0.7)\n",
    "\n",
    "print(features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import rf_select\n",
    "\n",
    "features, scores = rf_select(X, y, k=10, n_estimators=100, max_depth=5, n_jobs=-1)\n",
    "\n",
    "print(features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import f_regression_select\n",
    "\n",
    "features, scores = f_regression_select(X, y, k=10)\n",
    "print(features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import relieff_select\n",
    "\n",
    "features, scores = relieff_select(X, y, k=10, n_jobs=4)\n",
    "print(features)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear variables in juptyer notebook\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from toolkit import select_random_features\n",
    "\n",
    "selected_features, selected_X = select_random_features(X, y, 10)\n",
    "\n",
    "print(selected_features, selected_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import transform_impute_by_zero\n",
    "\n",
    "imputed_X, imputed_y = transform_impute_by_zero(X, y)\n",
    "\n",
    "print(imputed_X.shape, imputed_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the Powerkit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing code, for reference ONLY\n",
    "'''\n",
    "\n",
    "# rng = 45\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rng)\n",
    "# get_feature_importance = False\n",
    "# pipeline_comps = pipeline_func(X_train, y_train)\n",
    "# eval_returns = eval_func(X_test, y_test, pipeline_components=pipeline_comps)\n",
    "# # print(eval_returns)\n",
    "\n",
    "# # combine pipeline_comps and eval_returns into a single dictionary\n",
    "\n",
    "# final_returns = {}\n",
    "# final_returns['rng'] = rng\n",
    "# final_returns['condition'] = 'test'\n",
    "# final_returns.update(eval_returns)\n",
    "\n",
    "# if not get_feature_importance:\n",
    "#     final_returns.pop('feature_importance')\n",
    "\n",
    "# # convert final_returns into a dataframe, test if it works for multiple rows\n",
    "\n",
    "# df = pd.DataFrame([final_returns, final_returns])\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# feature_importance = final_returns['feature_importance']\n",
    "\n",
    "# for x,y in zip(feature_importance[0], feature_importance[1]):\n",
    "#     print(f'Feature: {x}, Score: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n",
      "Original informative columns: Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='object')\n",
      "Newly shuffled columns: Index(['993', '859', '298', '553', '672', '971', '27', '231', '306', '706'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n",
    "\n",
    "from toolkit import Powerkit, transform_impute_by_zero, select_random_features, select_preset_features, select_stat_features, f_regression_select, mrmr_select_fcq, hypertune_svr\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# create a Powerkit object\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "\n",
    "# turn X and Y into dataframes\n",
    "X, y = make_regression(n_samples=500, n_features=1000, n_informative=10, random_state=1, shuffle=False)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "# turn columns into strings\n",
    "\n",
    "X.columns = [str(i) for i in range(X.shape[1])]\n",
    "\n",
    "print(f'Original informative columns: {X.columns[:10]}')\n",
    "\n",
    "# shuffle columns around for X\n",
    "\n",
    "X = X.sample(frac=1, axis=1, random_state=0)\n",
    "\n",
    "print(f'Newly shuffled columns: {X.columns[:10]}')\n",
    "\n",
    "\n",
    "def pipeline_func(X_train, y_train, **kwargs):\n",
    "    \n",
    "    X_transformed, y_transformed = transform_impute_by_zero(X_train, y_train)\n",
    "    # selected_features, scores = f_regression_select(X_transformed, y_transformed, k=10)\n",
    "    selected_features, scores = mrmr_select_fcq(X_transformed, y_transformed, K=10, return_index=False)\n",
    "    selected_features, X_selected = select_preset_features(X_transformed, y_transformed, selected_features)\n",
    "    model = SVR()\n",
    "    model.fit(X_selected, y_transformed)\n",
    "    \n",
    "    return {'model': model, 'selected_features': selected_features, 'scores': scores}\n",
    "\n",
    "def eval_func(X_test, y_test, pipeline_components=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    example function to evaluate the performance of a pipeline\n",
    "    inputs\n",
    "        X_test: test set features\n",
    "        y_test: test set labels\n",
    "        pipeline_components: dictionary of pipeline components, e.g. {'model': model, 'selected_features': selected_features, 'scores': scores}\n",
    "    '''\n",
    "    \n",
    "    _, X_selected = select_preset_features(X_test, y_test, pipeline_components['selected_features'])\n",
    "    y_pred = pipeline_components['model'].predict(X_selected)\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # at the end, return a dictionary of all the information you want to return\n",
    "    return {'model_performance': corr, 'p_vals': p_vals, \n",
    "            'feature_importance': (pipeline_components['selected_features'], pipeline_components['scores'])}\n",
    "\n",
    "powerkit = Powerkit(X, y) \n",
    "powerkit.add_condition('test', True, pipeline_func, {}, eval_func, {})\n",
    "rng_list = [i for i in range(24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = powerkit._abstract_run(rng_list, n_jobs=4, verbose=False)\n",
    "df.head()\n",
    "\n",
    "contribution = powerkit.get_mean_contribution(df, 'test', adjust_for_accuracy=True, strict_mean=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_contrib: ['6', '916', '194', '426', '739']\n",
      "current iteration: 12 current_tol: 0.004842, abs_diff: 86887.690934, abs_prev: 17943995.840798, performance: 0.903058\n",
      "current_contrib: ['6', '771', '665', '916', '194']\n",
      "current iteration: 18 current_tol: 0.014347, abs_diff: 257848.457149, abs_prev: 17971669.781099, performance: 0.885644\n",
      "current_contrib: ['6', '771', '665', '916', '194']\n",
      "current iteration: 24 current_tol: 0.006934, abs_diff: 130338.050976, abs_prev: 18798064.740136, performance: 0.879302\n",
      "current_contrib: ['6', '771', '191', '665', '916']\n",
      "current iteration: 30 current_tol: 0.005307, abs_diff: 101065.107893, abs_prev: 19043476.929928, performance: 0.879257\n",
      "current_contrib: ['6', '771', '191', '665', '916']\n",
      "current iteration: 36 current_tol: 0.000431, abs_diff: 8354.880718, abs_prev: 19404558.115029, performance: 0.865812\n",
      "current_contrib: ['6', '771', '191', '665', '916']\n",
      "current iteration: 42 current_tol: 0.000723, abs_diff: 14143.697488, abs_prev: 19571133.102848, performance: 0.887777\n",
      "current_contrib: ['6', '771', '201', '191', '665']\n",
      "current iteration: 48 current_tol: 0.003676, abs_diff: 72253.924649, abs_prev: 19655184.367671, performance: 0.878509\n",
      "current_contrib: ['6', '771', '201', '191', '665']\n",
      "current iteration: 54 current_tol: 0.001166, abs_diff: 23264.162895, abs_prev: 19954659.217264, performance: 0.878160\n",
      "current_contrib: ['6', '201', '771', '191', '665']\n",
      "current iteration: 60 current_tol: 0.007862, abs_diff: 158001.159325, abs_prev: 20096074.224311, performance: 0.896739\n",
      "current_contrib: ['6', '201', '771', '191', '665']\n",
      "current iteration: 66 current_tol: 0.001277, abs_diff: 25511.225282, abs_prev: 19985094.919846, performance: 0.886632\n",
      "current_contrib: ['6', '201', '771', '191', '665']\n",
      "current iteration: 72 current_tol: 0.004980, abs_diff: 100023.940063, abs_prev: 20083405.975958, performance: 0.872049\n",
      "current_contrib: ['6', '201', '771', '191', '665']\n",
      "current iteration: 78 current_tol: 0.004036, abs_diff: 81500.387669, abs_prev: 20191765.283983, performance: 0.889108\n",
      "current_contrib: ['6', '201', '771', '191', '665']\n",
      "current iteration: 84 current_tol: 0.001152, abs_diff: 23290.742118, abs_prev: 20223788.827338, performance: 0.858320\n",
      "current_contrib: ['6', '201', '771', '191', '665']\n",
      "current iteration: 90 current_tol: 0.001195, abs_diff: 24454.229636, abs_prev: 20461382.762539, performance: 0.873772\n",
      "current_contrib: ['6', '201', '771', '191', '665']\n",
      "current iteration: 96 current_tol: 0.000911, abs_diff: 18741.087553, abs_prev: 20581685.285085, performance: 0.876091\n",
      "current_contrib: ['6', '201', '771', '191', '665']\n",
      "current iteration: 102 current_tol: 0.000839, abs_diff: 17413.943307, abs_prev: 20763415.487954, performance: 0.871115\n",
      "Consensus Run: condition test is done in 102 iterations\n",
      "Consensus Run under condition test is NOT converged within 0.0001 relative tolerance\n",
      "Consensus Run under condition test is NOT converged within 0.0001 absolute tolerance\n",
      "WARNING: Consensus Run under condition test is not converged within 100 iterations\n"
     ]
    }
   ],
   "source": [
    "rngs, total_df, meta_df = powerkit.run_until_consensus('test', n_jobs=6, abs_tol=0.0001, rel_tol=0.0001, verbose=True, verbose_level=1, return_meta_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution = powerkit.get_mean_contribution(total_df, 'test', adjust_for_accuracy=True, strict_mean=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchApp Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading SBML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading anthony's sbml model\n",
    "\n",
    "from libsbml import *\n",
    "\n",
    "reader = SBMLReader()\n",
    "\n",
    "document = reader.readSBML(\"data\\export_ECC_Base.xml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = document.getModel()\n",
    "\n",
    "print(f'Document errors: {document.getNumErrors()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of species: {model.getNumSpecies()}')\n",
    "\n",
    "print(f'Number of reactions: {model.getNumReactions()}')\n",
    "\n",
    "print(f'Number of compartments: {model.getNumCompartments()}')\n",
    "\n",
    "print(f'Number of parameters: {model.getNumParameters()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rules: {model.getNumRules()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import roadrunner\n",
    "\n",
    "rr = roadrunner.RoadRunner(\"data\\export_ECC_Base.xml\")\n",
    "\n",
    "print(f'Number of floating species: {len(rr.model.getFloatingSpeciesIds())}')\n",
    "\n",
    "print(f'Number of boundary species: {len(rr.model.getBoundarySpeciesIds())}')\n",
    "\n",
    "print(f'Number of global parameters: {len(rr.model.getGlobalParameterIds())}')\n",
    "\n",
    "print(f'Number of compartments: {len(rr.model.getCompartmentIds())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rr.simulate(0, 10, 100)\n",
    "\n",
    "rr.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{rr.model.getFloatingSpeciesIds()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model[\"init(IRS)\"]\n",
    "\n",
    "# rr.model[\"init(IRS)\"] = 0.5 # for changing initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model.getGlobalParameterIds()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.kc_INSULIN_INSR_INSRpY\n",
    "\n",
    "# rr.kc_INSULIN_INSR_INSRpY = 0.1 # for changing parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model['kc_INSULIN_INSR_INSRpY'] # another method for changing parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model['INSR'] # another method for changing initial condition values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking CCLE data to Anthony's SBML model initial conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing parameters in SBML model to the calibrated set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing dynamic simulation data back to singular vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LanODEApp Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load in core data and libraries'''\n",
    "\n",
    "# libraries used \n",
    "\n",
    "# load CCLE expression data  \n",
    "\n",
    "# load Anthony's model and optimal parameter sets \n",
    "\n",
    "document = reader.readSBML(\"data\\export_ECC_Base.xml\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamic-marker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

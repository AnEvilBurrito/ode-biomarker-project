{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader\n",
    "\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "\n",
    "### Load data\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# import GDSC2 drug response data using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/drug-response/GDSC2/cache_gdsc2.pkl', 'rb') as f:\n",
    "    gdsc2 = pickle.load(f)\n",
    "    gdsc2_info = pickle.load(f)\n",
    "    \n",
    "# import CCLE gene expression data using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/gene-expression/CCLE_Public_22Q2/ccle_expression.pkl', 'rb') as f:\n",
    "    gene_entrez = pickle.load(f)\n",
    "    ccle = pickle.load(f)\n",
    "\n",
    "# import CCLE sample info data using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/gene-expression/CCLE_Public_22Q2/ccle_sample_info.pkl', 'rb') as f:\n",
    "    ccle_sample_info = pickle.load(f)\n",
    "\n",
    "# import STRING database using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/protein-interaction/STRING/string_df.pkl', 'rb') as f:\n",
    "    string_df = pickle.load(f)\n",
    "    string_df_info = pickle.load(f)\n",
    "    string_df_alias = pickle.load(f)\n",
    "\n",
    "\n",
    "# import proteomic expression\n",
    "with open(f'{path_loader.get_data_path()}data/proteomic-expression/goncalves-2022-cell/goncalve_proteome_fillna_processed.pkl', 'rb') as f:\n",
    "    joined_full_protein_matrix = pickle.load(f)\n",
    "    joined_sin_peptile_exclusion_matrix = pickle.load(f)\n",
    "\n",
    "# import STRING database using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/protein-interaction/STRING/string_df.pkl', 'rb') as f:\n",
    "    string_df = pickle.load(f)\n",
    "    string_df_info = pickle.load(f)\n",
    "    string_df_alias = pickle.load(f)\n",
    "\n",
    "# open STRING to goncalves mapping file\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data\\protein-interaction\\STRING\\goncalve_to_string_id_df.pkl', 'rb') as f:\n",
    "    goncalve_to_string_id_df = pickle.load(f)\n",
    "\n",
    "# open the cache for neighbourhood calculations\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/protein-interaction/STRING/palbociclib_nth_degree_neighbours.pkl', 'rb') as f:\n",
    "    nth_degree_neighbours = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolkit Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# loading cell line proteomic expression data\n",
    "\n",
    "cancercell2022 = pd.read_csv('data\\preprocessed\\SY-Processed\\CancerCell2022_PRISM.csv')\n",
    "\n",
    "cancercell2022_dropnan = cancercell2022.dropna(subset=['AUC'])\n",
    "\n",
    "import DataFunctions as dfunc \n",
    "\n",
    "feature_data, label_data = dfunc.create_feature_and_label(cancercell2022_dropnan, label_name='AUC')\n",
    "\n",
    "feature_data_no_row = feature_data.drop(['Row'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import FeatureTransformer\n",
    "from toolkit import impute_by_zero, impute_by_first_quantile, get_network_stat_features, get_random_features\n",
    "\n",
    "F = FeatureTransformer()\n",
    "\n",
    "F.add_transform_function('impute_by_zero', impute_by_zero)\n",
    "F.add_selection_function('random_select', get_random_features, {\"selection_size\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, label_data, random_state=42)\n",
    "\n",
    "# Print the shapes of the new X objects\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n",
    "\n",
    "# Run Feature Transformer \n",
    "\n",
    "selected_features, sel_train, sel_test = F.run(X_train, y_train, X_test)\n",
    "\n",
    "print(selected_features, sel_train.shape, sel_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear variables in juptyer notebook\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create controlled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "\n",
    "# turn X and Y into dataframes\n",
    "X, y = make_regression(n_samples=500, n_features=1000, n_informative=10, random_state=1, shuffle=False)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "# turn columns into strings\n",
    "\n",
    "X.columns = [str(i) for i in range(X.shape[1])]\n",
    "\n",
    "print(f'Original informative columns: {X.columns[:10]}')\n",
    "\n",
    "# shuffle columns around for X\n",
    "\n",
    "X = X.sample(frac=1, axis=1, random_state=0)\n",
    "\n",
    "print(f'Newly shuffled columns: {X.columns[:10]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import mrmr_select_fcq\n",
    "\n",
    "features, scores = mrmr_select_fcq(X, y, K=10,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import enet_select\n",
    "\n",
    "features, scores = enet_select(X, y, 10, max_iter=10000, alpha=0.1, l1_ratio=0.7)\n",
    "\n",
    "print(features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import rf_select\n",
    "\n",
    "features, scores = rf_select(X, y, k=10, n_estimators=100, max_depth=5, n_jobs=-1)\n",
    "\n",
    "print(features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import f_regression_select\n",
    "\n",
    "features, scores = f_regression_select(X, y, k=10)\n",
    "print(features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import relieff_select\n",
    "\n",
    "features, scores = relieff_select(X, y, k=10, n_jobs=4)\n",
    "print(features)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear variables in juptyer notebook\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from toolkit import select_random_features\n",
    "\n",
    "selected_features, selected_X = select_random_features(X, y, 10)\n",
    "\n",
    "print(selected_features, selected_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import transform_impute_by_zero\n",
    "\n",
    "imputed_X, imputed_y = transform_impute_by_zero(X, y)\n",
    "\n",
    "print(imputed_X.shape, imputed_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the Powerkit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing code, for reference ONLY\n",
    "'''\n",
    "\n",
    "# rng = 45\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rng)\n",
    "# get_feature_importance = False\n",
    "# pipeline_comps = pipeline_func(X_train, y_train)\n",
    "# eval_returns = eval_func(X_test, y_test, pipeline_components=pipeline_comps)\n",
    "# # print(eval_returns)\n",
    "\n",
    "# # combine pipeline_comps and eval_returns into a single dictionary\n",
    "\n",
    "# final_returns = {}\n",
    "# final_returns['rng'] = rng\n",
    "# final_returns['condition'] = 'test'\n",
    "# final_returns.update(eval_returns)\n",
    "\n",
    "# if not get_feature_importance:\n",
    "#     final_returns.pop('feature_importance')\n",
    "\n",
    "# # convert final_returns into a dataframe, test if it works for multiple rows\n",
    "\n",
    "# df = pd.DataFrame([final_returns, final_returns])\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# feature_importance = final_returns['feature_importance']\n",
    "\n",
    "# for x,y in zip(feature_importance[0], feature_importance[1]):\n",
    "#     print(f'Feature: {x}, Score: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n",
      "Original informative columns: Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='object')\n",
      "Newly shuffled columns: Index(['993', '859', '298', '553', '672', '971', '27', '231', '306', '706'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n",
    "\n",
    "from toolkit import Powerkit, transform_impute_by_zero, select_random_features, select_preset_features, select_stat_features, f_regression_select, mrmr_select_fcq, hypertune_svr\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# create a Powerkit object\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "\n",
    "# turn X and Y into dataframes\n",
    "X, y = make_regression(n_samples=500, n_features=1000, n_informative=10, random_state=1, shuffle=False)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "# turn columns into strings\n",
    "\n",
    "X.columns = [str(i) for i in range(X.shape[1])]\n",
    "\n",
    "print(f'Original informative columns: {X.columns[:10]}')\n",
    "\n",
    "# shuffle columns around for X\n",
    "\n",
    "X = X.sample(frac=1, axis=1, random_state=0)\n",
    "\n",
    "print(f'Newly shuffled columns: {X.columns[:10]}')\n",
    "\n",
    "\n",
    "def pipeline_func(X_train, y_train, **kwargs):\n",
    "    \n",
    "    X_transformed, y_transformed = transform_impute_by_zero(X_train, y_train)\n",
    "    # selected_features, scores = f_regression_select(X_transformed, y_transformed, k=10)\n",
    "    selected_features, scores = mrmr_select_fcq(X_transformed, y_transformed, K=10, return_index=False)\n",
    "    selected_features, X_selected = select_preset_features(X_transformed, y_transformed, selected_features)\n",
    "    model = SVR()\n",
    "    model.fit(X_selected, y_transformed)\n",
    "    \n",
    "    return {'model': model, 'selected_features': selected_features, 'scores': scores}\n",
    "\n",
    "def eval_func(X_test, y_test, pipeline_components=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    example function to evaluate the performance of a pipeline\n",
    "    inputs\n",
    "        X_test: test set features\n",
    "        y_test: test set labels\n",
    "        pipeline_components: dictionary of pipeline components, e.g. {'model': model, 'selected_features': selected_features, 'scores': scores}\n",
    "    '''\n",
    "    \n",
    "    _, X_selected = select_preset_features(X_test, y_test, pipeline_components['selected_features'])\n",
    "    y_pred = pipeline_components['model'].predict(X_selected)\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # at the end, return a dictionary of all the information you want to return\n",
    "    return {'model_performance': corr, 'p_vals': p_vals, \n",
    "            'feature_importance': (pipeline_components['selected_features'], pipeline_components['scores'])}\n",
    "\n",
    "powerkit = Powerkit(X, y) \n",
    "powerkit.add_condition('test', True, pipeline_func, {}, eval_func, {})\n",
    "rng_list = [i for i in range(24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = powerkit._abstract_run(rng_list, n_jobs=4, verbose=False)\n",
    "df.head()\n",
    "\n",
    "contribution = powerkit.get_mean_contribution(df, 'test', adjust_for_accuracy=True, strict_mean=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(1, 5)\n",
      "current_contrib: ['6', '606', '573', '5', '8']\n",
      "current iteration: 1 current_tol: 0.001021, abs_diff: 19513.745325, abs_prev: 19118662.377876, performance: 0.832570\n",
      "(1, 5)\n",
      "current_contrib: ['6', '606', '573', '443', '5']\n",
      "current iteration: 2 current_tol: 0.000645, abs_diff: 12376.375171, abs_prev: 19176477.834858, performance: 0.872481\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rngs, total_df, meta_df \u001b[39m=\u001b[39m powerkit\u001b[39m.\u001b[39;49mrun_until_consensus(\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, abs_tol\u001b[39m=\u001b[39;49m\u001b[39m0.0001\u001b[39;49m, rel_tol\u001b[39m=\u001b[39;49m\u001b[39m0.0001\u001b[39;49m, max_iter\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m      2\u001b[0m                                                        verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose_level\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, return_meta_df\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, crunch_factor\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# single core can be more efficient when the computational cost of each iteration is low. \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:395\u001b[0m, in \u001b[0;36mPowerkit.run_until_consensus\u001b[1;34m(self, condition, rel_tol, abs_tol, max_iter, use_std, n_jobs, verbose, verbose_level, return_meta_df, crunch_factor)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mand\u001b[39;00m verbose_level \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    394\u001b[0m     verbose_at_run \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_selected_condition(condition, rng_list\u001b[39m=\u001b[39;49mrngs, n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49mverbose_at_run)\n\u001b[0;32m    397\u001b[0m \u001b[39m# create a mini df for each iteration\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39mfor\u001b[39;00m rng \u001b[39min\u001b[39;00m rngs: \n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:310\u001b[0m, in \u001b[0;36mPowerkit.run_selected_condition\u001b[1;34m(self, condition, rng_list, n_jobs, verbose)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39mif\u001b[39;00m condition \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconditions\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    309\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcondition \u001b[39m\u001b[39m{\u001b[39;00mcondition\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 310\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_abstract_run(rng_list, n_jobs, verbose, conditions\u001b[39m=\u001b[39;49m[condition])\n\u001b[0;32m    311\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:276\u001b[0m, in \u001b[0;36mPowerkit._abstract_run\u001b[1;34m(self, rng_list, n_jobs, verbose, conditions)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[39mfor\u001b[39;00m rng \u001b[39min\u001b[39;00m rng_list:\n\u001b[0;32m    275\u001b[0m         \u001b[39mfor\u001b[39;00m condition \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconditions\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m--> 276\u001b[0m             data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_abstract_run_single(condition,\n\u001b[0;32m    277\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconditions[condition][\u001b[39m'\u001b[39;49m\u001b[39mcondition_to_get_feature_importance\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    278\u001b[0m                                             rng,\n\u001b[0;32m    279\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconditions[condition][\u001b[39m'\u001b[39;49m\u001b[39mpipeline_function\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    280\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconditions[condition][\u001b[39m'\u001b[39;49m\u001b[39mpipeline_args\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    281\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconditions[condition][\u001b[39m'\u001b[39;49m\u001b[39meval_function\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    282\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconditions[condition][\u001b[39m'\u001b[39;49m\u001b[39meval_args\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    283\u001b[0m                                             verbose\u001b[39m=\u001b[39;49mverbose\n\u001b[0;32m    284\u001b[0m                                             )\n\u001b[0;32m    285\u001b[0m             data_collector\u001b[39m.\u001b[39mappend(data)\n\u001b[0;32m    286\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m     \u001b[39m# use joblib to parallelize the process, disable verbose printing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:256\u001b[0m, in \u001b[0;36mPowerkit._abstract_run_single\u001b[1;34m(self, condition, condition_to_get_feature_importance, rng, pipeline_function, pipeline_args, eval_function, eval_args, verbose)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39m# split the data and go through the pipeline\u001b[39;00m\n\u001b[0;32m    255\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_data, test_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_split_size, random_state\u001b[39m=\u001b[39mrng)\n\u001b[1;32m--> 256\u001b[0m pipeline_comps \u001b[39m=\u001b[39m pipeline_function(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpipeline_args)\n\u001b[0;32m    257\u001b[0m eval_returns \u001b[39m=\u001b[39m eval_function(X_test, y_test, pipeline_components\u001b[39m=\u001b[39mpipeline_comps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39meval_args)\n\u001b[0;32m    259\u001b[0m \u001b[39m# update the final returns\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m, in \u001b[0;36mpipeline_func\u001b[1;34m(X_train, y_train, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m X_transformed, y_transformed \u001b[39m=\u001b[39m transform_impute_by_zero(X_train, y_train)\n\u001b[0;32m     51\u001b[0m \u001b[39m# selected_features, scores = f_regression_select(X_transformed, y_transformed, k=10)\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m selected_features, scores \u001b[39m=\u001b[39m mrmr_select_fcq(X_transformed, y_transformed, K\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, return_index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     53\u001b[0m selected_features, X_selected \u001b[39m=\u001b[39m select_preset_features(X_transformed, y_transformed, selected_features)\n\u001b[0;32m     54\u001b[0m model \u001b[39m=\u001b[39m SVR()\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:985\u001b[0m, in \u001b[0;36mmrmr_select_fcq\u001b[1;34m(X, y, K, verbose, return_index)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    984\u001b[0m     last_selected \u001b[39m=\u001b[39m selected[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 985\u001b[0m     corr\u001b[39m.\u001b[39mloc[not_selected, last_selected] \u001b[39m=\u001b[39m X[not_selected]\u001b[39m.\u001b[39;49mcorrwith(X[last_selected])\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mclip(\u001b[39m.00001\u001b[39m)\n\u001b[0;32m    987\u001b[0m \u001b[39m# compute FCQ score for all the (currently) excluded features\u001b[39;00m\n\u001b[0;32m    988\u001b[0m score \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mloc[not_selected] \u001b[39m/\u001b[39m corr\u001b[39m.\u001b[39mloc[not_selected, selected]\u001b[39m.\u001b[39mmean(axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfillna(\u001b[39m.00001\u001b[39m)\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\venv\\lib\\site-packages\\pandas\\core\\frame.py:10572\u001b[0m, in \u001b[0;36mDataFrame.corrwith\u001b[1;34m(self, other, axis, drop, method, numeric_only)\u001b[0m\n\u001b[0;32m  10570\u001b[0m     \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ndf):\n\u001b[0;32m  10571\u001b[0m         nonnull_mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misnan(r) \u001b[39m&\u001b[39m \u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misnan(k)\n\u001b[1;32m> 10572\u001b[0m         corrs[cols[i]] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mcorrcoef(r[nonnull_mask], k[nonnull_mask])[\n\u001b[0;32m  10573\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[0;32m  10574\u001b[0m         ]\n\u001b[0;32m  10575\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m  10576\u001b[0m     \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ndf):\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcorrcoef\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py:2846\u001b[0m, in \u001b[0;36mcorrcoef\u001b[1;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[0;32m   2842\u001b[0m \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39mor\u001b[39;00m ddof \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue:\n\u001b[0;32m   2843\u001b[0m     \u001b[39m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[0;32m   2844\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mbias and ddof have no effect and are deprecated\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   2845\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m-> 2846\u001b[0m c \u001b[39m=\u001b[39m cov(x, y, rowvar, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   2847\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2848\u001b[0m     d \u001b[39m=\u001b[39m diag(c)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py:2699\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2695\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mDegrees of freedom <= 0 for slice\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2696\u001b[0m                   \u001b[39mRuntimeWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m   2697\u001b[0m     fact \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m-> 2699\u001b[0m X \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m avg[:, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m   2700\u001b[0m \u001b[39mif\u001b[39;00m w \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2701\u001b[0m     X_T \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rngs, total_df, meta_df = powerkit.run_until_consensus('test', n_jobs=1, abs_tol=0.0001, rel_tol=0.0001, max_iter=50,\n",
    "                                                       verbose=True, verbose_level=1, return_meta_df=True, crunch_factor=5)\n",
    "\n",
    "# single core can be more efficient when the computational cost of each iteration is low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution = powerkit.get_mean_contribution(total_df, 'test', adjust_for_accuracy=True, strict_mean=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchApp Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading SBML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading anthony's sbml model\n",
    "\n",
    "from libsbml import *\n",
    "\n",
    "reader = SBMLReader()\n",
    "\n",
    "document = reader.readSBML(\"data\\export_ECC_Base.xml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = document.getModel()\n",
    "\n",
    "print(f'Document errors: {document.getNumErrors()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of species: {model.getNumSpecies()}')\n",
    "\n",
    "print(f'Number of reactions: {model.getNumReactions()}')\n",
    "\n",
    "print(f'Number of compartments: {model.getNumCompartments()}')\n",
    "\n",
    "print(f'Number of parameters: {model.getNumParameters()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rules: {model.getNumRules()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import roadrunner\n",
    "\n",
    "rr = roadrunner.RoadRunner(\"data\\export_ECC_Base.xml\")\n",
    "\n",
    "print(f'Number of floating species: {len(rr.model.getFloatingSpeciesIds())}')\n",
    "\n",
    "print(f'Number of boundary species: {len(rr.model.getBoundarySpeciesIds())}')\n",
    "\n",
    "print(f'Number of global parameters: {len(rr.model.getGlobalParameterIds())}')\n",
    "\n",
    "print(f'Number of compartments: {len(rr.model.getCompartmentIds())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rr.simulate(0, 10, 100)\n",
    "\n",
    "rr.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{rr.model.getFloatingSpeciesIds()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model[\"init(IRS)\"]\n",
    "\n",
    "# rr.model[\"init(IRS)\"] = 0.5 # for changing initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model.getGlobalParameterIds()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.kc_INSULIN_INSR_INSRpY\n",
    "\n",
    "# rr.kc_INSULIN_INSR_INSRpY = 0.1 # for changing parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model['kc_INSULIN_INSR_INSRpY'] # another method for changing parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model['INSR'] # another method for changing initial condition values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking CCLE data to Anthony's SBML model initial conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing parameters in SBML model to the calibrated set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing dynamic simulation data back to singular vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LanODEApp Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load in core data and libraries'''\n",
    "\n",
    "# libraries used \n",
    "\n",
    "# load CCLE expression data  \n",
    "\n",
    "# load Anthony's model and optimal parameter sets \n",
    "\n",
    "document = reader.readSBML(\"data\\export_ECC_Base.xml\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamic-marker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader\n",
    "\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "\n",
    "### Load data\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# import GDSC2 drug response data using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/drug-response/GDSC2/cache_gdsc2.pkl', 'rb') as f:\n",
    "    gdsc2 = pickle.load(f)\n",
    "    gdsc2_info = pickle.load(f)\n",
    "    \n",
    "# import CCLE gene expression data using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/gene-expression/CCLE_Public_22Q2/ccle_expression.pkl', 'rb') as f:\n",
    "    gene_entrez = pickle.load(f)\n",
    "    ccle = pickle.load(f)\n",
    "\n",
    "# import CCLE sample info data using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/gene-expression/CCLE_Public_22Q2/ccle_sample_info.pkl', 'rb') as f:\n",
    "    ccle_sample_info = pickle.load(f)\n",
    "\n",
    "# import STRING database using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/protein-interaction/STRING/string_df.pkl', 'rb') as f:\n",
    "    string_df = pickle.load(f)\n",
    "    string_df_info = pickle.load(f)\n",
    "    string_df_alias = pickle.load(f)\n",
    "\n",
    "\n",
    "# import proteomic expression\n",
    "with open(f'{path_loader.get_data_path()}data/proteomic-expression/goncalves-2022-cell/goncalve_proteome_fillna_processed.pkl', 'rb') as f:\n",
    "    joined_full_protein_matrix = pickle.load(f)\n",
    "    joined_sin_peptile_exclusion_matrix = pickle.load(f)\n",
    "\n",
    "# import STRING database using pickle\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/protein-interaction/STRING/string_df.pkl', 'rb') as f:\n",
    "    string_df = pickle.load(f)\n",
    "    string_df_info = pickle.load(f)\n",
    "    string_df_alias = pickle.load(f)\n",
    "\n",
    "# open STRING to goncalves mapping file\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data\\protein-interaction\\STRING\\goncalve_to_string_id_df.pkl', 'rb') as f:\n",
    "    goncalve_to_string_id_df = pickle.load(f)\n",
    "\n",
    "# open the cache for neighbourhood calculations\n",
    "\n",
    "with open(f'{path_loader.get_data_path()}data/protein-interaction/STRING/palbociclib_nth_degree_neighbours.pkl', 'rb') as f:\n",
    "    nth_degree_neighbours = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolkit Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# loading cell line proteomic expression data\n",
    "\n",
    "cancercell2022 = pd.read_csv('data\\preprocessed\\SY-Processed\\CancerCell2022_PRISM.csv')\n",
    "\n",
    "cancercell2022_dropnan = cancercell2022.dropna(subset=['AUC'])\n",
    "\n",
    "import DataFunctions as dfunc \n",
    "\n",
    "feature_data, label_data = dfunc.create_feature_and_label(cancercell2022_dropnan, label_name='AUC')\n",
    "\n",
    "feature_data_no_row = feature_data.drop(['Row'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import FeatureTransformer\n",
    "from toolkit import impute_by_zero, impute_by_first_quantile, get_network_stat_features, get_random_features\n",
    "\n",
    "F = FeatureTransformer()\n",
    "\n",
    "F.add_transform_function('impute_by_zero', impute_by_zero)\n",
    "F.add_selection_function('random_select', get_random_features, {\"selection_size\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, label_data, random_state=42)\n",
    "\n",
    "# Print the shapes of the new X objects\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n",
    "\n",
    "# Run Feature Transformer \n",
    "\n",
    "selected_features, sel_train, sel_test = F.run(X_train, y_train, X_test)\n",
    "\n",
    "print(selected_features, sel_train.shape, sel_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear variables in juptyer notebook\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create controlled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original informative columns: Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='object')\n",
      "Newly shuffled columns: Index(['993', '859', '298', '553', '672', '971', '27', '231', '306', '706'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "\n",
    "# turn X and Y into dataframes\n",
    "X, y = make_regression(n_samples=500, n_features=1000, n_informative=10, random_state=1, shuffle=False)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "# turn columns into strings\n",
    "\n",
    "X.columns = [str(i) for i in range(X.shape[1])]\n",
    "\n",
    "print(f'Original informative columns: {X.columns[:10]}')\n",
    "\n",
    "# shuffle columns around for X\n",
    "\n",
    "X = X.sample(frac=1, axis=1, random_state=0)\n",
    "\n",
    "print(f'Newly shuffled columns: {X.columns[:10]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import mrmr_select_fcq\n",
    "\n",
    "features, scores = mrmr_select_fcq(X, y, K=10,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import enet_select\n",
    "\n",
    "features, scores = enet_select(X, y, 10, max_iter=10000, alpha=0.1, l1_ratio=0.7)\n",
    "\n",
    "print(features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import rf_select\n",
    "\n",
    "features, scores = rf_select(X, y, k=10, n_estimators=100, max_depth=5, n_jobs=-1)\n",
    "\n",
    "print(features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import f_regression_select\n",
    "\n",
    "features, scores = f_regression_select(X, y, k=10)\n",
    "print(features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import relieff_select\n",
    "\n",
    "features, scores = relieff_select(X, y, k=10, n_jobs=4)\n",
    "print(features)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear variables in juptyer notebook\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from toolkit import select_random_features\n",
    "\n",
    "selected_features, selected_X = select_random_features(X, y, 10)\n",
    "\n",
    "print(selected_features, selected_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import transform_impute_by_zero\n",
    "\n",
    "imputed_X, imputed_y = transform_impute_by_zero(X, y)\n",
    "\n",
    "print(imputed_X.shape, imputed_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from toolkit import hypertune_svr\n",
    "\n",
    "best_params, best_score, results = hypertune_svr(X, y, cv=5, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear'}\n",
      "0.35143606570346575\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071533</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear'}</td>\n",
       "      <td>0.198850</td>\n",
       "      <td>0.381300</td>\n",
       "      <td>0.363661</td>\n",
       "      <td>0.363311</td>\n",
       "      <td>0.450059</td>\n",
       "      <td>0.351436</td>\n",
       "      <td>0.082694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043346</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'kernel': 'poly'}</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.008858</td>\n",
       "      <td>-0.001281</td>\n",
       "      <td>-0.002172</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052588</td>\n",
       "      <td>0.013861</td>\n",
       "      <td>0.028052</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf'}</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>-0.007306</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045879</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'kernel': 'sigmoid'}</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>-0.003206</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_kernel  \\\n",
       "0       0.071533      0.005797         0.012741        0.001749       linear   \n",
       "1       0.043346      0.001597         0.013444        0.003961         poly   \n",
       "2       0.052588      0.013861         0.028052        0.004161          rbf   \n",
       "3       0.045879      0.004190         0.015927        0.002738      sigmoid   \n",
       "\n",
       "                  params  split0_test_score  split1_test_score  \\\n",
       "0   {'kernel': 'linear'}           0.198850           0.381300   \n",
       "1     {'kernel': 'poly'}          -0.000117          -0.000541   \n",
       "2      {'kernel': 'rbf'}           0.000356           0.000491   \n",
       "3  {'kernel': 'sigmoid'}           0.001534           0.003233   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0           0.363661           0.363311           0.450059         0.351436   \n",
       "1          -0.000063          -0.008858          -0.001281        -0.002172   \n",
       "2           0.000724          -0.007306           0.000018        -0.001143   \n",
       "3           0.002922          -0.003206           0.003311         0.001559   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.082694                1  \n",
       "1        0.003371                4  \n",
       "2        0.003090                3  \n",
       "3        0.002467                2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END hidden_layer_sizes=(1, 1, 1), learning_rate=constant; total time=  36.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END hidden_layer_sizes=(1, 1, 1), learning_rate=constant; total time=  35.9s\n",
      "[CV] END hidden_layer_sizes=(1, 1, 1), learning_rate=constant; total time=   9.2s\n"
     ]
    }
   ],
   "source": [
    "from toolkit import hypertune_ann\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# best_params, best_score, results = hypertune_ann(X, y, cv=5, n_jobs=1)\n",
    "\n",
    "# TODO: computational load need to be on VM  \n",
    "\n",
    "# define the parameter values that should be searched\n",
    "hidden_layer_sizes_range = [(i, i, i) for i in range(1, 100, 10)]\n",
    "learning_rate_range = ['constant', 'invscaling', 'adaptive']\n",
    "param_grid = dict(hidden_layer_sizes=hidden_layer_sizes_range,\n",
    "                    learning_rate=learning_rate_range)\n",
    "\n",
    "# instantiate and fit the grid\n",
    "grid = GridSearchCV(MLPRegressor(max_iter=100000), param_grid, cv=5, scoring='r2', n_jobs=1, verbose=2)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the Powerkit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing code, for reference ONLY\n",
    "'''\n",
    "\n",
    "# rng = 45\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rng)\n",
    "# get_feature_importance = False\n",
    "# pipeline_comps = pipeline_func(X_train, y_train)\n",
    "# eval_returns = eval_func(X_test, y_test, pipeline_components=pipeline_comps)\n",
    "# # print(eval_returns)\n",
    "\n",
    "# # combine pipeline_comps and eval_returns into a single dictionary\n",
    "\n",
    "# final_returns = {}\n",
    "# final_returns['rng'] = rng\n",
    "# final_returns['condition'] = 'test'\n",
    "# final_returns.update(eval_returns)\n",
    "\n",
    "# if not get_feature_importance:\n",
    "#     final_returns.pop('feature_importance')\n",
    "\n",
    "# # convert final_returns into a dataframe, test if it works for multiple rows\n",
    "\n",
    "# df = pd.DataFrame([final_returns, final_returns])\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# feature_importance = final_returns['feature_importance']\n",
    "\n",
    "# for x,y in zip(feature_importance[0], feature_importance[1]):\n",
    "#     print(f'Feature: {x}, Score: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\ode-biomarker-project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original informative columns: Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='object')\n",
      "Newly shuffled columns: Index(['993', '859', '298', '553', '672', '971', '27', '231', '306', '706'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')\n",
    "\n",
    "from toolkit import Powerkit, transform_impute_by_zero, select_random_features, select_preset_features, select_stat_features, f_regression_select, mrmr_select_fcq, hypertune_svr, get_variation\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# create a Powerkit object\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "\n",
    "# turn X and Y into dataframes\n",
    "X, y = make_regression(n_samples=500, n_features=1000, n_informative=10, random_state=1, shuffle=False)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "# turn columns into strings\n",
    "\n",
    "X.columns = [str(i) for i in range(X.shape[1])]\n",
    "\n",
    "print(f'Original informative columns: {X.columns[:10]}')\n",
    "\n",
    "# shuffle columns around for X\n",
    "\n",
    "X = X.sample(frac=1, axis=1, random_state=0)\n",
    "\n",
    "print(f'Newly shuffled columns: {X.columns[:10]}')\n",
    "\n",
    "\n",
    "def pipeline_func(X_train, y_train, **kwargs):\n",
    "    \n",
    "    X_transformed, y_transformed = transform_impute_by_zero(X_train, y_train)\n",
    "    # selected_features, scores = f_regression_select(X_transformed, y_transformed, k=10)\n",
    "    selected_features, scores = mrmr_select_fcq(X_transformed, y_transformed, K=10, return_index=False)\n",
    "    selected_features, X_selected = select_preset_features(X_transformed, y_transformed, selected_features)\n",
    "    model = SVR()\n",
    "    model.fit(X_selected, y_transformed)\n",
    "    \n",
    "    return {'model': model, 'selected_features': selected_features, 'scores': scores}\n",
    "\n",
    "def eval_func(X_test, y_test, pipeline_components=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    example function to evaluate the performance of a pipeline\n",
    "    inputs\n",
    "        X_test: test set features\n",
    "        y_test: test set labels\n",
    "        pipeline_components: dictionary of pipeline components, e.g. {'model': model, 'selected_features': selected_features, 'scores': scores}\n",
    "    '''\n",
    "    \n",
    "    _, X_selected = select_preset_features(X_test, y_test, pipeline_components['selected_features'])\n",
    "    y_pred = pipeline_components['model'].predict(X_selected)\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # at the end, return a dictionary of all the information you want to return\n",
    "    return {'model_performance': corr, 'p_vals': p_vals, \n",
    "            'feature_importance': (pipeline_components['selected_features'], pipeline_components['scores'])}\n",
    "\n",
    "powerkit = Powerkit(X, y) \n",
    "powerkit.add_condition('test', True, pipeline_func, {}, eval_func, {})\n",
    "rng_list = [i for i in range(24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = powerkit._abstract_run(rng_list, n_jobs=4, verbose=False)\n",
    "df.head()\n",
    "\n",
    "contribution = powerkit.get_mean_contribution(df, 'test', adjust_for_accuracy=True, strict_mean=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_contrib: ['6', '5', '7', '1', '4']\n",
      "current iteration: 0 current_tol: 10000000000.000000, abs_diff: 10000000000.000000, performance: 0.889399\n",
      "current_contrib: ['6', '206', '5', '7', '1']\n",
      "current iteration: 1 current_tol: 0.015530, abs_diff: 286232.320152, abs_prev: 18430525.481821, performance: 0.889399\n",
      "current_contrib: ['6', '206', '5', '793', '7']\n",
      "current iteration: 2 current_tol: 0.004512, abs_diff: 84487.286536, abs_prev: 18726379.046577, performance: 0.889399\n",
      "current_contrib: ['6', '206', '286', '5', '793']\n",
      "current iteration: 3 current_tol: 0.005339, abs_diff: 100441.207276, abs_prev: 18812194.681161, performance: 0.889399\n",
      "current_contrib: ['6', '665', '206', '286', '5']\n",
      "current iteration: 4 current_tol: 0.012478, abs_diff: 233659.197915, abs_prev: 18724967.429813, performance: 0.889399\n",
      "current_contrib: ['6', '257', '665', '206', '286']\n",
      "current iteration: 5 current_tol: 0.002375, abs_diff: 43987.178537, abs_prev: 18517720.013590, performance: 0.889399\n",
      "current_contrib: ['6', '225', '257', '665', '206']\n",
      "current iteration: 6 current_tol: 0.006167, abs_diff: 115434.315526, abs_prev: 18718472.643088, performance: 0.871833\n",
      "current_contrib: ['6', '225', '257', '665', '426']\n",
      "current iteration: 7 current_tol: 0.001235, abs_diff: 23268.337692, abs_prev: 18838326.855867, performance: 0.871833\n",
      "current_contrib: ['6', '225', '257', '583', '665']\n",
      "current iteration: 8 current_tol: 0.003954, abs_diff: 74479.727414, abs_prev: 18835492.785803, performance: 0.871833\n",
      "current_contrib: ['6', '225', '257', '583', '665']\n",
      "current iteration: 9 current_tol: 0.008016, abs_diff: 151937.986517, abs_prev: 18955071.417345, performance: 0.871833\n",
      "current_contrib: ['6', '225', '257', '583', '665']\n",
      "current iteration: 10 current_tol: 0.000564, abs_diff: 10603.311524, abs_prev: 18808543.371522, performance: 0.871833\n",
      "current_contrib: ['6', '225', '257', '583', '710']\n",
      "current iteration: 11 current_tol: 0.004839, abs_diff: 91091.254371, abs_prev: 18825126.940993, performance: 0.871833\n",
      "current_contrib: ['6', '225', '257', '583', '710']\n",
      "current iteration: 12 current_tol: 0.002506, abs_diff: 47460.475780, abs_prev: 18941610.238203, performance: 0.881790\n",
      "current_contrib: ['6', '225', '257', '583', '710']\n",
      "current iteration: 13 current_tol: 0.002200, abs_diff: 41577.585266, abs_prev: 18896643.135611, performance: 0.881790\n",
      "current_contrib: ['6', '225', '257', '583', '710']\n",
      "current iteration: 14 current_tol: 0.002913, abs_diff: 55199.821119, abs_prev: 18948107.224648, performance: 0.881790\n",
      "current_contrib: ['6', '225', '257', '583', '710']\n",
      "current iteration: 15 current_tol: 0.000707, abs_diff: 13367.383101, abs_prev: 18902413.263325, performance: 0.881790\n",
      "current_contrib: ['6', '225', '257', '45', '583']\n",
      "current iteration: 16 current_tol: 0.003774, abs_diff: 71350.087193, abs_prev: 18907640.811970, performance: 0.881790\n",
      "current_contrib: ['6', '225', '257', '45', '583']\n",
      "current iteration: 17 current_tol: 0.000201, abs_diff: 3822.718833, abs_prev: 18978591.195214, performance: 0.881790\n",
      "current_contrib: ['6', '225', '257', '45', '583']\n",
      "current iteration: 18 current_tol: 0.003076, abs_diff: 58391.361229, abs_prev: 18982844.545172, performance: 0.869413\n",
      "current_contrib: ['6', '225', '257', '45', '583']\n",
      "current iteration: 19 current_tol: 0.001242, abs_diff: 23635.715549, abs_prev: 19031077.586051, performance: 0.869413\n",
      "current_contrib: ['6', '225', '257', '45', '583']\n",
      "current iteration: 20 current_tol: 0.005963, abs_diff: 113887.854183, abs_prev: 19097541.494218, performance: 0.869413\n",
      "current_contrib: ['6', '225', '257', '45', '583']\n",
      "current iteration: 21 current_tol: 0.001843, abs_diff: 35397.999445, abs_prev: 19211147.713879, performance: 0.869413\n",
      "current_contrib: ['6', '225', '257', '583', '45']\n",
      "current iteration: 22 current_tol: 0.003155, abs_diff: 60513.210595, abs_prev: 19179814.271859, performance: 0.869413\n",
      "current_contrib: ['6', '225', '257', '583', '45']\n",
      "current iteration: 23 current_tol: 0.002094, abs_diff: 40047.549892, abs_prev: 19126087.642428, performance: 0.869413\n",
      "current_contrib: ['6', '225', '257', '583', '45']\n",
      "current iteration: 24 current_tol: 0.000583, abs_diff: 11130.679112, abs_prev: 19096347.384659, performance: 0.868597\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 25 current_tol: 0.000779, abs_diff: 14899.186586, abs_prev: 19117101.610932, performance: 0.868597\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 26 current_tol: 0.001268, abs_diff: 24295.019653, abs_prev: 19161260.793782, performance: 0.868597\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 27 current_tol: 0.002249, abs_diff: 43147.800298, abs_prev: 19185354.447804, performance: 0.868597\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 28 current_tol: 0.001783, abs_diff: 34193.198912, abs_prev: 19174822.361711, performance: 0.868597\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 29 current_tol: 0.002458, abs_diff: 47080.256363, abs_prev: 19155935.143424, performance: 0.868597\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 30 current_tol: 0.001605, abs_diff: 30833.603301, abs_prev: 19216865.725820, performance: 0.875884\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 31 current_tol: 0.000143, abs_diff: 2741.669520, abs_prev: 19230181.498573, performance: 0.875884\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 32 current_tol: 0.001071, abs_diff: 20603.630208, abs_prev: 19237837.451688, performance: 0.875884\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 33 current_tol: 0.001617, abs_diff: 31149.371875, abs_prev: 19258315.256364, performance: 0.875884\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 34 current_tol: 0.000537, abs_diff: 10355.045743, abs_prev: 19282911.283796, performance: 0.875884\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 35 current_tol: 0.001805, abs_diff: 34854.398296, abs_prev: 19310157.407296, performance: 0.875884\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 36 current_tol: 0.003288, abs_diff: 63643.282136, abs_prev: 19353656.638216, performance: 0.881493\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 37 current_tol: 0.001710, abs_diff: 33212.170881, abs_prev: 19417136.291024, performance: 0.881493\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 38 current_tol: 0.000564, abs_diff: 10946.025115, abs_prev: 19390864.663517, performance: 0.881493\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 39 current_tol: 0.000050, abs_diff: 978.051046, abs_prev: 19407977.655177, performance: 0.881493\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 40 current_tol: 0.001195, abs_diff: 23226.520695, abs_prev: 19435213.541029, performance: 0.881493\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 41 current_tol: 0.003202, abs_diff: 62302.047734, abs_prev: 19454741.280969, performance: 0.881493\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 42 current_tol: 0.001118, abs_diff: 21688.873500, abs_prev: 19396892.069314, performance: 0.876472\n",
      "current_contrib: ['6', '225', '257', '659', '583']\n",
      "current iteration: 43 current_tol: 0.000860, abs_diff: 16722.870393, abs_prev: 19442256.149196, performance: 0.876472\n",
      "current_contrib: ['6', '225', '257', '206', '659']\n",
      "current iteration: 44 current_tol: 0.004178, abs_diff: 81191.578873, abs_prev: 19434842.923964, performance: 0.876472\n",
      "current_contrib: ['6', '225', '257', '206', '659']\n",
      "current iteration: 45 current_tol: 0.002517, abs_diff: 49131.483109, abs_prev: 19516003.770280, performance: 0.876472\n",
      "current_contrib: ['6', '225', '257', '206', '659']\n",
      "current iteration: 46 current_tol: 0.001346, abs_diff: 26211.681120, abs_prev: 19473916.423003, performance: 0.876472\n",
      "current_contrib: ['6', '225', '257', '206', '659']\n",
      "current iteration: 47 current_tol: 0.001405, abs_diff: 27353.293455, abs_prev: 19461853.171145, performance: 0.876472\n",
      "current_contrib: ['6', '225', '257', '206', '659']\n",
      "current iteration: 48 current_tol: 0.000234, abs_diff: 4549.461204, abs_prev: 19434510.873523, performance: 0.885438\n",
      "current_contrib: ['6', '225', '257', '206', '659']\n",
      "current iteration: 49 current_tol: 0.002099, abs_diff: 40811.043195, abs_prev: 19439040.693812, performance: 0.885438\n",
      "Consensus Run: condition test is done in 50 iterations\n",
      "Consensus Run under condition test is NOT converged within 1e-06 relative tolerance\n",
      "Consensus Run under condition test is NOT converged within 1e-06 absolute tolerance\n",
      "WARNING: Consensus Run under condition test is not converged within 50 iterations\n"
     ]
    }
   ],
   "source": [
    "rngs, total_df, meta_df = powerkit.run_until_consensus('test', n_jobs=6, abs_tol=0.000001, \n",
    "                                                       rel_tol=0.000001, max_iter=50,\n",
    "                                                       verbose=True, verbose_level=1, \n",
    "                                                       return_meta_df=True, crunch_factor=1)\n",
    "\n",
    "# single core can be more efficient when the computational cost of each iteration is low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution = powerkit.get_mean_contribution(total_df, 'test', adjust_for_accuracy=False, strict_mean=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation = get_variation(total_df, 'test', strict_mean=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variability_for_feature(df, condition, use_iqr=True, strict_mean=0.75):\n",
    "    \n",
    "    # NOTE: df must contain a column called 'feature_importance' with a tuple of (features, scores)\n",
    "    # a column called 'rng' with the rng values is also required\n",
    "    # ideally, n needs to be large enough to get a good estimate of the variability\n",
    "    \n",
    "    # first, condition is needed to filter the dataframe\n",
    "    df = df[df['condition'] == condition]\n",
    "    \n",
    "    \n",
    "    list_of_dict = []\n",
    "    feature_importance_df = df['feature_importance']\n",
    "    for row in feature_importance_df:\n",
    "        for x,y in zip(row[0], row[1]):\n",
    "            # print(f'Feature: {x}, Score: {y}')\n",
    "            list_of_dict.append({'feature': x, 'variability_score': y})\n",
    "            \n",
    "    feature_importance_all = pd.DataFrame(list_of_dict)\n",
    "    feature_count = feature_importance_all.groupby('feature').count()\n",
    "    \n",
    "    if use_iqr: \n",
    "        iqr_df = (feature_importance_all.groupby('feature').quantile(0.75) - feature_importance_all.groupby('feature').quantile(0.25))\n",
    "        iqr_df_div_mean = iqr_df / abs(feature_importance_all.groupby('feature').mean())\n",
    "        # add IQR and mean columns\n",
    "        iqr_df_div_mean['iqr'] = iqr_df\n",
    "        iqr_df_div_mean['mean'] = feature_importance_all.groupby('feature').mean()\n",
    "\n",
    "        iqr_df_div_mean['count'] = feature_count['variability_score']\n",
    "        iqr_df_div_mean = iqr_df_div_mean[iqr_df_div_mean['count'] >= total_df['rng'].nunique() * strict_mean]\n",
    "\n",
    "        # sort the dataframe by iqr, ascending\n",
    "        iqr_df_div_mean = iqr_df_div_mean.sort_values(by='variability_score', ascending=True)\n",
    "        \n",
    "\n",
    "        return iqr_df_div_mean\n",
    "    else:\n",
    "        # calculate the std for each feature divided by the mean\n",
    "        # NOTE: only use this if a normal distribution is assumed\n",
    "        std_df = feature_importance_all.groupby('feature').std() / abs(feature_importance_all.groupby('feature').mean())\n",
    "\n",
    "        # add std and mean columns\n",
    "        std_df['std'] = feature_importance_all.groupby('feature').std()\n",
    "        std_df['mean'] = feature_importance_all.groupby('feature').mean()\n",
    "        \n",
    "        std_df['count'] = feature_count['variability_score']\n",
    "        std_df = std_df[std_df['count'] >= df['rng'].nunique() * strict_mean]\n",
    "\n",
    "        # sort the dataframe by std, ascending\n",
    "\n",
    "        std_df = std_df.sort_values(by='variability_score', ascending=True)\n",
    "        return std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variability_score</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.045472</td>\n",
       "      <td>834002.906249</td>\n",
       "      <td>1.834117e+07</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.143476</td>\n",
       "      <td>107.234729</td>\n",
       "      <td>7.474069e+02</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.234991</td>\n",
       "      <td>113.759009</td>\n",
       "      <td>4.840999e+02</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.248086</td>\n",
       "      <td>361.324631</td>\n",
       "      <td>1.456446e+03</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.291802</td>\n",
       "      <td>598.753161</td>\n",
       "      <td>2.051919e+03</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variability_score            std          mean  count\n",
       "feature                                                       \n",
       "6                 0.045472  834002.906249  1.834117e+07    100\n",
       "4                 0.143476     107.234729  7.474069e+02    100\n",
       "3                 0.234991     113.759009  4.840999e+02    100\n",
       "1                 0.248086     361.324631  1.456446e+03    100\n",
       "7                 0.291802     598.753161  2.051919e+03    100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varia_df = get_variability_for_feature(total_df, 'test', use_iqr=False, strict_mean=0.75)\n",
    "\n",
    "varia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchApp Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading SBML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading anthony's sbml model\n",
    "\n",
    "from libsbml import *\n",
    "\n",
    "reader = SBMLReader()\n",
    "\n",
    "document = reader.readSBML(\"data\\export_ECC_Base.xml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = document.getModel()\n",
    "\n",
    "print(f'Document errors: {document.getNumErrors()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of species: {model.getNumSpecies()}')\n",
    "\n",
    "print(f'Number of reactions: {model.getNumReactions()}')\n",
    "\n",
    "print(f'Number of compartments: {model.getNumCompartments()}')\n",
    "\n",
    "print(f'Number of parameters: {model.getNumParameters()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rules: {model.getNumRules()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import roadrunner\n",
    "\n",
    "rr = roadrunner.RoadRunner(\"data\\export_ECC_Base.xml\")\n",
    "\n",
    "print(f'Number of floating species: {len(rr.model.getFloatingSpeciesIds())}')\n",
    "\n",
    "print(f'Number of boundary species: {len(rr.model.getBoundarySpeciesIds())}')\n",
    "\n",
    "print(f'Number of global parameters: {len(rr.model.getGlobalParameterIds())}')\n",
    "\n",
    "print(f'Number of compartments: {len(rr.model.getCompartmentIds())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rr.simulate(0, 10, 100)\n",
    "\n",
    "rr.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{rr.model.getFloatingSpeciesIds()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model[\"init(IRS)\"]\n",
    "\n",
    "# rr.model[\"init(IRS)\"] = 0.5 # for changing initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model.getGlobalParameterIds()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.kc_INSULIN_INSR_INSRpY\n",
    "\n",
    "# rr.kc_INSULIN_INSR_INSRpY = 0.1 # for changing parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model['kc_INSULIN_INSR_INSRpY'] # another method for changing parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.model['INSR'] # another method for changing initial condition values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking CCLE data to Anthony's SBML model initial conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing parameters in SBML model to the calibrated set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing dynamic simulation data back to singular vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LanODEApp Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load in core data and libraries'''\n",
    "\n",
    "# libraries used \n",
    "\n",
    "# load CCLE expression data  \n",
    "\n",
    "# load Anthony's model and optimal parameter sets \n",
    "\n",
    "document = reader.readSBML(\"data\\export_ECC_Base.xml\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamic-marker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

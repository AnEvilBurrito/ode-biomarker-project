{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework\n",
    "\n",
    "- Data - Palbociclib Data (Proteomics and GDSC2)\n",
    "- Preprocessing method - missing data imputation by lower quantile (0 to 0.25)\n",
    "- Feature selection (Filtering) - select features with pearson correlation >= |0.4|\n",
    "- Model - Elastic Net\n",
    "- Target variable used - AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github\\ode-biomarker-project\\dynamic-marker\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import DataFunctions as utils\n",
    "import Visualisation as vis\n",
    "from toolkit import * \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "save_results_path = 'data//results//workbook-4-jun' \n",
    "\n",
    "if not os.path.exists(save_results_path):\n",
    "    os.makedirs(save_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# import GDSC2 drug response data using pickle\n",
    "\n",
    "with open('data/drug-response/GDSC2/cache_gdsc2.pkl', 'rb') as f:\n",
    "    gdsc2 = pickle.load(f)\n",
    "    gdsc2_info = pickle.load(f)\n",
    "\n",
    "# import CCLE gene expression data using pickle\n",
    "\n",
    "with open('data/gene-expression/CCLE_Public_22Q2/ccle_expression.pkl', 'rb') as f:\n",
    "    gene_entrez = pickle.load(f)\n",
    "    ccle = pickle.load(f)\n",
    "\n",
    "# import CCLE sample info data using pickle\n",
    "\n",
    "with open('data/gene-expression/CCLE_Public_22Q2/ccle_sample_info.pkl', 'rb') as f:\n",
    "    ccle_sample_info = pickle.load(f)\n",
    "\n",
    "# import STRING database using pickle\n",
    "\n",
    "with open('data/protein-interaction/STRING/string_df.pkl', 'rb') as f:\n",
    "    string_df = pickle.load(f)\n",
    "    string_df_info = pickle.load(f)\n",
    "    string_df_alias = pickle.load(f)\n",
    "\n",
    "\n",
    "# import proteomic expression\n",
    "with open('data/proteomic-expression/goncalves-2022-cell/goncalve_proteome_fillna_processed.pkl', 'rb') as f:\n",
    "    joined_full_protein_matrix = pickle.load(f)\n",
    "    joined_sin_peptile_exclusion_matrix = pickle.load(f)\n",
    "\n",
    "# import STRING database using pickle\n",
    "\n",
    "with open('data/protein-interaction/STRING/string_df.pkl', 'rb') as f:\n",
    "    string_df = pickle.load(f)\n",
    "    string_df_info = pickle.load(f)\n",
    "    string_df_alias = pickle.load(f)\n",
    "\n",
    "# open STRING to goncalves mapping file\n",
    "\n",
    "with open('data\\protein-interaction\\STRING\\goncalve_to_string_id_df.pkl', 'rb') as f:\n",
    "    goncalve_to_string_id_df = pickle.load(f)\n",
    "\n",
    "# open the cache for neighbourhood calculations\n",
    "\n",
    "with open('data/protein-interaction/STRING/palbociclib_nth_degree_neighbours.pkl', 'rb') as f:\n",
    "    nth_degree_neighbours = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config Parameters\n",
    "\n",
    "## Data \n",
    "\n",
    "# create the full dataset\n",
    "drug_selected = 'Palbociclib'\n",
    "\n",
    "## Preprocessing Method\n",
    "# Between fill by zero, impute by random variable between 0 to 1st quantile\n",
    "# Impute1stQuantile, Fill0, ImputeKNN\n",
    "preprocessing_method = 'Impute1stQuantile'\n",
    "\n",
    "# set threshold for feature removal (0.8 means remove features with > 80% missing values)\n",
    "feature_nan_removal_threshold = 0.8\n",
    "\n",
    "## Feature Selection Methods\n",
    "\n",
    "## Models \n",
    "## Target variable used\n",
    "\n",
    "target_variable = 'AUC'\n",
    "\n",
    "## Hyperparameters\n",
    "experiment_name = 'test'\n",
    "save_input = True\n",
    "save_output = True\n",
    "\n",
    "# hyperparameters\n",
    "max_gene_target_disance = 2 # specify the level of biological relevance to drug target(s)\n",
    "statistical_filter_size = 100 # can be optimized using global feature dropout testing\n",
    "monte_carlo_cross_validation_size = 50 # can be automatically optimized via rank impact assessment\n",
    "models_used = ['ElasticNet']\n",
    "models_hyperparameters = [{'alpha': 0.005},]\n",
    "\n",
    "# extra hyperparameters\n",
    "statistical_filter_threshold = 0.05 # currently not in use\n",
    "cv_split_size = 0.1\n",
    "n_cores_to_use = 1 # global parameter for parallel processing\n",
    "\n",
    "# generated hyperparameters\n",
    "rng_seed_lists = []\n",
    "for j in range(monte_carlo_cross_validation_size):\n",
    "    rng_seed_lists.append(np.random.randint(100000))\n",
    "\n",
    "\n",
    "verbose = True\n",
    "max_feature_save_size = 1000\n",
    "data_collector = []\n",
    "conditions_to_test = ['network_f_regression_selection',]\n",
    "conditions_to_get_feature_importance = [True,]\n",
    "matched_functions = [get_network_stat_features,]\n",
    "extra_args = [(nth_degree_neighbours, max_gene_target_disance, statistical_filter_size),]\n",
    "features_to_knockout = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = utils.create_joint_dataset_from_proteome_gdsc(drug_selected, joined_sin_peptile_exclusion_matrix, gdsc2, drug_value=target_variable)\n",
    "feature_data, label_data = utils.create_feature_and_label(data_df, label_name=target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ feature size: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Github\\ode-biomarker-project\\workbook-4-jun-2023.ipynb Cell 6\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m feature_size \u001b[39min\u001b[39;00m feature_size_tested:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m------------------ feature size: \u001b[39m\u001b[39m{\u001b[39;00mfeature_size\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     feature_size_df \u001b[39m=\u001b[39m run_bulk_test([\u001b[39m'\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnetwork_stat\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m                                     [\u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                                     [impute_with_random_selection, impute_with_stat_selection, impute_with_network_stat_selection], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                                     [(feature_size,), (feature_size,), (nth_degree_neighbours, max_gene_target_disance, feature_size)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                                     models_used, models_hyperparameters,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                                     rng_seed_lists, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                                     feature_data, label_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                                     cv_split_size\u001b[39m=\u001b[39mcv_split_size, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                                     verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                                     bulk_run_tag\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfeature_size_\u001b[39m\u001b[39m{\u001b[39;00mfeature_size\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                                     save_output\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                                     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39m# create a column for feature size for each row\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     feature_size_df[\u001b[39m'\u001b[39m\u001b[39mfeature_size\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feature_size\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:232\u001b[0m, in \u001b[0;36mrun_bulk_test\u001b[1;34m(conditions_to_test, conditions_to_get_feature_importance, matched_functions, extra_args, models_used, models_hyperparameters, rng_seed_lists, feature_data, label_data, cv_split_size, max_feature_save_size, n_jobs, verbose, save_output, bulk_run_tag, output_file_path)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[39mfor\u001b[39;00m rng \u001b[39min\u001b[39;00m rng_seed_lists:\n\u001b[0;32m    231\u001b[0m             \u001b[39mfor\u001b[39;00m j, condition \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(conditions_to_test):\n\u001b[1;32m--> 232\u001b[0m                 data \u001b[39m=\u001b[39m run_single_test(condition,\n\u001b[0;32m    233\u001b[0m                                     conditions_to_get_feature_importance[j],\n\u001b[0;32m    234\u001b[0m                                     matched_functions[j],\n\u001b[0;32m    235\u001b[0m                                     extra_args[j],\n\u001b[0;32m    236\u001b[0m                                     model_str,\n\u001b[0;32m    237\u001b[0m                                     models_hyperparameters[m],\n\u001b[0;32m    238\u001b[0m                                     rng,\n\u001b[0;32m    239\u001b[0m                                     feature_data, label_data,\n\u001b[0;32m    240\u001b[0m                                     cv_split_size,\n\u001b[0;32m    241\u001b[0m                                     max_feature_save_size,\n\u001b[0;32m    242\u001b[0m                                     verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[0;32m    244\u001b[0m                 data_collector\u001b[39m.\u001b[39mappend(data)\n\u001b[0;32m    245\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[0;32m    246\u001b[0m     \u001b[39m# use joblib to parallelize the process\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:159\u001b[0m, in \u001b[0;36mrun_single_test\u001b[1;34m(condition, condition_to_get_feature_importance, matched_function, extra_arg, model_str, single_model_hyperparameters, rng, feature_data, label_data, cv_split_size, max_feature_save_size, verbose)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrunning \u001b[39m\u001b[39m{\u001b[39;00mmodel_str\u001b[39m}\u001b[39;00m\u001b[39m with seed \u001b[39m\u001b[39m{\u001b[39;00mrng\u001b[39m}\u001b[39;00m\u001b[39m under \u001b[39m\u001b[39m{\u001b[39;00mcondition\u001b[39m}\u001b[39;00m\u001b[39m conditions\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    157\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(feature_data, label_data, test_size\u001b[39m=\u001b[39mcv_split_size, random_state\u001b[39m=\u001b[39mrng)\n\u001b[1;32m--> 159\u001b[0m selected_features, sel_train, sel_test \u001b[39m=\u001b[39m matched_function(X_train, y_train, X_test, \u001b[39m*\u001b[39;49mextra_arg)\n\u001b[0;32m    160\u001b[0m model \u001b[39m=\u001b[39m get_model_from_string(model_str, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msingle_model_hyperparameters)\n\u001b[0;32m    161\u001b[0m model\u001b[39m.\u001b[39mfit(sel_train, y_train)\n",
      "\u001b[1;32mc:\\Github\\ode-biomarker-project\\workbook-4-jun-2023.ipynb Cell 6\u001b[0m in \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimpute_with_stat_selection\u001b[39m(X_train, y_train, X_test, statistical_filter_size):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     X_train, y_train, X_test \u001b[39m=\u001b[39m impute_by_first_quantile(X_train, y_train, X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# perform feature selection on the training set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/ode-biomarker-project/workbook-4-jun-2023.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     selector \u001b[39m=\u001b[39m SelectKBest(f_regression, k\u001b[39m=\u001b[39mstatistical_filter_size)\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:134\u001b[0m, in \u001b[0;36mimpute_by_first_quantile\u001b[1;34m(X_train, y_train, X_test)\u001b[0m\n\u001b[0;32m    132\u001b[0m imputer \u001b[39m=\u001b[39m FirstQuantileImputer()\n\u001b[0;32m    133\u001b[0m imputer\u001b[39m.\u001b[39mfit(X_test)\n\u001b[1;32m--> 134\u001b[0m X_test \u001b[39m=\u001b[39m imputer\u001b[39m.\u001b[39;49mtransform(X_test, return_df\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m X_train, y_train, X_test\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\dynamic-marker\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Github\\ode-biomarker-project\\toolkit.py:65\u001b[0m, in \u001b[0;36mFirstQuantileImputer.transform\u001b[1;34m(self, X, y, return_df)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misnan(hi_bound):\n\u001b[0;32m     63\u001b[0m         hi_bound \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mdropna()\u001b[39m.\u001b[39mmin()\n\u001b[1;32m---> 65\u001b[0m     vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49muniform(\u001b[39m0\u001b[39;49m, hi_bound, size\u001b[39m=\u001b[39;49mX[col]\u001b[39m.\u001b[39;49misna()\u001b[39m.\u001b[39;49msum())\n\u001b[0;32m     66\u001b[0m     X\u001b[39m.\u001b[39mloc[X[col]\u001b[39m.\u001b[39misna(), col] \u001b[39m=\u001b[39m vals\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m return_df:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Test Feature Size Effect on training performance between 0 to 500 \n",
    "\n",
    "def impute_with_random_selection(X_train, y_train, X_test, n_features):\n",
    "    X_train, y_train, X_test = impute_by_first_quantile(X_train, y_train, X_test)\n",
    "    features, X_train, X_test = get_random_features(X_train, y_train, X_test, n_features)\n",
    "    return features, X_train, X_test\n",
    "\n",
    "def impute_with_stat_selection(X_train, y_train, X_test, statistical_filter_size):\n",
    "    X_train, y_train, X_test = impute_by_first_quantile(X_train, y_train, X_test)\n",
    "    # perform feature selection on the training set\n",
    "    selector = SelectKBest(f_regression, k=statistical_filter_size)\n",
    "    selector.fit(X_train, y_train)\n",
    "    # get the selected features\n",
    "    selected_features = X_train.columns[selector.get_support()]\n",
    "    sel_train, sel_test = X_train[selected_features], X_test[selected_features]\n",
    "    return selected_features, sel_train, sel_test\n",
    "\n",
    "def impute_with_network_stat_selection(X_train, y_train, X_test, nth_degree_neighbours, max_gene_target_disance, statistical_filter_size):\n",
    "    X_train, y_train, X_test = impute_by_first_quantile(X_train, y_train, X_test)\n",
    "    features, sel_train, sel_test = get_network_stat_features(X_train, y_train, X_test, nth_degree_neighbours, max_gene_target_disance, statistical_filter_size)\n",
    "    return features, sel_train, sel_test\n",
    "\n",
    "feature_size_tested = []\n",
    "for i in range(1, 500, 10):\n",
    "    feature_size_tested.append(i)\n",
    "\n",
    "all_df = pd.DataFrame()\n",
    "\n",
    "for feature_size in feature_size_tested:\n",
    "    print(f'------------------ feature size: {feature_size}')\n",
    "    feature_size_df = run_bulk_test(['random', 'stat', 'network_stat'], \n",
    "                                    [False, False, False], \n",
    "                                    [impute_with_random_selection, impute_with_stat_selection, impute_with_network_stat_selection], \n",
    "                                    [(feature_size,), (feature_size,), (nth_degree_neighbours, max_gene_target_disance, feature_size)],\n",
    "                                    models_used, models_hyperparameters,\n",
    "                                    rng_seed_lists, \n",
    "                                    feature_data, label_data,\n",
    "                                    cv_split_size=cv_split_size, \n",
    "                                    verbose=False, \n",
    "                                    bulk_run_tag=f'feature_size_{feature_size}',\n",
    "                                    save_output=False,\n",
    "                                    )\n",
    "    # create a column for feature size for each row\n",
    "    feature_size_df['feature_size'] = feature_size\n",
    "    all_df = pd.concat([all_df, feature_size_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the results\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# plot a line plot with error bars for pearson correlation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "sns.lineplot(x='feature_size', y='corr', hue='exp_condition', data=all_df, ax=ax)\n",
    "ax.set_title(f'Pearson correlation of proteomic expression with palbociclib AUC vs feature size')\n",
    "ax.set_xlabel('feature size')\n",
    "ax.set_ylabel('Pearson correlation')\n",
    "# enlarge the tick labels\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "# enlarge the xlabel and ylabel\n",
    "ax.xaxis.label.set_size(16)\n",
    "ax.yaxis.label.set_size(16)\n",
    "# enlarge the title\n",
    "ax.title.set_fontsize(20)\n",
    "plt.savefig(save_results_path+'feature_size_pearson_corr.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Record SHAP values for network stat features\n",
    "\n",
    "shap_df = run_bulk_test(['network_stat'],\n",
    "                        [False],\n",
    "                        [impute_with_network_stat_selection],\n",
    "                        [(nth_degree_neighbours, max_gene_target_disance, statistical_filter_size)],\n",
    "                        models_used, models_hyperparameters,\n",
    "                        rng_seed_lists,\n",
    "                        feature_data, label_data,\n",
    "                        cv_split_size=cv_split_size,\n",
    "                        verbose=False,\n",
    "                        bulk_run_tag=f'feature_selection_shap',\n",
    "                        save_output=False,\n",
    "                        save_output_path=save_results_path+'shap_output.pkl',\n",
    "                        )\n",
    "\n",
    "\n",
    "shap_contribs = get_mean_contribution(shap_df, 'network_stat')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean shap values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('### Plotting mean contribution')\n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.barplot(x=shap_contribs.values, y=shap_contribs.index)\n",
    "plt.title('Mean contribution of each feature to the prediction')\n",
    "plt.xlabel('Mean of Mean SHAP Absolute Value')\n",
    "plt.ylabel('Feature name')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_results_path+'mean_contribution.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

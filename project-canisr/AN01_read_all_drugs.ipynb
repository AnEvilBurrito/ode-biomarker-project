{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Users\\dawson\\Documents\\GitHub\\ode-biomarker-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path)\n",
    "print(f'Project path set to: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PathLoader import PathLoader\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLink import DataLink\n",
    "data_link = DataLink(path_loader, 'data_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages \n",
    "\n",
    "from tqdm import tqdm\n",
    "from toolkit import *\n",
    "\n",
    "# load folder specific python files \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "def pipeline_tree_methods(X_train, \n",
    "                          y_train, \n",
    "                          rng, \n",
    "                          model_used, \n",
    "                          model_extra_args, \n",
    "                          pre_filter=True,\n",
    "                          pre_filter_size=1000,\n",
    "                          **kwargs):\n",
    "    \n",
    "    # RandomForestRegressor or XGBRegressor at the moment \n",
    "    if model_used != 'RandomForestRegressor' and model_used != 'XGBRegressor':\n",
    "        raise ValueError(f'Model not supported for pipeline_tree_methods, use RandomForestRegressor or XGBRegressor, current model_used param is: {model_used}')\n",
    "    \n",
    "    # perform feature selection if pre_filter is True\n",
    "    if pre_filter:\n",
    "        selected_features, scores = f_regression_select(X_train, y_train, pre_filter_size)\n",
    "        _, X_selected = select_preset_features(X_train, y_train, selected_features)\n",
    "    else:\n",
    "        X_selected = X_train\n",
    "    model = get_model_from_string(model_used, **model_extra_args)\n",
    "    model.fit(X_selected, y_train)\n",
    "    return {'model': model, \n",
    "            'model_type': model_used,\n",
    "            'train_data': X_train,\n",
    "            'pre_filter': pre_filter,\n",
    "            'filtered_features': selected_features if pre_filter else None,\n",
    "            }\n",
    "\n",
    "\n",
    "def shap_eval_func(X_test, y_test, pipeline_components=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    evaluate the performance of a pipeline through pearson correlation, r2, mse, and \n",
    "    feature importance scores using mean absolute SHAP values \n",
    "    inputs\n",
    "        X_test: test set features\n",
    "        y_test: test set labels\n",
    "        pipeline_components: dictionary of pipeline components, e.g. {'model': model, 'selected_features': selected_features, 'scores': scores}\n",
    "    '''\n",
    "    \n",
    "    ## evaluation of model performance using test set\n",
    "    X_test, y_test = transform_impute_by_zero_to_min_uniform(X_test, y_test)\n",
    "    if pipeline_components['filtered_features'] is None: \n",
    "        X_selected = X_test\n",
    "    else:\n",
    "        _, X_selected = select_preset_features(X_test, y_test, pipeline_components['filtered_features'])\n",
    "    y_pred = pipeline_components['model'].predict(X_selected)\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ## obtaining SHAP values for each feature, mean absolute SHAP values will \n",
    "    ## be used as a way to compute feature importance scores \n",
    "    shap_values = get_shap_values(pipeline_components['model'], \n",
    "                                  pipeline_components['model_type'],\n",
    "                                  pipeline_components['train_data'], \n",
    "                                  X_selected)\n",
    "    mean_shap_values = np.abs(shap_values).mean(axis=0)\n",
    "    ## returning key metrics and results \n",
    "    features, scores = X_selected.columns.tolist(), mean_shap_values.tolist()\n",
    "    # at the end, return a dictionary of all the information you want to return\n",
    "    return {'model_used': pipeline_components['model_type'],\n",
    "            'prediction_target': 'cell_LNIC50',\n",
    "            'model_performance': corr, \n",
    "            'pearson_p_vals': p_vals, \n",
    "            'r_squared': r2,\n",
    "            'mse': mse,\n",
    "            'feature_importance': (features, scores),\n",
    "            'important_features': features, \n",
    "            'feature_scores': scores,\n",
    "            'y_pred': y_pred, # for plotting purposes\n",
    "            'y_test': y_test, \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\\\\proteomic-expression\\\\ccle-2019-cell\\\\ccle_proteomics_processed.pkl for access \n",
    "data = data_link.get_data_from_code('ccle_protein_expression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriving Data \n",
    "\n",
    "Create a list that stores all drug names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ipatasertib',\n",
       " 'AZD6482',\n",
       " 'IAP_5620',\n",
       " 'BMS-345541',\n",
       " 'KU-55933',\n",
       " 'Alisertib',\n",
       " 'VSP34_8731',\n",
       " 'Nelarabine',\n",
       " 'Cytarabine',\n",
       " 'AZD6738',\n",
       " 'Staurosporine',\n",
       " 'Leflunomide',\n",
       " 'AGI-5198',\n",
       " 'Ibrutinib',\n",
       " 'PD0325901',\n",
       " 'Picolinici-acid',\n",
       " 'MK-2206',\n",
       " 'I-BET-762',\n",
       " 'JAK1_8709',\n",
       " 'GSK2606414',\n",
       " 'Zoledronate',\n",
       " 'OSI-027',\n",
       " 'AZD8186',\n",
       " 'Docetaxel',\n",
       " 'MK-1775',\n",
       " 'Gallibiscoquinazole',\n",
       " 'Dactolisib',\n",
       " 'Elephantin',\n",
       " 'Foretinib',\n",
       " 'Crizotinib',\n",
       " 'Temozolomide',\n",
       " 'PAK_5339',\n",
       " 'Ulixertinib',\n",
       " 'Camptothecin',\n",
       " 'ERK_2440',\n",
       " 'AZD5991',\n",
       " 'ML323',\n",
       " 'UMI-77',\n",
       " 'LCL161',\n",
       " 'XAV939',\n",
       " 'GSK1904529A',\n",
       " 'PRIMA-1MET',\n",
       " 'MN-64',\n",
       " 'Topotecan',\n",
       " 'AMG-319',\n",
       " 'Alpelisib',\n",
       " 'GDC0810',\n",
       " 'LY2109761',\n",
       " 'KRAS (G12C) Inhibitor-12',\n",
       " 'RO-3306',\n",
       " 'EPZ5676',\n",
       " 'EPZ004777',\n",
       " 'OTX015',\n",
       " 'Obatoclax Mesylate',\n",
       " 'MK-8776',\n",
       " 'Vinorelbine',\n",
       " 'VE-822',\n",
       " 'Cyclophosphamide',\n",
       " 'TAF1_5496',\n",
       " 'VX-11e',\n",
       " 'Sepantronium bromide',\n",
       " 'CDK9_5038',\n",
       " 'GSK2578215A',\n",
       " 'Wee1 Inhibitor',\n",
       " 'Taselisib',\n",
       " 'Erlotinib',\n",
       " 'PCI-34051',\n",
       " 'PD173074',\n",
       " 'Doramapimod',\n",
       " 'Irinotecan',\n",
       " 'BIBR-1532',\n",
       " 'Carmustine',\n",
       " 'AZD3759',\n",
       " 'Daporinad',\n",
       " 'AZD5438',\n",
       " 'Vinblastine',\n",
       " 'Linsitinib',\n",
       " 'Sapitinib',\n",
       " 'RVX-208',\n",
       " 'AGI-6780',\n",
       " 'Pyridostatin',\n",
       " 'Entospletinib',\n",
       " 'PLX-4720',\n",
       " 'ZM447439',\n",
       " 'Axitinib',\n",
       " 'Palbociclib',\n",
       " 'Buparlisib',\n",
       " 'AZ6102',\n",
       " 'Talazoparib',\n",
       " 'Pevonedistat',\n",
       " 'Entinostat',\n",
       " 'SB216763',\n",
       " 'AZD7762',\n",
       " 'GSK591',\n",
       " 'AZ960',\n",
       " 'GSK343',\n",
       " 'Luminespib',\n",
       " 'WIKI4',\n",
       " 'MG-132',\n",
       " 'Telomerase Inhibitor IX',\n",
       " 'VE821',\n",
       " 'Dasatinib',\n",
       " 'AZD8055',\n",
       " 'Vincristine',\n",
       " 'OF-1',\n",
       " 'AZD1208',\n",
       " 'Teniposide',\n",
       " 'NVP-ADW742',\n",
       " 'Dihydrorotenone',\n",
       " 'Osimertinib',\n",
       " 'BMS-754807',\n",
       " 'AZD5582',\n",
       " 'Dabrafenib',\n",
       " 'Gemcitabine',\n",
       " 'SB505124',\n",
       " 'IWP-2',\n",
       " 'Acetalax',\n",
       " 'Oxaliplatin',\n",
       " 'PRT062607',\n",
       " 'P22077',\n",
       " 'WEHI-539',\n",
       " 'Dactinomycin',\n",
       " 'AZD1332',\n",
       " 'JQ1',\n",
       " 'Trametinib',\n",
       " 'AZD5153',\n",
       " 'Sorafenib',\n",
       " 'NU7441',\n",
       " 'Paclitaxel',\n",
       " 'ABT737',\n",
       " 'Podophyllotoxin bromide',\n",
       " 'Tamoxifen',\n",
       " 'Lapatinib',\n",
       " 'ERK_6604',\n",
       " 'Vorinostat',\n",
       " 'Bortezomib',\n",
       " 'Epirubicin',\n",
       " 'Uprosertib',\n",
       " 'BI-2536',\n",
       " 'AZD5363',\n",
       " 'LJI308',\n",
       " 'BMS-536924',\n",
       " 'MIRA-1',\n",
       " 'Eg5_9814',\n",
       " 'MIM1',\n",
       " 'Olaparib',\n",
       " 'Afatinib',\n",
       " 'ULK1_4989',\n",
       " 'AZD4547',\n",
       " 'BDP-00009066',\n",
       " 'Cisplatin',\n",
       " 'Niraparib',\n",
       " 'Nutlin-3a (-)',\n",
       " 'BPD-00008900',\n",
       " 'YK-4-279',\n",
       " 'Afuresertib',\n",
       " 'Selumetinib',\n",
       " 'PF-4708671',\n",
       " 'SCH772984',\n",
       " 'Nilotinib',\n",
       " 'Cediranib',\n",
       " 'I-BRD9',\n",
       " '5-Fluorouracil',\n",
       " 'IGF1R_3801',\n",
       " 'CZC24832',\n",
       " 'PFI3',\n",
       " 'CDK9_5576',\n",
       " 'IRAK4_4710',\n",
       " 'Rapamycin',\n",
       " 'WZ4003',\n",
       " 'GNE-317',\n",
       " 'Pictilisib',\n",
       " 'Mitoxantrone',\n",
       " 'Navitoclax',\n",
       " 'Fulvestrant',\n",
       " 'Sabutoclax',\n",
       " 'Tozasertib',\n",
       " 'Wnt-C59',\n",
       " 'Venetoclax',\n",
       " 'AZD2014',\n",
       " 'Savolitinib',\n",
       " 'Ribociclib',\n",
       " 'Dinaciclib',\n",
       " 'AT13148',\n",
       " 'Mirin',\n",
       " 'GSK269962A',\n",
       " 'Gefitinib',\n",
       " 'JAK_8517',\n",
       " 'Ruxolitinib',\n",
       " 'LGK974',\n",
       " 'Sinularin',\n",
       " 'Fludarabine']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdsc = data_link.get_data_from_code('gdsc1')\n",
    "# Select column 'DRUG_NAME' and make it unique by using set()\n",
    "all_drug_names = list(set(gdsc['DRUG_NAME']))\n",
    "all_drug_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 73/192 [00:14<00:20,  5.72it/s]"
     ]
    }
   ],
   "source": [
    "# load in dynamic features data \n",
    "\n",
    "available_drugs = []\n",
    "for drug_name in tqdm(all_drug_names):\n",
    "    if '-' in drug_name:\n",
    "        continue\n",
    "    # print(drug_name)\n",
    "    loading_code = f'generic-gdsc-1-{drug_name}-LN_IC50-ccle_protein_expression-true-Cell_Line'\n",
    "    # generic-gdsc-{number}-{drug_name}-{target_label}-{dataset_name}-{replace_index}-{row_index}\n",
    "    feature_data, label_data = data_link.get_data_using_code(loading_code)\n",
    "    # print(f'Data loaded for code {loading_code} Feature Shape {feature_data.shape} Label Shape {label_data.shape}')\n",
    "    # if the feature data is not empty, append the drug name to the available_drugs list\n",
    "    if feature_data.shape[0] > 0 and label_data.shape[0] > 0:\n",
    "        available_drugs.append(drug_name)\n",
    "        \n",
    "available_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(available_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Streamline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'CANISRDatabase'\n",
    "\n",
    "if not os.path.exists(f'{path_loader.get_data_path()}data/results/{folder_name}'):\n",
    "    os.makedirs(f'{path_loader.get_data_path()}data/results/{folder_name}')\n",
    "\n",
    "file_save_path = f'{path_loader.get_data_path()}data/results/{folder_name}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_func(X_train, y_train, rng, model_used, **kwargs):\n",
    "    k = X_train.shape[1]\n",
    "    selected_features, scores = f_regression_select(X_train, y_train, int(k/2))\n",
    "    model = get_model_from_string(model_used, **kwargs)\n",
    "    selected_features, X_selected = select_preset_features(X_train, y_train, selected_features)\n",
    "    model.fit(X_selected, y_train)\n",
    "    return {'model': model,\n",
    "            'filter_selected_features': selected_features,\n",
    "            'filter_scores': scores}\n",
    "\n",
    "\n",
    "def eval_func(X_test, y_test, pipeline_components=None, **kwargs):\n",
    "    selected_features, X_selected = select_preset_features(X_test, y_test, pipeline_components['filter_selected_features'])\n",
    "    y_pred = pipeline_components['model'].predict(X_selected)\n",
    "    # assess performance by pearson correlation\n",
    "    corr, p_vals = pearsonr(y_test, y_pred)\n",
    "    feat_imp = (pipeline_components['filter_selected_features'], pipeline_components['filter_scores'])\n",
    "    return {'model_performance': corr, 'p_vals': p_vals, 'feature_importance': feat_imp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_drug(drug_name, rng): \n",
    "    loading_code = f'generic-gdsc-2-{drug_name}-LN_IC50-ccle_protein_expression-true-Cell_Line'\n",
    "    feature_data, label_data = data_link.get_data_using_code(loading_code)\n",
    "    print(f'Data loaded for code {loading_code} Feature Shape {feature_data.shape} Label Shape {label_data.shape}')\n",
    "    \n",
    "    ### Extra Preprocessing Steps \n",
    "    # ensure all feature column names are strings\n",
    "    feature_data.columns = [str(col) for col in feature_data.columns]\n",
    "    # remove Nan values from the feature data\n",
    "    feature_data = feature_data.dropna(axis=1)\n",
    "    # ensure all column names are unique by dropping duplicates\n",
    "    feature_data = feature_data.loc[:,~feature_data.columns.duplicated()]\n",
    "    print(f'Feature Shape after preprocessing and dropping duplicates {feature_data.shape}')\n",
    "    powerkit = Powerkit(feature_data, label_data)\n",
    "    powerkit.add_condition(drug_name, True, pipeline_func, {'model_used': 'XGBRegressor'}, eval_func, {})\n",
    "    df = powerkit.run_selected_condition(drug_name, [rng], 1, True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = ['Alisertib', 'Palbociclib']\n",
    "all_dfs = []\n",
    "for drug in drugs:\n",
    "    df = run_drug(drug, 0)\n",
    "    all_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all dataframes into one dataframe\n",
    "df = pd.concat(all_dfs)\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert feature importance to a dataframe\n",
    "feature_importance = df['feature_importance'][0].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({'Feature': feature_importance[0], 'Score': feature_importance[1]})\n",
    "# set the value to be the absolute value of the score column\n",
    "feature_importance_df['Score'] = abs(feature_importance_df['Score'])\n",
    "# sort the dataframe by the score column in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Score', ascending=False)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccle_protein_expression-true-Cell_Line\n",
    "\n",
    "sample_kwargs = {\n",
    "    'drugs': available_drugs,\n",
    "    'data_link': data_link,\n",
    "    'drug_database': 'gdsc-2',\n",
    "    'feature_database_string': 'ccle_protein_expression-true-Cell_Line',\n",
    "    'target_name': 'LN_IC50',\n",
    "    'pipeline': pipeline_func,\n",
    "    'pipeline_args': {'model_used': 'RandomForestRegressor', 'model_extra_args': {}},\n",
    "    'evaluation_func': shap_eval_func,\n",
    "    'evaluation_args': {},\n",
    "    'experiment_id': 'test_sample_10',\n",
    "    'random_seeds': [i for i in range(10)],\n",
    "    'n_cores': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_drugs(drug, **kwargs):\n",
    "    # breakdown the kwargs\n",
    "    drug_name = drug\n",
    "    data_link = kwargs['data_link']\n",
    "    drug_database = kwargs['drug_database']\n",
    "    feature_database_string = kwargs['feature_database_string']\n",
    "    target_name = kwargs['target_name']\n",
    "    pipeline = kwargs['pipeline']\n",
    "    pipeline_args = kwargs['pipeline_args']\n",
    "    evaluation_func = kwargs['evaluation_func']\n",
    "    evaluation_args = kwargs['evaluation_args']\n",
    "    random_seeds = kwargs['random_seeds']\n",
    "    n_cores = kwargs['n_cores']\n",
    "    \n",
    "    loading_code = f'generic-{drug_database}-{drug_name}-{target_name}-{feature_database_string}'\n",
    "    feature_data, label_data = data_link.get_data_using_code(loading_code)\n",
    "    print(f'Data loaded for code {loading_code} Feature Shape {feature_data.shape} Label Shape {label_data.shape}')\n",
    "    \n",
    "    ### Extra Preprocessing Steps \n",
    "    # ensure all feature column names are strings\n",
    "    feature_data.columns = [str(col) for col in feature_data.columns]\n",
    "    # remove Nan values from the feature data\n",
    "    feature_data = feature_data.dropna(axis=1)\n",
    "    # ensure all column names are unique by dropping duplicates\n",
    "    feature_data = feature_data.loc[:,~feature_data.columns.duplicated()]\n",
    "    print(f'Feature Shape after preprocessing and dropping duplicates {feature_data.shape}')\n",
    "    powerkit = Powerkit(feature_data, label_data)\n",
    "    powerkit.add_condition(drug_name, True, pipeline, pipeline_args, evaluation_func, evaluation_args)\n",
    "    df = powerkit.run_selected_condition(drug_name, random_seeds, n_cores, True)\n",
    "    return df \n",
    "\n",
    "\n",
    "def run_all_drugs(**kwargs):\n",
    "    drugs = kwargs['drugs']\n",
    "    all_dfs = []\n",
    "    for drug in drugs:\n",
    "        df = run_drugs(drug, **kwargs)\n",
    "        all_dfs.append(df)\n",
    "    # combine all dataframes into one dataframe\n",
    "    df = pd.concat(all_dfs)\n",
    "    # reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_all_drugs(**sample_kwargs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Database and upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# load .env file to get the current\n",
    "engine = create_engine(\n",
    "    \"postgresql+pg8000://canisr:canisr@192.168.3.106:9080/db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.dialects.postgresql import ARRAY, TEXT, INTEGER, FLOAT\n",
    "\n",
    "# write df to database\n",
    "\n",
    "df.to_sql('test_sample_10', engine, if_exists='replace', index=False, dtype={\n",
    "    'important_features': ARRAY(TEXT),\n",
    "    'feature_scores': ARRAY(FLOAT), \n",
    "    'y_pred': ARRAY(FLOAT), \n",
    "    'y_test': ARRAY(FLOAT),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text \n",
    "\n",
    "# select data from database and load into a dataframe to check if the data was written correctly\n",
    "# Establish a connection\n",
    "with engine.connect() as connection:\n",
    "    query = text('SELECT * FROM test_sample_10')\n",
    "    df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 'importance_features' and 'feature_scores' columns from the dataframe and plot them as bar chart\n",
    "\n",
    "feature_importance = df['important_features'][0]\n",
    "feature_scores = df['feature_scores'][0]\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_importance, 'Score': feature_scores})\n",
    "# set the value to be the absolute value of the score column\n",
    "\n",
    "feature_importance_df['Score'] = abs(feature_importance_df['Score'])\n",
    "# sort the dataframe by the score column in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Score', ascending=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='Score', y='Feature', data=feature_importance_df[:10])\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot y_pred and y_test columns from the dataframe\n",
    "\n",
    "y_pred = df['y_pred'][0]\n",
    "y_test = df['y_test'][0]\n",
    "\n",
    "# make into np arrays\n",
    "y_pred = np.array(y_pred)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(y_test, y_pred)\n",
    "# show a trend line\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "plt.plot(y_test, np.poly1d(np.polyfit(y_test, y_pred, 1))(y_test), color='red', lw=2)\n",
    "plt.title('Predictions vs True Values')\n",
    "# also show the correlation coefficient\n",
    "plt.text(0, 6, f'Pearson Correlation: {df[\"model_performance\"][0]:.2f}', fontsize=24, ha='center')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_func(X_train, y_train, rng, model_used, **kwargs):\n",
    "    k = 100 # have to minimize the number of features to 100 for the model to work with kernelexplainer \n",
    "    selected_features, scores = f_regression_select(X_train, y_train, k)\n",
    "    model = get_model_from_string(model_used, **kwargs)\n",
    "    selected_features, X_selected = select_preset_features(X_train, y_train, selected_features)\n",
    "    model.fit(X_selected, y_train)\n",
    "    return {'model': model,\n",
    "            'model_type': model_used,\n",
    "            'train_data': X_selected,\n",
    "            'filtered_features': selected_features,\n",
    "            'filtered_scores': scores}\n",
    "\n",
    "folder_name = 'CANISRDatabase'\n",
    "if not os.path.exists(f'{path_loader.get_data_path()}data/results/{folder_name}'):\n",
    "    os.makedirs(f'{path_loader.get_data_path()}data/results/{folder_name}')\n",
    "\n",
    "file_save_path = f'{path_loader.get_data_path()}data/results/{folder_name}/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = ['RandomForestRegressor', 'XGBRegressor', 'MLPRegressor', 'KNeighborsRegressor', 'ElasticNet', 'LinearRegression', 'SVR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamline2_kwargs = {\n",
    "    'drugs': available_drugs, # FIXME: Change this to available_drugs on nml\n",
    "    'models_used': all_models, # FIXME: Change this to all_models on nml\n",
    "    'data_link': data_link,\n",
    "    'drug_database': 'gdsc-1',\n",
    "    'feature_database_string': 'ccle_protein_expression-true-Cell_Line',\n",
    "    'target_name': 'LN_IC50',\n",
    "    'pipeline': pipeline_func,\n",
    "    'pipeline_args': {'model_used': 'RandomForestRegressor'},\n",
    "    'evaluation_func': shap_eval_func,\n",
    "    'evaluation_args': {},\n",
    "    'experiment_id': 'drug_response_models',\n",
    "    'random_seeds': [i for i in range(10)], # FIXME: Change this to 10 on nml\n",
    "    'n_cores': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_drugs_with_model(drug, model_used, **kwargs):\n",
    "    # breakdown the kwargs\n",
    "    drug_name = drug\n",
    "    data_link = kwargs['data_link']\n",
    "    drug_database = kwargs['drug_database']\n",
    "    feature_database_string = kwargs['feature_database_string']\n",
    "    target_name = kwargs['target_name']\n",
    "    pipeline = kwargs['pipeline']\n",
    "    evaluation_func = kwargs['evaluation_func']\n",
    "    evaluation_args = kwargs['evaluation_args']\n",
    "    random_seeds = kwargs['random_seeds']\n",
    "    n_cores = kwargs['n_cores']\n",
    "    \n",
    "    loading_code = f'generic-{drug_database}-{drug_name}-{target_name}-{feature_database_string}'\n",
    "    feature_data, label_data = data_link.get_data_using_code(loading_code)\n",
    "    # print(f'Data loaded for code {loading_code} Feature Shape {feature_data.shape} Label Shape {label_data.shape}')\n",
    "    \n",
    "    ### Extra Preprocessing Steps \n",
    "    # ensure all feature column names are strings\n",
    "    feature_data.columns = [str(col) for col in feature_data.columns]\n",
    "    # remove Nan values from the feature data\n",
    "    feature_data = feature_data.dropna(axis=1)\n",
    "    # ensure all column names are unique by dropping duplicates\n",
    "    feature_data = feature_data.loc[:,~feature_data.columns.duplicated()]\n",
    "    # print(f'Feature Shape after preprocessing and dropping duplicates {feature_data.shape}')\n",
    "    powerkit = Powerkit(feature_data, label_data)\n",
    "    pipeline_args = {'model_used': model_used}\n",
    "    powerkit.add_condition(drug_name, True, pipeline, pipeline_args, evaluation_func, evaluation_args)\n",
    "    df = powerkit.run_selected_condition(drug_name, random_seeds, n_cores, True)\n",
    "    return df \n",
    "\n",
    "import tqdm \n",
    "import itertools\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "def run_all_drugs_2(**kwargs):\n",
    "    drugs = kwargs['drugs']\n",
    "    all_model_used = kwargs['models_used']\n",
    "    # all_dfs = []\n",
    "    # for drug in drugs:\n",
    "    #     for model_used in all_model_used:\n",
    "    #         df = run_drugs_with_model(drug, model_used, **kwargs)\n",
    "    #         all_dfs.append(df)\n",
    "    # use tqdm to show progress bar\n",
    "    all_dfs = []\n",
    "    # zip the drugs and models together\n",
    "    drug_model_pairs = list(itertools.product(drugs, all_model_used))\n",
    "    print(f'Running {len(drug_model_pairs)} drug-model pairs')\n",
    "    for drug, model_used in tqdm(drug_model_pairs, desc=\"Running drug-model pairs\"):\n",
    "        # print(f'Running drug {drug} with model {model_used}')\n",
    "        df = run_drugs_with_model(drug, model_used, **kwargs)\n",
    "        all_dfs.append(df)         \n",
    "    # combine all dataframes into one dataframe\n",
    "    df = pd.concat(all_dfs)\n",
    "    # reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_all_drugs_2(**streamline2_kwargs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column names to be more readable\n",
    "df = df.rename(columns={'condition': 'drugname'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column called 'source_id' which will be a unique id for the entire cohort \n",
    "source_id = \"goncalves_proteomics_gdsc1_shap_v1\"\n",
    "# make all the source_id the same\n",
    "df['source_id'] = source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 'importance_features' and 'feature_scores' columns from the dataframe and plot them as bar chart\n",
    "\n",
    "feature_importance = df['important_features'][0]\n",
    "feature_scores = df['feature_scores'][0]\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_importance, 'Score': feature_scores})\n",
    "# set the value to be the absolute value of the score column\n",
    "\n",
    "feature_importance_df['Score'] = abs(feature_importance_df['Score'])\n",
    "# sort the dataframe by the score column in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Score', ascending=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='Score', y='Feature', data=feature_importance_df[:10])\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot y_pred and y_test columns from the dataframe\n",
    "\n",
    "y_pred = df['y_pred'][0]\n",
    "y_test = df['y_test'][0]\n",
    "\n",
    "# make into np arrays\n",
    "y_pred = np.array(y_pred)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(y_test, y_pred)\n",
    "# show a trend line\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "plt.plot(y_test, np.poly1d(np.polyfit(y_test, y_pred, 1))(y_test), color='red', lw=2)\n",
    "plt.title('Predictions vs True Values')\n",
    "# also show the correlation coefficient\n",
    "plt.text(0, 6, f'Pearson Correlation: {df[\"model_performance\"][0]:.2f}', fontsize=24, ha='center')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to the folder as a pickle file\n",
    "df.to_pickle(f'{file_save_path}drug_response_models.pkl')\n",
    "print(f'Data saved to {file_save_path}drug_response_models.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from PathLoader import PathLoader\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "folder_name = 'SHAPPipeline' # this relates to the corresponding script for a given pipeline \n",
    "condition = 'testrun' # running condition name, can be multiple conditions here\n",
    "\n",
    "# load pickle file\n",
    "data = {}\n",
    "file_strings = ['meta_df', 'rngs_list', 'total_df']\n",
    "loading_path = f'{path_loader.get_data_path()}data/results/{folder_name}/'\n",
    "for string in file_strings:\n",
    "    with open(f'{loading_path}{string}_{condition}.pkl', 'rb') as handle:\n",
    "        data[string] = pickle.load(handle)\n",
    "\n",
    "total_df = data['total_df']\n",
    "meta_df = data['meta_df']\n",
    "rngs_list = data['rngs_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q07157;ZO1_HUMAN: 0.0\n",
      "P10301;RRAS_HUMAN: 0.00919809306654198\n",
      "P42768;WASP_HUMAN: 0.0\n",
      "P08575;PTPRC_HUMAN: 0.0\n",
      "Q12959;DLG1_HUMAN: 0.009262273077079003\n",
      "P14317;HCLS1_HUMAN: 0.0\n",
      "Q92835;SHIP1_HUMAN: 0.0\n",
      "P35221;CTNA1_HUMAN: 0.0\n",
      "P35222;CTNB1_HUMAN: 0.01718109009278917\n",
      "P41240;CSK_HUMAN: 0.046690955789939426\n",
      "O00159;MYO1C_HUMAN: 0.0\n",
      "P05067;A4_HUMAN: 0.09061422978454617\n",
      "Q6WCQ1;MPRIP_HUMAN: 0.1409622984458508\n",
      "Q92608;DOCK2_HUMAN: 0.0\n",
      "P33316;DUT_HUMAN: 0.0035557395501818983\n",
      "Q14789;GOGB1_HUMAN: 0.015616058282382588\n",
      "P29350;PTN6_HUMAN: 0.0036652135535133806\n",
      "Q9Y5B0;CTDP1_HUMAN: 0.11627870917164111\n",
      "O60716;CTND1_HUMAN: 0.0\n",
      "P15151;PVR_HUMAN: 0.013559254390375345\n",
      "P63010;AP2B1_HUMAN: 0.0\n",
      "P98171;RHG04_HUMAN: 0.0\n",
      "P33993;MCM7_HUMAN: 0.0\n",
      "P35236;PTN7_HUMAN: 0.0\n",
      "P02545;LMNA_HUMAN: 0.032814448220297554\n",
      "P06756;ITAV_HUMAN: 0.019999257711113893\n",
      "Q08379;GOGA2_HUMAN: 0.0\n",
      "Q13422;IKZF1_HUMAN: 0.0\n",
      "O43516;WIPF1_HUMAN: 0.0\n",
      "P06400;RB_HUMAN: 0.1520167137473922\n",
      "Q14566;MCM6_HUMAN: 0.03087598971330163\n",
      "P33991;MCM4_HUMAN: 0.0\n",
      "Q92556;ELMO1_HUMAN: 0.0\n",
      "Q8N3R9;PALS1_HUMAN: 0.06776647548839743\n",
      "P32519;ELF1_HUMAN: 0.16172530052220796\n",
      "Q14247;SRC8_HUMAN: 0.027239077181730277\n",
      "P25205;MCM3_HUMAN: 0.0\n",
      "Q9UQB8;BAIP2_HUMAN: 0.1369350228718478\n",
      "Q9UBI6;GBG12_HUMAN: 0.03658498093917128\n",
      "P62820;RAB1A_HUMAN: 0.02453051789957438\n"
     ]
    }
   ],
   "source": [
    "feature_importance = total_df['feature_importance']\n",
    "# print(f'feature_importance: {feature_importance.iloc[1][0]}')\n",
    "features, scores = feature_importance.iloc[1][0], feature_importance.iloc[1][1]\n",
    "for f, s in zip(features, scores):\n",
    "    print(f'{f}: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P42768;WASP_HUMAN: 0.0\n",
      "P42768;WASP_HUMAN: 0.0\n",
      "P42768;WASP_HUMAN: 0.0\n",
      "P42768;WASP_HUMAN: 0.08562510803787571\n",
      "P42768;WASP_HUMAN: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature = 'P42768;WASP_HUMAN'\n",
    "\n",
    "for row in feature_importance:\n",
    "    features, scores = row[0], row[1]\n",
    "    for f, s in zip(features, scores):\n",
    "        if f == feature:\n",
    "            print(f'{f}: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import Powerkit, get_variation\n",
    "\n",
    "new_powerkit = Powerkit([],[])\n",
    "\n",
    "contributions = new_powerkit.get_mean_contribution(total_df, condition, strict_mean=0.75)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations = get_variation(total_df, condition, use_iqr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testrun 2 and 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from PathLoader import PathLoader\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "folder_name = 'SHAPPipeline' # this relates to the corresponding script for a given pipeline \n",
    "condition = 'testrun2' # running condition name, can be multiple conditions here\n",
    "\n",
    "# load pickle file\n",
    "data = {}\n",
    "file_strings = ['meta_df', 'rngs_list', 'total_df']\n",
    "loading_path = f'{path_loader.get_data_path()}data/results/{folder_name}/'\n",
    "for string in file_strings:\n",
    "    with open(f'{loading_path}{string}_{condition}.pkl', 'rb') as handle:\n",
    "        data[string] = pickle.load(handle)\n",
    "\n",
    "total_df = data['total_df']\n",
    "meta_df = data['meta_df']\n",
    "rngs_list = data['rngs_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import Powerkit, get_variation\n",
    "\n",
    "new_powerkit = Powerkit([],[])\n",
    "\n",
    "contributions = new_powerkit.get_mean_contribution(total_df, condition, strict_mean=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations = get_variation(total_df, condition, use_iqr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from PathLoader import PathLoader\n",
    "path_loader = PathLoader('data_config.env', 'current_user.env')\n",
    "folder_name = 'SHAPPipeline' # this relates to the corresponding script for a given pipeline \n",
    "condition = 'testrun3' # running condition name, can be multiple conditions here\n",
    "\n",
    "# load pickle file\n",
    "data = {}\n",
    "file_strings = ['meta_df', 'rngs_list', 'total_df']\n",
    "loading_path = f'{path_loader.get_data_path()}data/results/{folder_name}/'\n",
    "for string in file_strings:\n",
    "    with open(f'{loading_path}{string}_{condition}.pkl', 'rb') as handle:\n",
    "        data[string] = pickle.load(handle)\n",
    "\n",
    "total_df = data['total_df']\n",
    "meta_df = data['meta_df']\n",
    "rngs_list = data['rngs_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import Powerkit, get_variation\n",
    "\n",
    "new_powerkit = Powerkit([],[])\n",
    "\n",
    "contributions = new_powerkit.get_mean_contribution(total_df, condition, strict_mean=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations = get_variation(total_df, condition, use_iqr=False, strict_mean=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
